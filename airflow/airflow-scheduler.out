[2025-09-08T16:38:05.844+0000] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2025-09-08T16:38:05.917+0000] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2025-09-08T16:38:05.918+0000] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2025-09-08T16:38:05.931+0000] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 4276
[2025-09-08T16:38:05.933+0000] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-08T16:38:05.940+0000] {settings.py:63} INFO - Configured default timezone UTC
[2025-09-08T16:38:05.946+0000] {scheduler_job_runner.py:1870} INFO - Marked 1 SchedulerJob instances as failed
[2025-09-08T16:38:06.000+0000] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-09-08T16:40:03.797+0000] {dag.py:4180} INFO - Setting next_dagrun for branching_pipeline to None, run_after=None
[2025-09-08T16:40:03.859+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:40:03.859+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:40:03.860+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:40:03.861+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:40:03.862+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T16:40:03.862+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:03.867+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:05.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:40:05.702+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:40:06.381+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:40:06.387+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=read_csv_file, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:40:05.740952+00:00, run_end_date=2025-09-08 16:40:06.009073+00:00, run_duration=0.268121, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=86, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:40:03.860698+00:00, queued_by_job_id=85, pid=6291
[2025-09-08T16:40:06.457+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:40:06.458+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:40:06.458+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 1/16 running and queued tasks
[2025-09-08T16:40:06.458+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:40:06.460+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>, <TaskInstance: branching_pipeline.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:40:06.461+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T16:40:06.461+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:06.461+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T16:40:06.462+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:06.466+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:07.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:40:08.150+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:40:03.512588+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:40:08.695+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:10.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:40:11.254+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:40:11.880+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1)
[2025-09-08T16:40:11.881+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:40:11.887+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T16:40:03.512588+00:00, map_index=-1, run_start_date=2025-09-08 16:40:08.182706+00:00, run_end_date=2025-09-08 16:40:08.327021+00:00, run_duration=0.144315, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=87, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:40:06.459513+00:00, queued_by_job_id=85, pid=6310
[2025-09-08T16:40:11.887+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=remove_null_values, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:40:11.288387+00:00, run_end_date=2025-09-08 16:40:11.455908+00:00, run_duration=0.167521, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=88, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:40:06.459513+00:00, queued_by_job_id=85, pid=6346
[2025-09-08T16:40:12.074+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:40:12.075+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:40:12.075+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 1/16 running and queued tasks
[2025-09-08T16:40:12.075+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:40:12.077+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>, <TaskInstance: branching_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:40:12.077+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T16:40:12.077+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:12.078+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T16:40:12.078+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:12.082+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:13.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:40:13.762+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:40:03.512588+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:40:14.383+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:15.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:40:16.025+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:40:16.635+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1)
[2025-09-08T16:40:16.636+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:40:16.639+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=remove_null_values, run_id=manual__2025-09-08T16:40:03.512588+00:00, map_index=-1, run_start_date=2025-09-08 16:40:13.800284+00:00, run_end_date=2025-09-08 16:40:13.949464+00:00, run_duration=0.14918, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=89, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:40:12.076325+00:00, queued_by_job_id=85, pid=6359
[2025-09-08T16:40:16.640+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=determine_branch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:40:16.060600+00:00, run_end_date=2025-09-08 16:40:16.205028+00:00, run_duration=0.144428, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=90, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:40:12.076325+00:00, queued_by_job_id=85, pid=6371
[2025-09-08T16:40:17.140+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.groupby_region_smoker scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:40:17.140+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:40:17.141+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 1/16 running and queued tasks
[2025-09-08T16:40:17.141+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.groupby_region_smoker scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:40:17.142+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>, <TaskInstance: branching_pipeline.groupby_region_smoker scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:40:17.143+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T16:40:17.143+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:17.144+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='groupby_region_smoker', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T16:40:17.144+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'groupby_region_smoker', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:17.148+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:18.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:40:18.803+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:40:03.512588+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:40:19.367+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'groupby_region_smoker', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:20.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:40:21.197+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.groupby_region_smoker scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:40:21.791+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1)
[2025-09-08T16:40:21.791+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='groupby_region_smoker', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:40:21.795+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=determine_branch, run_id=manual__2025-09-08T16:40:03.512588+00:00, map_index=-1, run_start_date=2025-09-08 16:40:18.835946+00:00, run_end_date=2025-09-08 16:40:18.966896+00:00, run_duration=0.13095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=91, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:40:17.142156+00:00, queued_by_job_id=85, pid=6399
[2025-09-08T16:40:21.795+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=groupby_region_smoker, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:40:21.238482+00:00, run_end_date=2025-09-08 16:40:21.385093+00:00, run_duration=0.146611, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=92, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:40:17.142156+00:00, queued_by_job_id=85, pid=6430
[2025-09-08T16:40:21.953+0000] {dagrun.py:854} INFO - Marking run <DagRun branching_pipeline @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 16:40:03.785858+00:00. externally triggered: False> successful
[2025-09-08T16:40:21.954+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=branching_pipeline, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 16:40:03.811859+00:00, run_end_date=2025-09-08 16:40:21.954306+00:00, run_duration=18.142447, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=017ebd910dbefd69905fbd942c6d293a
[2025-09-08T16:40:21.956+0000] {dag.py:4180} INFO - Setting next_dagrun for branching_pipeline to None, run_after=None
[2025-09-08T16:40:21.965+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.groupby_region_smoker manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
[2025-09-08T16:40:21.965+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:40:21.966+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.groupby_region_smoker manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
[2025-09-08T16:40:21.967+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.groupby_region_smoker manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:40:21.967+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='groupby_region_smoker', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T16:40:21.968+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'groupby_region_smoker', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:21.972+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'groupby_region_smoker', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:40:23.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:40:23.761+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.groupby_region_smoker manual__2025-09-08T16:40:03.512588+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:40:24.309+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='groupby_region_smoker', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1)
[2025-09-08T16:40:24.312+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=groupby_region_smoker, run_id=manual__2025-09-08T16:40:03.512588+00:00, map_index=-1, run_start_date=2025-09-08 16:40:23.800257+00:00, run_end_date=2025-09-08 16:40:23.939864+00:00, run_duration=0.139607, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=93, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:40:21.966534+00:00, queued_by_job_id=85, pid=6448
[2025-09-08T16:40:24.461+0000] {dagrun.py:854} INFO - Marking run <DagRun branching_pipeline @ 2025-09-08 16:40:03.512588+00:00: manual__2025-09-08T16:40:03.512588+00:00, state:running, queued_at: 2025-09-08 16:40:03.526583+00:00. externally triggered: True> successful
[2025-09-08T16:40:24.462+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=branching_pipeline, execution_date=2025-09-08 16:40:03.512588+00:00, run_id=manual__2025-09-08T16:40:03.512588+00:00, run_start_date=2025-09-08 16:40:06.435646+00:00, run_end_date=2025-09-08 16:40:24.462004+00:00, run_duration=18.026358, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 16:40:03.512588+00:00, data_interval_end=2025-09-08 16:40:03.512588+00:00, dag_hash=017ebd910dbefd69905fbd942c6d293a
[2025-09-08T16:43:06.005+0000] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-08T16:45:48.492+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
[2025-09-08T16:45:48.492+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:45:48.493+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
[2025-09-08T16:45:48.494+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:45:48.494+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T16:45:48.495+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:45:48.499+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:45:49.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:45:50.350+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:45:47.011336+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:45:50.924+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1)
[2025-09-08T16:45:50.928+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T16:45:47.011336+00:00, map_index=-1, run_start_date=2025-09-08 16:45:50.389855+00:00, run_end_date=2025-09-08 16:45:50.527538+00:00, run_duration=0.137683, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=94, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:45:48.493796+00:00, queued_by_job_id=85, pid=8964
[2025-09-08T16:45:50.997+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
[2025-09-08T16:45:50.997+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:45:50.997+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
[2025-09-08T16:45:50.999+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:45:51.000+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T16:45:51.001+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:45:51.006+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:45:52.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:45:52.675+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:45:47.011336+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:45:53.267+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1)
[2025-09-08T16:45:53.270+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=remove_null_values, run_id=manual__2025-09-08T16:45:47.011336+00:00, map_index=-1, run_start_date=2025-09-08 16:45:52.713208+00:00, run_end_date=2025-09-08 16:45:52.884960+00:00, run_duration=0.171752, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=95, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:45:50.998496+00:00, queued_by_job_id=85, pid=8976
[2025-09-08T16:45:53.324+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
[2025-09-08T16:45:53.324+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:45:53.324+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
[2025-09-08T16:45:53.326+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:45:53.326+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T16:45:53.326+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:45:53.330+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:45:54.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:45:54.989+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:45:47.011336+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:45:55.670+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1)
[2025-09-08T16:45:55.675+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=determine_branch, run_id=manual__2025-09-08T16:45:47.011336+00:00, map_index=-1, run_start_date=2025-09-08 16:45:55.028154+00:00, run_end_date=2025-09-08 16:45:55.163651+00:00, run_duration=0.135497, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=96, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:45:53.325326+00:00, queued_by_job_id=85, pid=8989
[2025-09-08T16:45:56.230+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.filter_by_region manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
[2025-09-08T16:45:56.230+0000] {scheduler_job_runner.py:495} INFO - DAG branching_pipeline has 0/16 running and queued tasks
[2025-09-08T16:45:56.231+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.filter_by_region manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
[2025-09-08T16:45:56.232+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.filter_by_region manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:45:56.232+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='filter_by_region', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T16:45:56.233+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'filter_by_region', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:45:56.237+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'filter_by_region', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:45:57.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:45:57.886+0000] {task_command.py:467} INFO - Running <TaskInstance: branching_pipeline.filter_by_region manual__2025-09-08T16:45:47.011336+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:45:58.464+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='filter_by_region', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1)
[2025-09-08T16:45:58.467+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=filter_by_region, run_id=manual__2025-09-08T16:45:47.011336+00:00, map_index=-1, run_start_date=2025-09-08 16:45:57.924482+00:00, run_end_date=2025-09-08 16:45:58.084108+00:00, run_duration=0.159626, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=97, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:45:56.231742+00:00, queued_by_job_id=85, pid=9028
[2025-09-08T16:45:58.622+0000] {dagrun.py:854} INFO - Marking run <DagRun branching_pipeline @ 2025-09-08 16:45:47.011336+00:00: manual__2025-09-08T16:45:47.011336+00:00, state:running, queued_at: 2025-09-08 16:45:47.017081+00:00. externally triggered: True> successful
[2025-09-08T16:45:58.623+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=branching_pipeline, execution_date=2025-09-08 16:45:47.011336+00:00, run_id=manual__2025-09-08T16:45:47.011336+00:00, run_start_date=2025-09-08 16:45:48.473460+00:00, run_end_date=2025-09-08 16:45:58.623218+00:00, run_duration=10.149758, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 16:45:47.011336+00:00, data_interval_end=2025-09-08 16:45:47.011336+00:00, dag_hash=017ebd910dbefd69905fbd942c6d293a
[2025-09-08T16:48:06.037+0000] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-08T16:50:15.582+0000] {manager.py:537} INFO - DAG branching_pipeline is missing and will be deactivated.
[2025-09-08T16:50:15.587+0000] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-09-08T16:50:15.593+0000] {manager.py:553} INFO - Deleted DAG branching_pipeline in serialized_dag table
[2025-09-08T16:50:42.088+0000] {dag.py:4180} INFO - Setting next_dagrun for executing_branching to None, run_after=None
[2025-09-08T16:50:42.122+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: executing_branching.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:50:42.123+0000] {scheduler_job_runner.py:495} INFO - DAG executing_branching has 0/16 running and queued tasks
[2025-09-08T16:50:42.124+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_branching.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:50:42.126+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: executing_branching.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:50:42.127+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='executing_branching', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 8 and queue default
[2025-09-08T16:50:42.128+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_branching', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:50:42.132+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_branching', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:50:43.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:50:43.885+0000] {task_command.py:467} INFO - Running <TaskInstance: executing_branching.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:50:44.534+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_branching', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:50:44.537+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=executing_branching, task_id=read_csv_file, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:50:43.917713+00:00, run_end_date=2025-09-08 16:50:44.071093+00:00, run_duration=0.15338, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=98, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2025-09-08 16:50:42.125076+00:00, queued_by_job_id=85, pid=11150
[2025-09-08T16:50:45.024+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: executing_branching.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:50:45.024+0000] {scheduler_job_runner.py:495} INFO - DAG executing_branching has 0/16 running and queued tasks
[2025-09-08T16:50:45.024+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_branching.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:50:45.026+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: executing_branching.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:50:45.026+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='executing_branching', task_id='remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
[2025-09-08T16:50:45.026+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_branching', 'remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:50:45.030+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_branching', 'remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:50:46.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:50:46.719+0000] {task_command.py:467} INFO - Running <TaskInstance: executing_branching.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:50:47.325+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_branching', task_id='remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:50:47.329+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=executing_branching, task_id=remove_null_values, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:50:46.753134+00:00, run_end_date=2025-09-08 16:50:46.901799+00:00, run_duration=0.148665, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=99, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-09-08 16:50:45.025353+00:00, queued_by_job_id=85, pid=11170
[2025-09-08T16:50:47.484+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: executing_branching.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:50:47.485+0000] {scheduler_job_runner.py:495} INFO - DAG executing_branching has 0/16 running and queued tasks
[2025-09-08T16:50:47.485+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_branching.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:50:47.486+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: executing_branching.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:50:47.487+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='executing_branching', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T16:50:47.487+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_branching', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:50:47.491+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_branching', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:50:48.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:50:49.160+0000] {task_command.py:467} INFO - Running <TaskInstance: executing_branching.determine_branch scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:50:49.715+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_branching', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:50:49.718+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=executing_branching, task_id=determine_branch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:50:49.196176+00:00, run_end_date=2025-09-08 16:50:49.336110+00:00, run_duration=0.139934, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=100, pool=default_pool, queue=default, priority_weight=6, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:50:47.486213+00:00, queued_by_job_id=85, pid=11189
[2025-09-08T16:50:49.775+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: executing_branching.filter_by_southeast scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:50:49.776+0000] {scheduler_job_runner.py:495} INFO - DAG executing_branching has 0/16 running and queued tasks
[2025-09-08T16:50:49.776+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_branching.filter_by_southeast scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T16:50:49.777+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: executing_branching.filter_by_southeast scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:50:49.778+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='executing_branching', task_id='filter_by_southeast', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T16:50:49.778+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_branching', 'filter_by_southeast', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:50:49.782+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_branching', 'filter_by_southeast', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:50:51.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:50:51.569+0000] {task_command.py:467} INFO - Running <TaskInstance: executing_branching.filter_by_southeast scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:50:52.177+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_branching', task_id='filter_by_southeast', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:50:52.182+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=executing_branching, task_id=filter_by_southeast, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:50:51.605201+00:00, run_end_date=2025-09-08 16:50:51.746597+00:00, run_duration=0.141396, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=101, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:50:49.776924+00:00, queued_by_job_id=85, pid=11226
[2025-09-08T16:50:52.331+0000] {dagrun.py:854} INFO - Marking run <DagRun executing_branching @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 16:50:42.078175+00:00. externally triggered: False> successful
[2025-09-08T16:50:52.332+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=executing_branching, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 16:50:42.098183+00:00, run_end_date=2025-09-08 16:50:52.331969+00:00, run_duration=10.233786, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=2f2979667b5d51f05c44b06be49754a6
[2025-09-08T16:50:52.333+0000] {dag.py:4180} INFO - Setting next_dagrun for executing_branching to None, run_after=None
[2025-09-08T16:53:06.064+0000] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-08T16:56:18.641+0000] {manager.py:537} INFO - DAG executing_branching is missing and will be deactivated.
[2025-09-08T16:56:18.644+0000] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-09-08T16:56:18.649+0000] {manager.py:553} INFO - Deleted DAG executing_branching in serialized_dag table
[2025-09-08T16:56:54.440+0000] {dag.py:4180} INFO - Setting next_dagrun for taskgroup_and_labels_pipeline to None, run_after=None
[2025-09-08T16:56:54.477+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
[2025-09-08T16:56:54.478+0000] {scheduler_job_runner.py:495} INFO - DAG taskgroup_and_labels_pipeline has 0/16 running and queued tasks
[2025-09-08T16:56:54.478+0000] {scheduler_job_runner.py:495} INFO - DAG taskgroup_and_labels_pipeline has 1/16 running and queued tasks
[2025-09-08T16:56:54.479+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
[2025-09-08T16:56:54.481+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:56:54.481+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T16:56:54.481+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:56:54.482+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.read_csv_file', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T16:56:54.482+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.read_csv_file', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:56:54.487+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:56:55.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:56:56.306+0000] {task_command.py:467} INFO - Running <TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:56:57.033+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.read_csv_file', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:56:58.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:56:58.768+0000] {task_command.py:467} INFO - Running <TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file manual__2025-09-08T16:56:53.736348+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:56:59.374+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:56:59.374+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.read_csv_file', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1)
[2025-09-08T16:56:59.380+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Reading_and_Preprocessing.read_csv_file, run_id=manual__2025-09-08T16:56:53.736348+00:00, map_index=-1, run_start_date=2025-09-08 16:56:58.807067+00:00, run_end_date=2025-09-08 16:56:58.946975+00:00, run_duration=0.139908, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=103, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:56:54.479841+00:00, queued_by_job_id=85, pid=14075
[2025-09-08T16:56:59.380+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Reading_and_Preprocessing.read_csv_file, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:56:56.339013+00:00, run_end_date=2025-09-08 16:56:56.493270+00:00, run_duration=0.154257, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=102, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:56:54.479841+00:00, queued_by_job_id=85, pid=14039
[2025-09-08T16:56:59.558+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
[2025-09-08T16:56:59.558+0000] {scheduler_job_runner.py:495} INFO - DAG taskgroup_and_labels_pipeline has 0/16 running and queued tasks
[2025-09-08T16:56:59.559+0000] {scheduler_job_runner.py:495} INFO - DAG taskgroup_and_labels_pipeline has 1/16 running and queued tasks
[2025-09-08T16:56:59.559+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
[2025-09-08T16:56:59.560+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:56:59.561+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T16:56:59.561+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:56:59.561+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.remove_null_values', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T16:56:59.562+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.remove_null_values', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:56:59.566+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:00.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:57:01.221+0000] {task_command.py:467} INFO - Running <TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:57:01.823+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.remove_null_values', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:03.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:57:03.496+0000] {task_command.py:467} INFO - Running <TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values manual__2025-09-08T16:56:53.736348+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:57:04.131+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:57:04.131+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.remove_null_values', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1)
[2025-09-08T16:57:04.135+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Reading_and_Preprocessing.remove_null_values, run_id=manual__2025-09-08T16:56:53.736348+00:00, map_index=-1, run_start_date=2025-09-08 16:57:03.535570+00:00, run_end_date=2025-09-08 16:57:03.702562+00:00, run_duration=0.166992, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=105, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:56:59.559848+00:00, queued_by_job_id=85, pid=14107
[2025-09-08T16:57:04.135+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Reading_and_Preprocessing.remove_null_values, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:57:01.255183+00:00, run_end_date=2025-09-08 16:57:01.418308+00:00, run_duration=0.163125, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=104, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:56:59.559848+00:00, queued_by_job_id=85, pid=14089
[2025-09-08T16:57:04.295+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: taskgroup_and_labels_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.determine_branch manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
[2025-09-08T16:57:04.295+0000] {scheduler_job_runner.py:495} INFO - DAG taskgroup_and_labels_pipeline has 0/16 running and queued tasks
[2025-09-08T16:57:04.295+0000] {scheduler_job_runner.py:495} INFO - DAG taskgroup_and_labels_pipeline has 1/16 running and queued tasks
[2025-09-08T16:57:04.296+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: taskgroup_and_labels_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.determine_branch manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
[2025-09-08T16:57:04.297+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: taskgroup_and_labels_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: taskgroup_and_labels_pipeline.determine_branch manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:57:04.297+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T16:57:04.298+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:04.298+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T16:57:04.298+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'determine_branch', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:04.303+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:05.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:57:05.908+0000] {task_command.py:467} INFO - Running <TaskInstance: taskgroup_and_labels_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:57:06.488+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'determine_branch', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:07.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:57:08.318+0000] {task_command.py:467} INFO - Running <TaskInstance: taskgroup_and_labels_pipeline.determine_branch manual__2025-09-08T16:56:53.736348+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:57:08.929+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:57:08.930+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1)
[2025-09-08T16:57:08.933+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=determine_branch, run_id=manual__2025-09-08T16:56:53.736348+00:00, map_index=-1, run_start_date=2025-09-08 16:57:08.353054+00:00, run_end_date=2025-09-08 16:57:08.517736+00:00, run_duration=0.164682, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=107, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:57:04.296526+00:00, queued_by_job_id=85, pid=14162
[2025-09-08T16:57:08.934+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=determine_branch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:57:05.942739+00:00, run_end_date=2025-09-08 16:57:06.103068+00:00, run_duration=0.160329, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=106, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:57:04.296526+00:00, queued_by_job_id=85, pid=14120
[2025-09-08T16:57:09.504+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
[2025-09-08T16:57:09.504+0000] {scheduler_job_runner.py:495} INFO - DAG taskgroup_and_labels_pipeline has 0/16 running and queued tasks
[2025-09-08T16:57:09.504+0000] {scheduler_job_runner.py:495} INFO - DAG taskgroup_and_labels_pipeline has 1/16 running and queued tasks
[2025-09-08T16:57:09.505+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
[2025-09-08T16:57:09.506+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T16:57:09.507+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Filtering.filter_by_region', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T16:57:09.507+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Filtering.filter_by_region', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:09.507+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Filtering.filter_by_region', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T16:57:09.508+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Filtering.filter_by_region', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:09.512+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Filtering.filter_by_region', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:10.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:57:11.166+0000] {task_command.py:467} INFO - Running <TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:57:11.711+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Filtering.filter_by_region', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
[2025-09-08T16:57:12.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_branching_pipeline.py
[2025-09-08T16:57:13.388+0000] {task_command.py:467} INFO - Running <TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region manual__2025-09-08T16:56:53.736348+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T16:57:14.004+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Filtering.filter_by_region', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T16:57:14.004+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Filtering.filter_by_region', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1)
[2025-09-08T16:57:14.009+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Filtering.filter_by_region, run_id=manual__2025-09-08T16:56:53.736348+00:00, map_index=-1, run_start_date=2025-09-08 16:57:13.424892+00:00, run_end_date=2025-09-08 16:57:13.583399+00:00, run_duration=0.158507, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=109, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:57:09.505792+00:00, queued_by_job_id=85, pid=14189
[2025-09-08T16:57:14.010+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Filtering.filter_by_region, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:57:11.202210+00:00, run_end_date=2025-09-08 16:57:11.340103+00:00, run_duration=0.137893, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=108, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:57:09.505792+00:00, queued_by_job_id=85, pid=14177
[2025-09-08T16:57:14.568+0000] {dagrun.py:854} INFO - Marking run <DagRun taskgroup_and_labels_pipeline @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 16:56:54.437018+00:00. externally triggered: False> successful
[2025-09-08T16:57:14.568+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=taskgroup_and_labels_pipeline, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 16:56:54.450135+00:00, run_end_date=2025-09-08 16:57:14.568504+00:00, run_duration=20.118369, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=a2f56e96da3fac730cdc84e09782986d
[2025-09-08T16:57:14.570+0000] {dag.py:4180} INFO - Setting next_dagrun for taskgroup_and_labels_pipeline to None, run_after=None
[2025-09-08T16:57:14.572+0000] {dagrun.py:854} INFO - Marking run <DagRun taskgroup_and_labels_pipeline @ 2025-09-08 16:56:53.736348+00:00: manual__2025-09-08T16:56:53.736348+00:00, state:running, queued_at: 2025-09-08 16:56:53.748070+00:00. externally triggered: True> successful
[2025-09-08T16:57:14.572+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=taskgroup_and_labels_pipeline, execution_date=2025-09-08 16:56:53.736348+00:00, run_id=manual__2025-09-08T16:56:53.736348+00:00, run_start_date=2025-09-08 16:56:54.450184+00:00, run_end_date=2025-09-08 16:57:14.572665+00:00, run_duration=20.122481, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 16:56:53.736348+00:00, data_interval_end=2025-09-08 16:56:53.736348+00:00, dag_hash=a2f56e96da3fac730cdc84e09782986d
[2025-09-08T16:58:06.108+0000] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-08T17:01:34.182+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-04 00:00:00+00:00, run_after=2025-09-05 00:00:00+00:00
[2025-09-08T17:01:34.212+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:34.212+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:01:34.213+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:34.214+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:01:34.214+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:01:34.214+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:34.219+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:35.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:35.578+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-03T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:36.066+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:36.071+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:35.610987+00:00, run_end_date=2025-09-08 17:01:35.743979+00:00, run_duration=0.132992, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:34.213513+00:00, queued_by_job_id=85, pid=16221
[2025-09-08T17:01:36.126+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-05 00:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
[2025-09-08T17:01:36.158+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:36.158+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:01:36.158+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:01:36.159+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:36.160+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-04T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:01:36.161+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:01:36.161+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:36.161+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:01:36.162+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:36.166+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:37.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:37.659+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-04T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:38.133+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:39.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:39.535+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-03T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:40.043+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:40.043+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:40.047+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:39.568725+00:00, run_end_date=2025-09-08 17:01:39.684018+00:00, run_duration=0.115293, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:01:36.159837+00:00, queued_by_job_id=85, pid=16250
[2025-09-08T17:01:40.047+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:37.695163+00:00, run_end_date=2025-09-08 17:01:37.821796+00:00, run_duration=0.126633, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:36.159837+00:00, queued_by_job_id=85, pid=16239
[2025-09-08T17:01:40.211+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-07 00:00:00+00:00
[2025-09-08T17:01:40.248+0000] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:40.248+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:01:40.248+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:01:40.249+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:01:40.249+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:40.251+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-05T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-04T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:01:40.252+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:01:40.252+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:40.252+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:01:40.253+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:40.253+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:01:40.253+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:40.259+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:41.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:41.660+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-05T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:42.262+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:43.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:43.668+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-04T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:44.148+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:45.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:45.551+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-03T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:46.072+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:46.072+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:46.073+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:46.079+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:45.583924+00:00, run_end_date=2025-09-08 17:01:45.717279+00:00, run_duration=0.133355, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=115, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:01:40.250227+00:00, queued_by_job_id=85, pid=16307
[2025-09-08T17:01:46.079+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:41.692953+00:00, run_end_date=2025-09-08 17:01:41.833832+00:00, run_duration=0.140879, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:40.250227+00:00, queued_by_job_id=85, pid=16269
[2025-09-08T17:01:46.080+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:43.701970+00:00, run_end_date=2025-09-08 17:01:43.822114+00:00, run_duration=0.120144, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:01:40.250227+00:00, queued_by_job_id=85, pid=16297
[2025-09-08T17:01:46.127+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
[2025-09-08T17:01:46.162+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-03 00:00:00+00:00: scheduled__2025-09-03T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:34.178510+00:00. externally triggered: False> successful
[2025-09-08T17:01:46.162+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-03 00:00:00+00:00, run_id=scheduled__2025-09-03T00:00:00+00:00, run_start_date=2025-09-08 17:01:34.192959+00:00, run_end_date=2025-09-08 17:01:46.162836+00:00, run_duration=11.969877, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-03 00:00:00+00:00, data_interval_end=2025-09-04 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
[2025-09-08T17:01:46.165+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-04 00:00:00+00:00, run_after=2025-09-05 00:00:00+00:00
[2025-09-08T17:01:46.176+0000] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:46.176+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:01:46.177+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:01:46.177+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:01:46.177+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:46.179+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-05T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:01:46.179+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:01:46.180+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:46.180+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:01:46.180+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:46.181+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:01:46.181+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:46.186+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:47.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:47.909+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:48.563+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:49.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:50.051+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-05T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:50.546+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:51.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:51.942+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-04T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:52.623+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:52.623+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:52.624+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:01:52.627+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:50.087933+00:00, run_end_date=2025-09-08 17:01:50.211184+00:00, run_duration=0.123251, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=117, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:01:46.178422+00:00, queued_by_job_id=85, pid=16337
[2025-09-08T17:01:52.628+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:51.980027+00:00, run_end_date=2025-09-08 17:01:52.176816+00:00, run_duration=0.196789, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=118, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:01:46.178422+00:00, queued_by_job_id=85, pid=16348
[2025-09-08T17:01:52.628+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:47.945394+00:00, run_end_date=2025-09-08 17:01:48.081145+00:00, run_duration=0.135751, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=116, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:46.178422+00:00, queued_by_job_id=85, pid=16325
[2025-09-08T17:01:52.785+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
[2025-09-08T17:01:52.851+0000] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:52.851+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:01:52.852+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:01:52.852+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:01:52.853+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 3/16 running and queued tasks
[2025-09-08T17:01:52.853+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
[2025-09-08T17:01:52.858+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-05T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:01:52.858+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:01:52.859+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:52.860+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:01:52.860+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:52.861+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:01:52.861+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:52.862+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:01:52.863+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:52.868+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:54.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:54.307+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:54.799+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:56.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:56.334+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:56.987+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:01:58.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:01:58.499+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-05T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:01:59.067+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:00.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:00.484+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-04T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:00.997+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:00.997+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:00.997+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:00.998+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:01.004+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:56.371427+00:00, run_end_date=2025-09-08 17:01:56.491630+00:00, run_duration=0.120203, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=120, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:01:52.855076+00:00, queued_by_job_id=85, pid=16395
[2025-09-08T17:02:01.004+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:00.525492+00:00, run_end_date=2025-09-08 17:02:00.639581+00:00, run_duration=0.114089, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=122, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:01:52.855076+00:00, queued_by_job_id=85, pid=16423
[2025-09-08T17:02:01.005+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:58.537791+00:00, run_end_date=2025-09-08 17:01:58.695781+00:00, run_duration=0.15799, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=121, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:01:52.855076+00:00, queued_by_job_id=85, pid=16412
[2025-09-08T17:02:01.005+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:54.343282+00:00, run_end_date=2025-09-08 17:01:54.475309+00:00, run_duration=0.132027, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=119, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:52.855076+00:00, queued_by_job_id=85, pid=16383
[2025-09-08T17:02:01.583+0000] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
[2025-09-08T17:02:01.584+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:02:01.584+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:02:01.584+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:02:01.585+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 3/16 running and queued tasks
[2025-09-08T17:02:01.585+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
[2025-09-08T17:02:01.587+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-05T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:02:01.587+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:02:01.587+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:01.588+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:02:01.588+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:01.588+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:02:01.589+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:01.589+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:02:01.589+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:01.594+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:02.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:03.154+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:03.732+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:04.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:05.196+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:05.752+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:06.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:07.142+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-05T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:07.685+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:08.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:09.128+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-04T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:09.722+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:09.723+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:09.723+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:09.723+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:09.727+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:05.235088+00:00, run_end_date=2025-09-08 17:02:05.399226+00:00, run_duration=0.164138, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=124, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:02:01.586088+00:00, queued_by_job_id=85, pid=16472
[2025-09-08T17:02:09.728+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:09.166810+00:00, run_end_date=2025-09-08 17:02:09.305741+00:00, run_duration=0.138931, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:02:01.586088+00:00, queued_by_job_id=85, pid=16494
[2025-09-08T17:02:09.728+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:07.182417+00:00, run_end_date=2025-09-08 17:02:07.296810+00:00, run_duration=0.114393, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=125, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:02:01.586088+00:00, queued_by_job_id=85, pid=16483
[2025-09-08T17:02:09.729+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:03.192337+00:00, run_end_date=2025-09-08 17:02:03.334761+00:00, run_duration=0.142424, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=123, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:02:01.586088+00:00, queued_by_job_id=85, pid=16455
[2025-09-08T17:02:10.331+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-04 00:00:00+00:00: scheduled__2025-09-04T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:36.122509+00:00. externally triggered: False> successful
[2025-09-08T17:02:10.332+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-04 00:00:00+00:00, run_id=scheduled__2025-09-04T00:00:00+00:00, run_start_date=2025-09-08 17:01:36.135943+00:00, run_end_date=2025-09-08 17:02:10.332352+00:00, run_duration=34.196409, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-04 00:00:00+00:00, data_interval_end=2025-09-05 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
[2025-09-08T17:02:10.335+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-05 00:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
[2025-09-08T17:02:10.344+0000] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
[2025-09-08T17:02:10.345+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:02:10.345+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:02:10.345+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:02:10.346+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
[2025-09-08T17:02:10.347+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:02:10.348+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:02:10.348+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:10.348+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:02:10.349+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:10.349+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:02:10.349+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:10.354+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:11.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:11.796+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:12.302+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:13.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:13.865+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-06T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:14.369+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:15.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:15.878+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-05T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:16.406+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:16.406+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:16.407+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:16.410+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:13.905124+00:00, run_end_date=2025-09-08 17:02:14.020026+00:00, run_duration=0.114902, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:02:10.346939+00:00, queued_by_job_id=85, pid=16550
[2025-09-08T17:02:16.411+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:15.917917+00:00, run_end_date=2025-09-08 17:02:16.059660+00:00, run_duration=0.141743, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:02:10.346939+00:00, queued_by_job_id=85, pid=16567
[2025-09-08T17:02:16.411+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:11.836223+00:00, run_end_date=2025-09-08 17:02:11.972607+00:00, run_duration=0.136384, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:02:10.346939+00:00, queued_by_job_id=85, pid=16521
[2025-09-08T17:02:16.561+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-07 00:00:00+00:00
[2025-09-08T17:02:16.578+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-05 00:00:00+00:00: scheduled__2025-09-05T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:40.201500+00:00. externally triggered: False> successful
[2025-09-08T17:02:16.579+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-05 00:00:00+00:00, run_id=scheduled__2025-09-05T00:00:00+00:00, run_start_date=2025-09-08 17:01:40.221338+00:00, run_end_date=2025-09-08 17:02:16.579242+00:00, run_duration=36.357904, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-05 00:00:00+00:00, data_interval_end=2025-09-06 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
[2025-09-08T17:02:16.582+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-07 00:00:00+00:00
[2025-09-08T17:02:16.590+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
[2025-09-08T17:02:16.591+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:02:16.591+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:02:16.591+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
[2025-09-08T17:02:16.593+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:02:16.593+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:02:16.594+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:16.594+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:02:16.594+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:16.598+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:17.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:18.124+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:18.682+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:20.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:20.185+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-06T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:20.733+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:20.734+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:20.737+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:20.223833+00:00, run_end_date=2025-09-08 17:02:20.386408+00:00, run_duration=0.162575, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:02:16.592388+00:00, queued_by_job_id=85, pid=16591
[2025-09-08T17:02:20.738+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:18.168061+00:00, run_end_date=2025-09-08 17:02:18.286704+00:00, run_duration=0.118643, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:02:16.592388+00:00, queued_by_job_id=85, pid=16580
[2025-09-08T17:02:20.892+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
[2025-09-08T17:02:20.907+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-06 00:00:00+00:00: scheduled__2025-09-06T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:46.123409+00:00. externally triggered: False> successful
[2025-09-08T17:02:20.908+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-06 00:00:00+00:00, run_id=scheduled__2025-09-06T00:00:00+00:00, run_start_date=2025-09-08 17:01:46.138584+00:00, run_end_date=2025-09-08 17:02:20.908004+00:00, run_duration=34.76942, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
[2025-09-08T17:02:20.910+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
[2025-09-08T17:02:20.919+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:02:20.920+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:02:20.920+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:02:20.921+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:02:20.922+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:02:20.922+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:20.926+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:02:22.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:02:22.369+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:02:22.890+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:02:22.893+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:22.407195+00:00, run_end_date=2025-09-08 17:02:22.544644+00:00, run_duration=0.137449, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=132, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:02:20.920961+00:00, queued_by_job_id=85, pid=16610
[2025-09-08T17:02:23.181+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
[2025-09-08T17:02:23.192+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:52.780375+00:00. externally triggered: False> successful
[2025-09-08T17:02:23.192+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 17:01:52.800996+00:00, run_end_date=2025-09-08 17:02:23.192863+00:00, run_duration=30.391867, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
[2025-09-08T17:02:23.195+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
[2025-09-08T17:03:06.136+0000] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-08T17:03:43.537+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-09 12:00:00+00:00, run_after=2025-08-16 00:00:00+00:00
[2025-09-08T17:03:43.566+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:03:43.567+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:03:43.567+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:03:43.568+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:03:43.569+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:03:43.569+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:43.574+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:44.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:03:45.122+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:03:45.620+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:03:45.623+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:45.156129+00:00, run_end_date=2025-09-08 17:03:45.284506+00:00, run_duration=0.128377, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:03:43.568067+00:00, queued_by_job_id=85, pid=17253
[2025-09-08T17:03:45.667+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 00:00:00+00:00, run_after=2025-08-16 12:00:00+00:00
[2025-09-08T17:03:45.699+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:03:45.699+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:03:45.700+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:03:45.700+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:03:45.701+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:03:45.702+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:03:45.702+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:45.703+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:03:45.703+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:45.707+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:46.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:03:47.092+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:03:47.629+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:48.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:03:49.138+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:03:49.638+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:03:49.638+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:03:49.642+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:49.181621+00:00, run_end_date=2025-09-08 17:03:49.305457+00:00, run_duration=0.123836, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:03:45.701185+00:00, queued_by_job_id=85, pid=17282
[2025-09-08T17:03:49.642+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-09T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:47.149834+00:00, run_end_date=2025-09-08 17:03:47.278793+00:00, run_duration=0.128959, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:03:45.701185+00:00, queued_by_job_id=85, pid=17265
[2025-09-08T17:03:49.783+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 12:00:00+00:00, run_after=2025-08-23 00:00:00+00:00
[2025-09-08T17:03:49.818+0000] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:03:49.818+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:03:49.818+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:03:49.819+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:03:49.819+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:03:49.821+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:03:49.821+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:03:49.821+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:49.822+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:03:49.822+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:49.822+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:03:49.823+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:49.827+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:51.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:03:51.254+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:03:51.748+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:52.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:03:53.164+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:03:53.771+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:55.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:03:55.357+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:03:55.897+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:03:55.897+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:03:55.897+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:03:55.901+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:55.391312+00:00, run_end_date=2025-09-08 17:03:55.528495+00:00, run_duration=0.137183, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=115, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:03:49.820059+00:00, queued_by_job_id=85, pid=17340
[2025-09-08T17:03:55.902+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:51.287717+00:00, run_end_date=2025-09-08 17:03:51.414413+00:00, run_duration=0.126696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:03:49.820059+00:00, queued_by_job_id=85, pid=17294
[2025-09-08T17:03:55.902+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-09T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:53.200005+00:00, run_end_date=2025-09-08 17:03:53.321442+00:00, run_duration=0.121437, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:03:49.820059+00:00, queued_by_job_id=85, pid=17306
[2025-09-08T17:03:56.059+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 00:00:00+00:00, run_after=2025-08-23 12:00:00+00:00
[2025-09-08T17:03:56.100+0000] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:03:56.100+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:03:56.100+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:03:56.101+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:03:56.101+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 3/16 running and queued tasks
[2025-09-08T17:03:56.101+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:03:56.103+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:03:56.103+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:03:56.104+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:56.104+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:03:56.104+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:56.105+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:03:56.105+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:56.105+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:03:56.106+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:56.110+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:57.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:03:57.546+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:03:58.031+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:03:59.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:03:59.567+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:00.088+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:01.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:01.489+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:02.002+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:03.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:03.403+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-09T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:03.925+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:03.925+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:03.926+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:03.926+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:03.930+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-16T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:57.580384+00:00, run_end_date=2025-09-08 17:03:57.713366+00:00, run_duration=0.132982, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=116, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:03:56.102559+00:00, queued_by_job_id=85, pid=17352
[2025-09-08T17:04:03.930+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:03.441979+00:00, run_end_date=2025-09-08 17:04:03.551263+00:00, run_duration=0.109284, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=119, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:03:56.102559+00:00, queued_by_job_id=85, pid=17392
[2025-09-08T17:04:03.931+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:59.613203+00:00, run_end_date=2025-09-08 17:03:59.745651+00:00, run_duration=0.132448, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=117, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:03:56.102559+00:00, queued_by_job_id=85, pid=17370
[2025-09-08T17:04:03.931+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-09T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:01.524716+00:00, run_end_date=2025-09-08 17:04:01.664139+00:00, run_duration=0.139423, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=118, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:03:56.102559+00:00, queued_by_job_id=85, pid=17381
[2025-09-08T17:04:04.083+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 12:00:00+00:00, run_after=2025-08-30 00:00:00+00:00
[2025-09-08T17:04:04.113+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-09 12:00:00+00:00: scheduled__2025-08-09T12:00:00+00:00, state:running, queued_at: 2025-09-08 17:03:45.663853+00:00. externally triggered: False> successful
[2025-09-08T17:04:04.114+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-09 12:00:00+00:00, run_id=scheduled__2025-08-09T12:00:00+00:00, run_start_date=2025-09-08 17:03:45.676899+00:00, run_end_date=2025-09-08 17:04:04.114070+00:00, run_duration=18.437171, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-09 12:00:00+00:00, data_interval_end=2025-08-16 00:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:04.116+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 00:00:00+00:00, run_after=2025-08-16 12:00:00+00:00
[2025-09-08T17:04:04.128+0000] {scheduler_job_runner.py:423} INFO - 4 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:04.128+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:04.129+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:04.129+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:04:04.129+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 3/16 running and queued tasks
[2025-09-08T17:04:04.130+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:04.131+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:04.132+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:04:04.132+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:04.132+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:04:04.133+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:04.133+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:04:04.133+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:04.134+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:04:04.134+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:04.139+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:05.580+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:05.749+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:06.285+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:07.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:07.686+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:08.172+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:09.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:09.611+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:10.144+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:11.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:11.614+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-09T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:12.122+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:12.122+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:12.122+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:12.123+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:12.127+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-16T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:07.724293+00:00, run_end_date=2025-09-08 17:04:07.851092+00:00, run_duration=0.126799, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=121, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:04.130871+00:00, queued_by_job_id=85, pid=17438
[2025-09-08T17:04:12.127+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:11.649566+00:00, run_end_date=2025-09-08 17:04:11.780565+00:00, run_duration=0.130999, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=123, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:04:04.130871+00:00, queued_by_job_id=85, pid=17466
[2025-09-08T17:04:12.128+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:05.793486+00:00, run_end_date=2025-09-08 17:04:05.948979+00:00, run_duration=0.155493, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=120, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:04.130871+00:00, queued_by_job_id=85, pid=17426
[2025-09-08T17:04:12.128+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:09.647447+00:00, run_end_date=2025-09-08 17:04:09.782820+00:00, run_duration=0.135373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=122, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:04.130871+00:00, queued_by_job_id=85, pid=17449
[2025-09-08T17:04:12.294+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 00:00:00+00:00, run_after=2025-08-30 12:00:00+00:00
[2025-09-08T17:04:12.325+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-16 00:00:00+00:00: scheduled__2025-08-16T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:03:49.779832+00:00. externally triggered: False> successful
[2025-09-08T17:04:12.325+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-16 00:00:00+00:00, run_id=scheduled__2025-08-16T00:00:00+00:00, run_start_date=2025-09-08 17:03:49.792629+00:00, run_end_date=2025-09-08 17:04:12.325943+00:00, run_duration=22.533314, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-16 00:00:00+00:00, data_interval_end=2025-08-16 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:12.328+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 12:00:00+00:00, run_after=2025-08-23 00:00:00+00:00
[2025-09-08T17:04:12.330+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-09 00:00:00+00:00: scheduled__2025-08-09T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:03:43.533483+00:00. externally triggered: False> successful
[2025-09-08T17:04:12.331+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-09 00:00:00+00:00, run_id=scheduled__2025-08-09T00:00:00+00:00, run_start_date=2025-09-08 17:03:43.546655+00:00, run_end_date=2025-09-08 17:04:12.331177+00:00, run_duration=28.784522, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-09 00:00:00+00:00, data_interval_end=2025-08-09 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:12.335+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-09 12:00:00+00:00, run_after=2025-08-16 00:00:00+00:00
[2025-09-08T17:04:12.347+0000] {scheduler_job_runner.py:423} INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:12.348+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:12.348+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:12.348+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
[2025-09-08T17:04:12.349+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:12.351+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:12.352+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:04:12.352+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:12.352+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:04:12.353+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:12.353+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:04:12.354+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:12.358+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:13.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:13.779+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:14.270+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:15.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:15.896+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:16.416+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:17.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:17.819+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:18.309+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:18.310+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:18.310+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:18.314+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-16T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:17.856549+00:00, run_end_date=2025-09-08 17:04:17.993423+00:00, run_duration=0.136874, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:12.350158+00:00, queued_by_job_id=85, pid=17524
[2025-09-08T17:04:18.314+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:15.954140+00:00, run_end_date=2025-09-08 17:04:16.083263+00:00, run_duration=0.129123, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=125, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:12.350158+00:00, queued_by_job_id=85, pid=17514
[2025-09-08T17:04:18.315+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:13.816434+00:00, run_end_date=2025-09-08 17:04:13.952053+00:00, run_duration=0.135619, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=124, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:12.350158+00:00, queued_by_job_id=85, pid=17479
[2025-09-08T17:04:18.874+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 00:00:00+00:00, run_after=2025-08-16 12:00:00+00:00
[2025-09-08T17:04:18.901+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-16 12:00:00+00:00: scheduled__2025-08-16T12:00:00+00:00, state:running, queued_at: 2025-09-08 17:03:56.055671+00:00. externally triggered: False> successful
[2025-09-08T17:04:18.901+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-16 12:00:00+00:00, run_id=scheduled__2025-08-16T12:00:00+00:00, run_start_date=2025-09-08 17:03:56.069197+00:00, run_end_date=2025-09-08 17:04:18.901674+00:00, run_duration=22.832477, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-16 12:00:00+00:00, data_interval_end=2025-08-23 00:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:18.904+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 00:00:00+00:00, run_after=2025-08-23 12:00:00+00:00
[2025-09-08T17:04:18.913+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:18.913+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:18.914+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:18.914+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:18.916+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:18.917+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:04:18.917+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:18.918+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:04:18.918+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:18.922+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:20.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:20.407+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:20.887+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:22.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:22.374+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:22.891+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:22.891+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:22.895+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:22.413867+00:00, run_end_date=2025-09-08 17:04:22.547866+00:00, run_duration=0.133999, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:18.915561+00:00, queued_by_job_id=85, pid=17555
[2025-09-08T17:04:22.895+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:20.444828+00:00, run_end_date=2025-09-08 17:04:20.563447+00:00, run_duration=0.118619, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:18.915561+00:00, queued_by_job_id=85, pid=17538
[2025-09-08T17:04:23.038+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 12:00:00+00:00, run_after=2025-08-30 00:00:00+00:00
[2025-09-08T17:04:23.063+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:23.063+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:23.064+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:23.064+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:23.065+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:23.066+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:04:23.066+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:23.067+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:04:23.067+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:23.071+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:24.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:24.424+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:24.999+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:26.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:26.524+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:27.060+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:27.061+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:27.064+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:26.579369+00:00, run_end_date=2025-09-08 17:04:26.692299+00:00, run_duration=0.11293, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:04:23.065162+00:00, queued_by_job_id=85, pid=17602
[2025-09-08T17:04:27.065+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:24.461605+00:00, run_end_date=2025-09-08 17:04:24.606499+00:00, run_duration=0.144894, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:23.065162+00:00, queued_by_job_id=85, pid=17567
[2025-09-08T17:04:27.214+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 00:00:00+00:00, run_after=2025-08-30 12:00:00+00:00
[2025-09-08T17:04:27.238+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:27.239+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:27.239+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:27.239+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:27.241+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:27.241+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:04:27.241+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:27.242+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:04:27.242+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:27.246+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:28.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:28.743+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:29.261+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:30.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:30.712+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:31.196+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:31.196+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:31.200+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:30.749920+00:00, run_end_date=2025-09-08 17:04:30.884797+00:00, run_duration=0.134877, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=132, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:04:27.240377+00:00, queued_by_job_id=85, pid=17629
[2025-09-08T17:04:31.200+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:28.786698+00:00, run_end_date=2025-09-08 17:04:28.900140+00:00, run_duration=0.113442, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:04:27.240377+00:00, queued_by_job_id=85, pid=17618
[2025-09-08T17:04:31.447+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 12:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
[2025-09-08T17:04:31.475+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-23 00:00:00+00:00: scheduled__2025-08-23T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:04.079636+00:00. externally triggered: False> successful
[2025-09-08T17:04:31.476+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-23 00:00:00+00:00, run_id=scheduled__2025-08-23T00:00:00+00:00, run_start_date=2025-09-08 17:04:04.093209+00:00, run_end_date=2025-09-08 17:04:31.476148+00:00, run_duration=27.382939, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-23 00:00:00+00:00, data_interval_end=2025-08-23 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:31.478+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 12:00:00+00:00, run_after=2025-08-30 00:00:00+00:00
[2025-09-08T17:04:31.488+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:31.488+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:31.489+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:31.489+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:31.490+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:31.491+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:04:31.491+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:31.492+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:04:31.492+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:31.496+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:32.759+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:32.934+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:33.497+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:34.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:34.922+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:35.420+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:35.420+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:35.424+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:32.974095+00:00, run_end_date=2025-09-08 17:04:33.127018+00:00, run_duration=0.152923, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=133, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:31.490086+00:00, queued_by_job_id=85, pid=17648
[2025-09-08T17:04:35.425+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:34.960377+00:00, run_end_date=2025-09-08 17:04:35.092193+00:00, run_duration=0.131816, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=134, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:04:31.490086+00:00, queued_by_job_id=85, pid=17660
[2025-09-08T17:04:36.079+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 00:00:00+00:00, run_after=2025-08-30 12:00:00+00:00
[2025-09-08T17:04:36.094+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-23 12:00:00+00:00: scheduled__2025-08-23T12:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:12.289239+00:00. externally triggered: False> successful
[2025-09-08T17:04:36.095+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-23 12:00:00+00:00, run_id=scheduled__2025-08-23T12:00:00+00:00, run_start_date=2025-09-08 17:04:12.305334+00:00, run_end_date=2025-09-08 17:04:36.095342+00:00, run_duration=23.790008, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-23 12:00:00+00:00, data_interval_end=2025-08-30 00:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:36.098+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 00:00:00+00:00, run_after=2025-08-30 12:00:00+00:00
[2025-09-08T17:04:36.107+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:36.107+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:36.108+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:36.109+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:36.109+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:04:36.110+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:36.114+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:37.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:37.544+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:38.082+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:38.085+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:37.608323+00:00, run_end_date=2025-09-08 17:04:37.730998+00:00, run_duration=0.122675, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=135, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:36.108557+00:00, queued_by_job_id=85, pid=17703
[2025-09-08T17:04:38.226+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 12:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
[2025-09-08T17:04:38.248+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:38.249+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:38.249+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
[2025-09-08T17:04:38.250+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:38.251+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:04:38.251+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:38.255+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:39.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:39.627+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:40.191+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:40.195+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:39.665026+00:00, run_end_date=2025-09-08 17:04:39.822956+00:00, run_duration=0.15793, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=136, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:38.249993+00:00, queued_by_job_id=85, pid=17715
[2025-09-08T17:04:40.340+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-06 12:00:00+00:00
[2025-09-08T17:04:40.363+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-30 00:00:00+00:00: scheduled__2025-08-30T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:31.443393+00:00. externally triggered: False> successful
[2025-09-08T17:04:40.363+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-30 00:00:00+00:00, run_id=scheduled__2025-08-30T00:00:00+00:00, run_start_date=2025-09-08 17:04:31.459322+00:00, run_end_date=2025-09-08 17:04:40.363932+00:00, run_duration=8.90461, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-30 00:00:00+00:00, data_interval_end=2025-08-30 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:40.366+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 12:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
[2025-09-08T17:04:40.375+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:40.376+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:40.376+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:40.377+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:40.378+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:04:40.378+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:40.382+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:41.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:41.785+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:42.265+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:42.268+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:41.821881+00:00, run_end_date=2025-09-08 17:04:41.954799+00:00, run_duration=0.132918, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=137, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:40.377105+00:00, queued_by_job_id=85, pid=17727
[2025-09-08T17:04:42.422+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
[2025-09-08T17:04:42.456+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:42.456+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:42.457+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:42.457+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:42.458+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:42.459+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:04:42.459+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:42.460+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:04:42.460+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:42.464+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:43.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:43.905+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:44.412+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:45.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:45.864+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:46.448+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:46.448+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:46.452+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:45.935059+00:00, run_end_date=2025-09-08 17:04:46.108298+00:00, run_duration=0.173239, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=139, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:42.458056+00:00, queued_by_job_id=85, pid=17765
[2025-09-08T17:04:46.452+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:43.966715+00:00, run_end_date=2025-09-08 17:04:44.099927+00:00, run_duration=0.133212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=138, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:42.458056+00:00, queued_by_job_id=85, pid=17746
[2025-09-08T17:04:46.511+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:46.511+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:46.511+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:46.512+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:46.513+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:46.513+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:04:46.514+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:46.514+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:04:46.514+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:46.519+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:47.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:47.970+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:48.444+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:49.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:49.915+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:50.452+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:50.452+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:50.456+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:49.952822+00:00, run_end_date=2025-09-08 17:04:50.088153+00:00, run_duration=0.135331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=141, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:46.512648+00:00, queued_by_job_id=85, pid=17804
[2025-09-08T17:04:50.456+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:48.007204+00:00, run_end_date=2025-09-08 17:04:48.126992+00:00, run_duration=0.119788, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=140, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:46.512648+00:00, queued_by_job_id=85, pid=17787
[2025-09-08T17:04:51.029+0000] {scheduler_job_runner.py:423} INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:51.029+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:51.030+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
[2025-09-08T17:04:51.030+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:51.031+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:51.032+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:04:51.032+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:51.033+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:04:51.033+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:51.037+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:52.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:52.466+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:52.982+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:54.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:54.491+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-30T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:54.994+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:54.995+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:54.998+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:54.531316+00:00, run_end_date=2025-09-08 17:04:54.664411+00:00, run_duration=0.133095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=143, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:04:51.031068+00:00, queued_by_job_id=85, pid=17835
[2025-09-08T17:04:54.999+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:52.502995+00:00, run_end_date=2025-09-08 17:04:52.640315+00:00, run_duration=0.13732, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=142, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:51.031068+00:00, queued_by_job_id=85, pid=17818
[2025-09-08T17:04:55.147+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-06 00:00:00+00:00: scheduled__2025-09-06T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:42.418213+00:00. externally triggered: False> successful
[2025-09-08T17:04:55.147+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-06 00:00:00+00:00, run_id=scheduled__2025-09-06T00:00:00+00:00, run_start_date=2025-09-08 17:04:42.433417+00:00, run_end_date=2025-09-08 17:04:55.147417+00:00, run_duration=12.714, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-06 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:55.150+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
[2025-09-08T17:04:55.161+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:55.161+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:04:55.162+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
[2025-09-08T17:04:55.163+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:04:55.164+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:04:55.165+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:55.174+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:04:56.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:04:56.745+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-30T12:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:04:57.247+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:04:57.251+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:56.800687+00:00, run_end_date=2025-09-08 17:04:56.948261+00:00, run_duration=0.147574, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=144, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:04:55.162940+00:00, queued_by_job_id=85, pid=17865
[2025-09-08T17:04:57.412+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-30 12:00:00+00:00: scheduled__2025-08-30T12:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:40.335843+00:00. externally triggered: False> successful
[2025-09-08T17:04:57.413+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-30 12:00:00+00:00, run_id=scheduled__2025-08-30T12:00:00+00:00, run_start_date=2025-09-08 17:04:40.350586+00:00, run_end_date=2025-09-08 17:04:57.413292+00:00, run_duration=17.062706, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-30 12:00:00+00:00, data_interval_end=2025-09-06 00:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
[2025-09-08T17:04:57.417+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-06 12:00:00+00:00
[2025-09-08T17:04:58.447+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
[2025-09-08T17:06:13.222+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
[2025-09-08T17:06:13.249+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:13.250+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:06:13.250+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:13.251+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:06:13.251+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
[2025-09-08T17:06:13.252+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:13.256+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:14.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:06:14.633+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:06:15.134+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:06:15.138+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:14.666154+00:00, run_end_date=2025-09-08 17:06:14.791579+00:00, run_duration=0.125425, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:06:13.250805+00:00, queued_by_job_id=85, pid=18449
[2025-09-08T17:06:15.199+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:15.200+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:06:15.200+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:15.201+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:06:15.202+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
[2025-09-08T17:06:15.202+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:15.206+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:16.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:06:16.708+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:06:17.188+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:06:17.191+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:16.747389+00:00, run_end_date=2025-09-08 17:06:16.861738+00:00, run_duration=0.114349, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:06:15.201124+00:00, queued_by_job_id=85, pid=18467
[2025-09-08T17:06:17.240+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:17.240+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:06:17.241+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:17.242+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:06:17.242+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-09-08T17:06:17.243+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:17.247+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:18.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:06:18.782+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:06:19.289+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:06:19.294+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:18.818280+00:00, run_end_date=2025-09-08 17:06:18.950174+00:00, run_duration=0.131894, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:06:17.241662+00:00, queued_by_job_id=85, pid=18495
[2025-09-08T17:06:19.351+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:19.352+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:06:19.352+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:19.354+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:06:19.354+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-09-08T17:06:19.355+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:19.359+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:20.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:06:20.788+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:06:21.282+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:06:21.287+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:20.826389+00:00, run_end_date=2025-09-08 17:06:20.934189+00:00, run_duration=0.1078, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:06:19.353349+00:00, queued_by_job_id=85, pid=18506
[2025-09-08T17:06:21.353+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:21.354+0000] {scheduler_job_runner.py:495} INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
[2025-09-08T17:06:21.354+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
[2025-09-08T17:06:21.355+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-09-08T17:06:21.356+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-09-08T17:06:21.356+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:21.361+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
[2025-09-08T17:06:22.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /workspaces/Files_Learning_Apache_Airflow/airflow/dags/executing_cron_catchup_backfill.py
[2025-09-08T17:06:22.860+0000] {task_command.py:467} INFO - Running <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [queued]> on host codespaces-9bd7b3
[2025-09-08T17:06:23.347+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
[2025-09-08T17:06:23.351+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:22.892765+00:00, run_end_date=2025-09-08 17:06:23.027969+00:00, run_duration=0.135204, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:06:21.355102+00:00, queued_by_job_id=85, pid=18523
[2025-09-08T17:06:23.390+0000] {dagrun.py:854} INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:06:13.218489+00:00. externally triggered: False> successful
[2025-09-08T17:06:23.390+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 17:06:13.230980+00:00, run_end_date=2025-09-08 17:06:23.390859+00:00, run_duration=10.159879, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 12:00:00+00:00, dag_hash=712f1f12a72f4bb9b6d8fa080e6c8e8d
[2025-09-08T17:06:23.394+0000] {dag.py:4180} INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
[2025-09-08T17:08:06.205+0000] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-08T17:13:06.251+0000] {scheduler_job_runner.py:1847} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-09-08T17:14:30.444+0000] {scheduler_job_runner.py:260} INFO - Exiting gracefully upon receiving signal 15
[2025-09-08T17:14:31.449+0000] {process_utils.py:132} INFO - Sending 15 to group 4276. PIDs of all processes in the group: [4276]
[2025-09-08T17:14:31.449+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 4276
[2025-09-08T17:14:31.664+0000] {process_utils.py:80} INFO - Process psutil.Process(pid=4276, status='terminated', exitcode=0, started='16:38:05') (4276) terminated with exit code 0
[2025-09-08T17:14:31.672+0000] {process_utils.py:132} INFO - Sending 15 to group 4276. PIDs of all processes in the group: []
[2025-09-08T17:14:31.676+0000] {process_utils.py:87} INFO - Sending the signal 15 to group 4276
[2025-09-08T17:14:31.676+0000] {process_utils.py:101} INFO - Sending the signal 15 to process 4276 as process group is missing.
[2025-09-08T17:14:31.677+0000] {scheduler_job_runner.py:1014} INFO - Exited execute loop
