2025-09-07 22:27:29,037 INFO - Loaded executor: SequentialExecutor
2025-09-07 22:27:29,112 INFO - Starting the scheduler
2025-09-07 22:27:29,113 INFO - Processing each file at most -1 times
2025-09-07 22:27:29,122 INFO - Launched DagFileProcessorManager with pid: 11494
2025-09-07 22:27:29,124 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 22:27:29,130 INFO - Configured default timezone UTC
2025-09-07 22:30:42,543 INFO - Exiting gracefully upon receiving signal 15
2025-09-07 22:30:43,546 INFO - Sending 15 to group 11494. PIDs of all processes in the group: [11494]
2025-09-07 22:30:43,547 INFO - Sending the signal 15 to group 11494
2025-09-07 22:30:43,760 INFO - Process psutil.Process(pid=11494, status='terminated', exitcode=0, started='22:27:29') (11494) terminated with exit code 0
2025-09-07 22:30:43,762 INFO - Sending 15 to group 11494. PIDs of all processes in the group: []
2025-09-07 22:30:43,762 INFO - Sending the signal 15 to group 11494
2025-09-07 22:30:43,763 INFO - Sending the signal 15 to process 11494 as process group is missing.
2025-09-07 22:30:43,763 INFO - Exited execute loop
2025-09-07 22:31:03,270 INFO - Loaded executor: SequentialExecutor
2025-09-07 22:31:03,311 INFO - Starting the scheduler
2025-09-07 22:31:03,312 INFO - Processing each file at most -1 times
2025-09-07 22:31:03,318 INFO - Launched DagFileProcessorManager with pid: 14021
2025-09-07 22:31:03,322 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 22:31:03,328 INFO - Configured default timezone UTC
2025-09-07 22:32:29,810 INFO - Exiting gracefully upon receiving signal 15
2025-09-07 22:32:30,816 INFO - Sending 15 to group 14021. PIDs of all processes in the group: [14021]
2025-09-07 22:32:30,817 INFO - Sending the signal 15 to group 14021
2025-09-07 22:32:30,989 INFO - Process psutil.Process(pid=14021, status='terminated', exitcode=0, started='22:31:03') (14021) terminated with exit code 0
2025-09-07 22:32:30,991 INFO - Sending 15 to group 14021. PIDs of all processes in the group: []
2025-09-07 22:32:30,992 INFO - Sending the signal 15 to group 14021
2025-09-07 22:32:30,992 INFO - Sending the signal 15 to process 14021 as process group is missing.
2025-09-07 22:32:30,992 INFO - Exited execute loop
2025-09-07 22:32:48,485 INFO - Loaded executor: SequentialExecutor
2025-09-07 22:32:48,545 INFO - Starting the scheduler
2025-09-07 22:32:48,549 INFO - Processing each file at most -1 times
2025-09-07 22:32:48,559 INFO - Launched DagFileProcessorManager with pid: 15185
2025-09-07 22:32:48,563 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 22:32:48,570 INFO - Configured default timezone UTC
2025-09-07 22:32:51,638 WARNING - The Authorization header is missing: Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7
Host: localhost:8793
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36
Accept-Encoding: gzip, deflate, br, zstd
Accept-Language: en-US,en;q=0.9,th;q=0.8
Cache-Control: max-age=0
Referer: https://special-sniffle-4j96vg7xxrxx279rp.github.dev/
X-Request-Id: 34e9dd4fe9acd6f8adeb2c085e782997
X-Real-Ip: 35.142.96.234
X-Forwarded-Port: 443
X-Forwarded-Scheme: https
X-Original-Uri: /
X-Scheme: https
Dnt: 1
Sec-Fetch-Site: same-site
Sec-Fetch-Mode: navigate
Sec-Fetch-Dest: document
Sec-Ch-Ua: "Not;A=Brand";v="99", "Google Chrome";v="139", "Chromium";v="139"
Sec-Ch-Ua-Mobile: ?0
Sec-Ch-Ua-Platform: "Windows"
Priority: u=0, i
X-Original-Proto: https
X-Forwarded-Proto: https
X-Forwarded-Host: special-sniffle-4j96vg7xxrxx279rp-8793.app.github.dev
X-Forwarded-For: 35.142.96.234
Proxy-Connection: Keep-Alive

.
2025-09-07 22:32:51,811 WARNING - The Authorization header is missing: Accept: image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8
Host: localhost:8793
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36
Accept-Encoding: gzip, deflate, br, zstd
Accept-Language: en-US,en;q=0.9,th;q=0.8
Referer: https://special-sniffle-4j96vg7xxrxx279rp-8793.app.github.dev/
X-Request-Id: 4383b2cb5be0f896f800c8ae8e303cbc
X-Real-Ip: 35.142.96.234
X-Forwarded-Port: 443
X-Forwarded-Scheme: https
X-Original-Uri: /favicon.ico
X-Scheme: https
Sec-Ch-Ua-Platform: "Windows"
Sec-Ch-Ua: "Not;A=Brand";v="99", "Google Chrome";v="139", "Chromium";v="139"
Dnt: 1
Sec-Ch-Ua-Mobile: ?0
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: no-cors
Sec-Fetch-Dest: image
Priority: u=1, i
X-Original-Proto: https
X-Forwarded-Proto: https
X-Forwarded-Host: special-sniffle-4j96vg7xxrxx279rp-8793.app.github.dev
X-Forwarded-For: 35.142.96.234
Proxy-Connection: Keep-Alive

.
2025-09-07 22:37:48,631 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 22:42:48,660 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 22:47:48,687 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 22:52:48,714 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 22:57:48,754 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:02:48,796 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:03:11,754 INFO - 1 tasks up for execution:
	<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:03:10.879694+00:00 [scheduled]>
2025-09-07 23:03:11,755 INFO - DAG hello_world has 0/16 running and queued tasks
2025-09-07 23:03:11,755 INFO - Setting the following tasks to queued state:
	<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:03:10.879694+00:00 [scheduled]>
2025-09-07 23:03:11,757 INFO - Trying to enqueue tasks: [<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:03:10.879694+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:03:11,757 INFO - Sending TaskInstanceKey(dag_id='hello_world', task_id='hello_world_task', run_id='manual__2025-09-07T23:03:10.879694+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:03:11,757 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'hello_world', 'hello_world_task', 'manual__2025-09-07T23:03:10.879694+00:00', '--local', '--subdir', 'DAGS_FOLDER/simple_hello_world.py']
2025-09-07 23:03:11,761 INFO - Executing command: ['airflow', 'tasks', 'run', 'hello_world', 'hello_world_task', 'manual__2025-09-07T23:03:10.879694+00:00', '--local', '--subdir', 'DAGS_FOLDER/simple_hello_world.py']
2025-09-07 23:03:13,566 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='hello_world', task_id='hello_world_task', run_id='manual__2025-09-07T23:03:10.879694+00:00', try_number=1, map_index=-1)
2025-09-07 23:03:13,572 INFO - TaskInstance Finished: dag_id=hello_world, task_id=hello_world_task, run_id=manual__2025-09-07T23:03:10.879694+00:00, map_index=-1, run_start_date=2025-09-07 23:03:13.153919+00:00, run_end_date=2025-09-07 23:03:13.279929+00:00, run_duration=0.12601, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:03:11.756021+00:00, queued_by_job_id=3, pid=28741
2025-09-07 23:03:13,596 INFO - Marking run <DagRun hello_world @ 2025-09-07 23:03:10.879694+00:00: manual__2025-09-07T23:03:10.879694+00:00, state:running, queued_at: 2025-09-07 23:03:10.895743+00:00. externally triggered: True> successful
2025-09-07 23:03:13,597 INFO - DagRun Finished: dag_id=hello_world, execution_date=2025-09-07 23:03:10.879694+00:00, run_id=manual__2025-09-07T23:03:10.879694+00:00, run_start_date=2025-09-07 23:03:11.729021+00:00, run_end_date=2025-09-07 23:03:13.597051+00:00, run_duration=1.86803, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-07 23:03:10.879694+00:00, data_interval_end=2025-09-07 23:03:10.879694+00:00, dag_hash=88f303ec2c9857d49be8588c02aa5640
2025-09-07 23:05:37,010 INFO - 1 tasks up for execution:
	<TaskInstance: hello_world.hello_world_task scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-07 23:05:37,011 INFO - DAG hello_world has 0/16 running and queued tasks
2025-09-07 23:05:37,011 INFO - Setting the following tasks to queued state:
	<TaskInstance: hello_world.hello_world_task scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-07 23:05:37,012 INFO - Trying to enqueue tasks: [<TaskInstance: hello_world.hello_world_task scheduled__2025-09-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:05:37,013 INFO - Sending TaskInstanceKey(dag_id='hello_world', task_id='hello_world_task', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:05:37,013 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'hello_world', 'hello_world_task', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/simple_hello_world.py']
2025-09-07 23:05:37,017 INFO - Executing command: ['airflow', 'tasks', 'run', 'hello_world', 'hello_world_task', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/simple_hello_world.py']
2025-09-07 23:05:39,125 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='hello_world', task_id='hello_world_task', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-07 23:05:39,128 INFO - TaskInstance Finished: dag_id=hello_world, task_id=hello_world_task, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-07 23:05:38.665570+00:00, run_end_date=2025-09-07 23:05:38.824436+00:00, run_duration=0.158866, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=5, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:05:37.011917+00:00, queued_by_job_id=3, pid=29815
2025-09-07 23:05:39,175 INFO - Marking run <DagRun hello_world @ 2025-09-06 00:00:00+00:00: scheduled__2025-09-06T00:00:00+00:00, state:running, queued_at: 2025-09-07 23:05:36.981182+00:00. externally triggered: False> successful
2025-09-07 23:05:39,176 INFO - DagRun Finished: dag_id=hello_world, execution_date=2025-09-06 00:00:00+00:00, run_id=scheduled__2025-09-06T00:00:00+00:00, run_start_date=2025-09-07 23:05:36.994539+00:00, run_end_date=2025-09-07 23:05:39.176020+00:00, run_duration=2.181481, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=ba8fb2c152734e6cddd872ecfca02267
2025-09-07 23:07:48,825 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:12:48,863 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:17:48,891 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:22:48,918 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:27:48,945 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:32:48,966 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:37:48,993 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:39:25,959 INFO - 1 tasks up for execution:
	<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:39:24.577731+00:00 [scheduled]>
2025-09-07 23:39:25,959 INFO - DAG hello_world has 0/16 running and queued tasks
2025-09-07 23:39:25,960 INFO - Setting the following tasks to queued state:
	<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:39:24.577731+00:00 [scheduled]>
2025-09-07 23:39:25,961 INFO - Trying to enqueue tasks: [<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:39:24.577731+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:39:25,961 INFO - Sending TaskInstanceKey(dag_id='hello_world', task_id='hello_world_task', run_id='manual__2025-09-07T23:39:24.577731+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:39:25,962 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'hello_world', 'hello_world_task', 'manual__2025-09-07T23:39:24.577731+00:00', '--local', '--subdir', 'DAGS_FOLDER/simple_hello_world.py']
2025-09-07 23:39:25,965 INFO - Executing command: ['airflow', 'tasks', 'run', 'hello_world', 'hello_world_task', 'manual__2025-09-07T23:39:24.577731+00:00', '--local', '--subdir', 'DAGS_FOLDER/simple_hello_world.py']
2025-09-07 23:39:27,929 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='hello_world', task_id='hello_world_task', run_id='manual__2025-09-07T23:39:24.577731+00:00', try_number=1, map_index=-1)
2025-09-07 23:39:27,932 INFO - TaskInstance Finished: dag_id=hello_world, task_id=hello_world_task, run_id=manual__2025-09-07T23:39:24.577731+00:00, map_index=-1, run_start_date=2025-09-07 23:39:27.496812+00:00, run_end_date=2025-09-07 23:39:27.620990+00:00, run_duration=0.124178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=6, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:39:25.960678+00:00, queued_by_job_id=3, pid=43743
2025-09-07 23:39:27,973 INFO - Marking run <DagRun hello_world @ 2025-09-07 23:39:24.577731+00:00: manual__2025-09-07T23:39:24.577731+00:00, state:running, queued_at: 2025-09-07 23:39:24.587705+00:00. externally triggered: True> successful
2025-09-07 23:39:27,974 INFO - DagRun Finished: dag_id=hello_world, execution_date=2025-09-07 23:39:24.577731+00:00, run_id=manual__2025-09-07T23:39:24.577731+00:00, run_start_date=2025-09-07 23:39:25.943394+00:00, run_end_date=2025-09-07 23:39:27.974362+00:00, run_duration=2.030968, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=d74b11ae748cf8b0087ebf09915348d7
2025-09-07 23:41:17,037 INFO - 1 tasks up for execution:
	<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:41:16.490482+00:00 [scheduled]>
2025-09-07 23:41:17,038 INFO - DAG hello_world has 0/16 running and queued tasks
2025-09-07 23:41:17,038 INFO - Setting the following tasks to queued state:
	<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:41:16.490482+00:00 [scheduled]>
2025-09-07 23:41:17,040 INFO - Trying to enqueue tasks: [<TaskInstance: hello_world.hello_world_task manual__2025-09-07T23:41:16.490482+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:41:17,040 INFO - Sending TaskInstanceKey(dag_id='hello_world', task_id='hello_world_task', run_id='manual__2025-09-07T23:41:16.490482+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:41:17,041 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'hello_world', 'hello_world_task', 'manual__2025-09-07T23:41:16.490482+00:00', '--local', '--subdir', 'DAGS_FOLDER/simple_hello_world.py']
2025-09-07 23:41:17,044 INFO - Executing command: ['airflow', 'tasks', 'run', 'hello_world', 'hello_world_task', 'manual__2025-09-07T23:41:16.490482+00:00', '--local', '--subdir', 'DAGS_FOLDER/simple_hello_world.py']
2025-09-07 23:41:18,850 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='hello_world', task_id='hello_world_task', run_id='manual__2025-09-07T23:41:16.490482+00:00', try_number=1, map_index=-1)
2025-09-07 23:41:18,853 INFO - TaskInstance Finished: dag_id=hello_world, task_id=hello_world_task, run_id=manual__2025-09-07T23:41:16.490482+00:00, map_index=-1, run_start_date=2025-09-07 23:41:18.424765+00:00, run_end_date=2025-09-07 23:41:18.554659+00:00, run_duration=0.129894, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:41:17.039391+00:00, queued_by_job_id=3, pid=44537
2025-09-07 23:41:18,895 INFO - Marking run <DagRun hello_world @ 2025-09-07 23:41:16.490482+00:00: manual__2025-09-07T23:41:16.490482+00:00, state:running, queued_at: 2025-09-07 23:41:16.496834+00:00. externally triggered: True> successful
2025-09-07 23:41:18,895 INFO - DagRun Finished: dag_id=hello_world, execution_date=2025-09-07 23:41:16.490482+00:00, run_id=manual__2025-09-07T23:41:16.490482+00:00, run_start_date=2025-09-07 23:41:17.021036+00:00, run_end_date=2025-09-07 23:41:18.895690+00:00, run_duration=1.874654, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=75b47e7b9802507cd5c01520ac789e62
2025-09-07 23:42:27,376 INFO - Setting next_dagrun for executing_multiple_tasks to None, run_after=None
2025-09-07 23:42:27,403 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskB scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-07 23:42:27,404 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:42:27,404 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskB scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-07 23:42:27,405 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskB scheduled__2025-09-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:42:27,406 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:42:27,406 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:42:27,410 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:42:29,273 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-07 23:42:29,276 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskB, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-07 23:42:28.834232+00:00, run_end_date=2025-09-07 23:42:28.957725+00:00, run_duration=0.123493, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:42:27.404862+00:00, queued_by_job_id=3, pid=45066
2025-09-07 23:42:29,319 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-07 23:42:29,319 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:42:29,319 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-07 23:42:29,321 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:42:29,321 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:42:29,321 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:42:29,325 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:42:31,153 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-07 23:42:31,156 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskA, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-07 23:42:30.691848+00:00, run_end_date=2025-09-07 23:42:30.820335+00:00, run_duration=0.128487, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:42:29.320347+00:00, queued_by_job_id=3, pid=45078
2025-09-07 23:42:31,236 INFO - Marking run <DagRun executing_multiple_tasks @ 2025-09-06 00:00:00+00:00: scheduled__2025-09-06T00:00:00+00:00, state:running, queued_at: 2025-09-07 23:42:27.373224+00:00. externally triggered: False> successful
2025-09-07 23:42:31,243 INFO - DagRun Finished: dag_id=executing_multiple_tasks, execution_date=2025-09-06 00:00:00+00:00, run_id=scheduled__2025-09-06T00:00:00+00:00, run_start_date=2025-09-07 23:42:27.384866+00:00, run_end_date=2025-09-07 23:42:31.243067+00:00, run_duration=3.858201, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-06 00:00:00+00:00, dag_hash=d6f6ff7db102fc3b152d8a28dabbe771
2025-09-07 23:42:31,248 INFO - Setting next_dagrun for executing_multiple_tasks to None, run_after=None
2025-09-07 23:42:49,022 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:43:39,791 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:43:38.323116+00:00 [scheduled]>
2025-09-07 23:43:39,791 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:43:39,791 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:43:38.323116+00:00 [scheduled]>
2025-09-07 23:43:39,792 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:43:38.323116+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:43:39,793 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:43:38.323116+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:43:39,793 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:43:38.323116+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:43:39,797 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:43:38.323116+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:43:41,597 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:43:38.323116+00:00', try_number=1, map_index=-1)
2025-09-07 23:43:41,600 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskA, run_id=manual__2025-09-07T23:43:38.323116+00:00, map_index=-1, run_start_date=2025-09-07 23:43:41.172569+00:00, run_end_date=2025-09-07 23:43:41.296207+00:00, run_duration=0.123638, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=10, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:43:39.792277+00:00, queued_by_job_id=3, pid=45583
2025-09-07 23:43:41,642 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:43:38.323116+00:00 [scheduled]>
2025-09-07 23:43:41,643 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:43:41,643 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:43:38.323116+00:00 [scheduled]>
2025-09-07 23:43:41,644 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:43:38.323116+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:43:41,645 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='manual__2025-09-07T23:43:38.323116+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:43:41,645 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'manual__2025-09-07T23:43:38.323116+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:43:41,649 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'manual__2025-09-07T23:43:38.323116+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:43:43,597 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='manual__2025-09-07T23:43:38.323116+00:00', try_number=1, map_index=-1)
2025-09-07 23:43:43,600 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskB, run_id=manual__2025-09-07T23:43:38.323116+00:00, map_index=-1, run_start_date=2025-09-07 23:43:43.185243+00:00, run_end_date=2025-09-07 23:43:43.308302+00:00, run_duration=0.123059, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=11, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:43:41.644009+00:00, queued_by_job_id=3, pid=45595
2025-09-07 23:43:43,645 INFO - Marking run <DagRun executing_multiple_tasks @ 2025-09-07 23:43:38.323116+00:00: manual__2025-09-07T23:43:38.323116+00:00, state:running, queued_at: 2025-09-07 23:43:38.329770+00:00. externally triggered: True> successful
2025-09-07 23:43:43,645 INFO - DagRun Finished: dag_id=executing_multiple_tasks, execution_date=2025-09-07 23:43:38.323116+00:00, run_id=manual__2025-09-07T23:43:38.323116+00:00, run_start_date=2025-09-07 23:43:39.774258+00:00, run_end_date=2025-09-07 23:43:43.645513+00:00, run_duration=3.871255, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-07 23:43:38.323116+00:00, data_interval_end=2025-09-07 23:43:38.323116+00:00, dag_hash=ab5a91820c3d9ec06ec675b65cb15d62
2025-09-07 23:44:11,030 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:44:21,660 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>
2025-09-07 23:44:21,661 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:44:21,661 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>
2025-09-07 23:44:21,663 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:44:21,663 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:44:20.672695+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-07 23:44:21,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:44:20.672695+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:44:21,668 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:44:20.672695+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:44:23,644 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:44:20.672695+00:00', try_number=1, map_index=-1)
2025-09-07 23:44:23,647 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskA, run_id=manual__2025-09-07T23:44:20.672695+00:00, map_index=-1, run_start_date=2025-09-07 23:44:23.228201+00:00, run_end_date=2025-09-07 23:44:23.353737+00:00, run_duration=0.125536, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=12, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-09-07 23:44:21.662327+00:00, queued_by_job_id=3, pid=45900
2025-09-07 23:44:23,693 INFO - 2 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>
2025-09-07 23:44:23,694 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:44:23,694 INFO - DAG executing_multiple_tasks has 1/16 running and queued tasks
2025-09-07 23:44:23,695 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>
2025-09-07 23:44:23,697 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>, <TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:44:23,698 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='manual__2025-09-07T23:44:20.672695+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:44:23,698 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'manual__2025-09-07T23:44:20.672695+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:44:23,699 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskC', run_id='manual__2025-09-07T23:44:20.672695+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:44:23,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskC', 'manual__2025-09-07T23:44:20.672695+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:44:23,703 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'manual__2025-09-07T23:44:20.672695+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:44:29,514 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskC', 'manual__2025-09-07T23:44:20.672695+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:44:46,351 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='manual__2025-09-07T23:44:20.672695+00:00', try_number=1, map_index=-1)
2025-09-07 23:44:46,352 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskC', run_id='manual__2025-09-07T23:44:20.672695+00:00', try_number=1, map_index=-1)
2025-09-07 23:44:46,355 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskB, run_id=manual__2025-09-07T23:44:20.672695+00:00, map_index=-1, run_start_date=2025-09-07 23:44:25.098218+00:00, run_end_date=2025-09-07 23:44:29.228969+00:00, run_duration=4.130751, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=13, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:44:23.696034+00:00, queued_by_job_id=3, pid=45912
2025-09-07 23:44:46,356 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskC, run_id=manual__2025-09-07T23:44:20.672695+00:00, map_index=-1, run_start_date=2025-09-07 23:44:30.920431+00:00, run_end_date=2025-09-07 23:44:46.053640+00:00, run_duration=15.133209, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=14, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:44:23.696034+00:00, queued_by_job_id=3, pid=45965
2025-09-07 23:44:46,502 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:44:46,520 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>
2025-09-07 23:44:46,520 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:44:46,521 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>
2025-09-07 23:44:46,522 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:44:20.672695+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:44:46,523 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskD', run_id='manual__2025-09-07T23:44:20.672695+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:44:46,523 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskD', 'manual__2025-09-07T23:44:20.672695+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:44:46,527 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskD', 'manual__2025-09-07T23:44:20.672695+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:44:48,362 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskD', run_id='manual__2025-09-07T23:44:20.672695+00:00', try_number=1, map_index=-1)
2025-09-07 23:44:48,365 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskD, run_id=manual__2025-09-07T23:44:20.672695+00:00, map_index=-1, run_start_date=2025-09-07 23:44:47.940047+00:00, run_end_date=2025-09-07 23:44:48.060914+00:00, run_duration=0.120867, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=15, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:44:46.521610+00:00, queued_by_job_id=3, pid=46080
2025-09-07 23:44:48,509 INFO - Marking run <DagRun executing_multiple_tasks @ 2025-09-07 23:44:20.672695+00:00: manual__2025-09-07T23:44:20.672695+00:00, state:running, queued_at: 2025-09-07 23:44:20.677387+00:00. externally triggered: True> successful
2025-09-07 23:44:48,509 INFO - DagRun Finished: dag_id=executing_multiple_tasks, execution_date=2025-09-07 23:44:20.672695+00:00, run_id=manual__2025-09-07T23:44:20.672695+00:00, run_start_date=2025-09-07 23:44:21.636929+00:00, run_end_date=2025-09-07 23:44:48.509537+00:00, run_duration=26.872608, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-06 23:44:20.672695+00:00, data_interval_end=2025-09-07 23:44:20.672695+00:00, dag_hash=0348451d517d87a90f57a2ebef65096b
2025-09-07 23:45:16,651 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:45:46,955 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:46:17,289 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:47:49,061 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:50:17,178 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:50:47,346 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:50:51,072 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:50:54,380 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:51:04,467 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:51:03.441178+00:00 [scheduled]>
2025-09-07 23:51:04,468 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:51:04,468 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:51:03.441178+00:00 [scheduled]>
2025-09-07 23:51:04,469 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:51:03.441178+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:51:04,470 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:51:03.441178+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2025-09-07 23:51:04,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:51:03.441178+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:51:04,474 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:51:03.441178+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:51:06,382 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:51:03.441178+00:00', try_number=1, map_index=-1)
2025-09-07 23:51:06,385 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskA, run_id=manual__2025-09-07T23:51:03.441178+00:00, map_index=-1, run_start_date=2025-09-07 23:51:05.980799+00:00, run_end_date=2025-09-07 23:51:06.061389+00:00, run_duration=0.08059, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=16, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2025-09-07 23:51:04.469119+00:00, queued_by_job_id=3, pid=49245
2025-09-07 23:51:07,412 ERROR - Marking run <DagRun executing_multiple_tasks @ 2025-09-07 23:51:03.441178+00:00: manual__2025-09-07T23:51:03.441178+00:00, state:running, queued_at: 2025-09-07 23:51:03.445902+00:00. externally triggered: True> failed
2025-09-07 23:51:07,412 INFO - DagRun Finished: dag_id=executing_multiple_tasks, execution_date=2025-09-07 23:51:03.441178+00:00, run_id=manual__2025-09-07T23:51:03.441178+00:00, run_start_date=2025-09-07 23:51:04.449138+00:00, run_end_date=2025-09-07 23:51:07.412798+00:00, run_duration=2.96366, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-06 23:51:03.441178+00:00, data_interval_end=2025-09-07 23:51:03.441178+00:00, dag_hash=00884def79a7f5899a57515e7fbd317c
2025-09-07 23:51:24,780 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:51:55,006 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:52:25,421 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:52:39,732 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:52:38.910917+00:00 [scheduled]>
2025-09-07 23:52:39,732 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:52:39,733 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:52:38.910917+00:00 [scheduled]>
2025-09-07 23:52:39,734 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:52:38.910917+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:52:39,734 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:52:38.910917+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2025-09-07 23:52:39,734 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:52:38.910917+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:52:39,738 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:52:38.910917+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:52:41,804 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:52:38.910917+00:00', try_number=1, map_index=-1)
2025-09-07 23:52:41,807 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskA, run_id=manual__2025-09-07T23:52:38.910917+00:00, map_index=-1, run_start_date=2025-09-07 23:52:41.413955+00:00, run_end_date=2025-09-07 23:52:41.489454+00:00, run_duration=0.075499, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=17, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2025-09-07 23:52:39.733519+00:00, queued_by_job_id=3, pid=49968
2025-09-07 23:52:42,074 ERROR - Marking run <DagRun executing_multiple_tasks @ 2025-09-07 23:52:38.910917+00:00: manual__2025-09-07T23:52:38.910917+00:00, state:running, queued_at: 2025-09-07 23:52:38.918653+00:00. externally triggered: True> failed
2025-09-07 23:52:42,074 INFO - DagRun Finished: dag_id=executing_multiple_tasks, execution_date=2025-09-07 23:52:38.910917+00:00, run_id=manual__2025-09-07T23:52:38.910917+00:00, run_start_date=2025-09-07 23:52:39.713126+00:00, run_end_date=2025-09-07 23:52:42.074549+00:00, run_duration=2.361423, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-06 23:52:38.910917+00:00, data_interval_end=2025-09-07 23:52:38.910917+00:00, dag_hash=3de2273005cc2a8d0879a8d3413bf89e
2025-09-07 23:52:49,088 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:52:56,684 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:53:27,597 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:53:31,218 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:53:34,769 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
2025-09-07 23:53:34,770 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:53:34,770 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
2025-09-07 23:53:34,771 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:53:34,772 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2025-09-07 23:53:34,772 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:34,776 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:36,664 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1)
2025-09-07 23:53:36,667 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskA, run_id=manual__2025-09-07T23:53:33.927649+00:00, map_index=-1, run_start_date=2025-09-07 23:53:36.256127+00:00, run_end_date=2025-09-07 23:53:36.382916+00:00, run_duration=0.126789, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=18, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2025-09-07 23:53:34.771156+00:00, queued_by_job_id=3, pid=50427
2025-09-07 23:53:36,711 INFO - 3 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
2025-09-07 23:53:36,711 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:53:36,712 INFO - DAG executing_multiple_tasks has 1/16 running and queued tasks
2025-09-07 23:53:36,712 INFO - DAG executing_multiple_tasks has 2/16 running and queued tasks
2025-09-07 23:53:36,712 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
2025-09-07 23:53:36,714 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>, <TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>, <TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:53:36,714 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:53:36,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:36,715 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskC', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:53:36,715 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskC', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:36,715 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskD', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:53:36,716 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskD', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:36,720 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:42,655 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskC', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:54,511 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskD', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:56,456 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1)
2025-09-07 23:53:56,456 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskC', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1)
2025-09-07 23:53:56,457 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskD', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1)
2025-09-07 23:53:56,460 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskB, run_id=manual__2025-09-07T23:53:33.927649+00:00, map_index=-1, run_start_date=2025-09-07 23:53:38.223910+00:00, run_end_date=2025-09-07 23:53:42.366389+00:00, run_duration=4.142479, state=skipped, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=19, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:53:36.713384+00:00, queued_by_job_id=3, pid=50458
2025-09-07 23:53:56,460 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskC, run_id=manual__2025-09-07T23:53:33.927649+00:00, map_index=-1, run_start_date=2025-09-07 23:53:44.076129+00:00, run_end_date=2025-09-07 23:53:54.197738+00:00, run_duration=10.121609, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=20, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:53:36.713384+00:00, queued_by_job_id=3, pid=50493
2025-09-07 23:53:56,461 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskD, run_id=manual__2025-09-07T23:53:33.927649+00:00, map_index=-1, run_start_date=2025-09-07 23:53:56.015626+00:00, run_end_date=2025-09-07 23:53:56.146293+00:00, run_duration=0.130667, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=21, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:53:36.713384+00:00, queued_by_job_id=3, pid=50584
2025-09-07 23:53:56,625 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskG manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
2025-09-07 23:53:56,625 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:53:56,625 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskG manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>
2025-09-07 23:53:56,627 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskG manual__2025-09-07T23:53:33.927649+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:53:56,627 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskG', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:53:56,627 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskG', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:56,631 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskG', 'manual__2025-09-07T23:53:33.927649+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:53:58,573 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskG', run_id='manual__2025-09-07T23:53:33.927649+00:00', try_number=1, map_index=-1)
2025-09-07 23:53:58,576 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskG, run_id=manual__2025-09-07T23:53:33.927649+00:00, map_index=-1, run_start_date=2025-09-07 23:53:57.998250+00:00, run_end_date=2025-09-07 23:53:58.195240+00:00, run_duration=0.19699, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=22, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:53:56.626370+00:00, queued_by_job_id=3, pid=50602
2025-09-07 23:53:58,615 ERROR - Marking run <DagRun executing_multiple_tasks @ 2025-09-07 23:53:33.927649+00:00: manual__2025-09-07T23:53:33.927649+00:00, state:running, queued_at: 2025-09-07 23:53:33.935183+00:00. externally triggered: True> failed
2025-09-07 23:53:58,616 INFO - DagRun Finished: dag_id=executing_multiple_tasks, execution_date=2025-09-07 23:53:33.927649+00:00, run_id=manual__2025-09-07T23:53:33.927649+00:00, run_start_date=2025-09-07 23:53:34.751335+00:00, run_end_date=2025-09-07 23:53:58.616185+00:00, run_duration=23.86485, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-06 23:53:33.927649+00:00, data_interval_end=2025-09-07 23:53:33.927649+00:00, dag_hash=3de2273005cc2a8d0879a8d3413bf89e
2025-09-07 23:54:01,592 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:54:32,200 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:54:35,334 INFO - 1 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
2025-09-07 23:54:35,334 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:54:35,334 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
2025-09-07 23:54:35,336 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskA manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:54:35,336 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2025-09-07 23:54:35,336 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:35,340 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskA', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:37,265 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskA', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1)
2025-09-07 23:54:37,269 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskA, run_id=manual__2025-09-07T23:54:34.886386+00:00, map_index=-1, run_start_date=2025-09-07 23:54:36.733923+00:00, run_end_date=2025-09-07 23:54:36.857190+00:00, run_duration=0.123267, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=23, pool=default_pool, queue=default, priority_weight=7, operator=BashOperator, queued_dttm=2025-09-07 23:54:35.335357+00:00, queued_by_job_id=3, pid=50884
2025-09-07 23:54:37,310 INFO - 3 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
2025-09-07 23:54:37,310 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:54:37,311 INFO - DAG executing_multiple_tasks has 1/16 running and queued tasks
2025-09-07 23:54:37,311 INFO - DAG executing_multiple_tasks has 2/16 running and queued tasks
2025-09-07 23:54:37,311 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
2025-09-07 23:54:37,313 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskB manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>, <TaskInstance: executing_multiple_tasks.taskC manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>, <TaskInstance: executing_multiple_tasks.taskD manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:54:37,313 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:54:37,313 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:37,314 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskC', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:54:37,314 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskC', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:37,314 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskD', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:54:37,315 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskD', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:37,318 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskB', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:43,181 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskC', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:55,044 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskD', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:56,980 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskB', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1)
2025-09-07 23:54:56,981 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskC', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1)
2025-09-07 23:54:56,981 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskD', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1)
2025-09-07 23:54:56,984 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskB, run_id=manual__2025-09-07T23:54:34.886386+00:00, map_index=-1, run_start_date=2025-09-07 23:54:38.699781+00:00, run_end_date=2025-09-07 23:54:42.899317+00:00, run_duration=4.199536, state=skipped, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=24, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:54:37.312316+00:00, queued_by_job_id=3, pid=50896
2025-09-07 23:54:56,985 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskC, run_id=manual__2025-09-07T23:54:34.886386+00:00, map_index=-1, run_start_date=2025-09-07 23:54:44.570602+00:00, run_end_date=2025-09-07 23:54:54.757838+00:00, run_duration=10.187236, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=25, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:54:37.312316+00:00, queued_by_job_id=3, pid=50949
2025-09-07 23:54:56,985 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskD, run_id=manual__2025-09-07T23:54:34.886386+00:00, map_index=-1, run_start_date=2025-09-07 23:54:56.563492+00:00, run_end_date=2025-09-07 23:54:56.686069+00:00, run_duration=0.122577, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=26, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-09-07 23:54:37.312316+00:00, queued_by_job_id=3, pid=51042
2025-09-07 23:54:57,251 INFO - 2 tasks up for execution:
	<TaskInstance: executing_multiple_tasks.taskF manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskG manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
2025-09-07 23:54:57,251 INFO - DAG executing_multiple_tasks has 0/16 running and queued tasks
2025-09-07 23:54:57,251 INFO - DAG executing_multiple_tasks has 1/16 running and queued tasks
2025-09-07 23:54:57,252 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_multiple_tasks.taskF manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
	<TaskInstance: executing_multiple_tasks.taskG manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>
2025-09-07 23:54:57,253 INFO - Trying to enqueue tasks: [<TaskInstance: executing_multiple_tasks.taskF manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>, <TaskInstance: executing_multiple_tasks.taskG manual__2025-09-07T23:54:34.886386+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:54:57,253 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskF', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:54:57,254 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskF', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:57,254 INFO - Sending TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskG', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:54:57,254 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskG', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:57,259 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskF', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:54:59,056 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_multiple_tasks', 'taskG', 'manual__2025-09-07T23:54:34.886386+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-07 23:55:01,061 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskF', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1)
2025-09-07 23:55:01,062 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_multiple_tasks', task_id='taskG', run_id='manual__2025-09-07T23:54:34.886386+00:00', try_number=1, map_index=-1)
2025-09-07 23:55:01,065 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskF, run_id=manual__2025-09-07T23:54:34.886386+00:00, map_index=-1, run_start_date=2025-09-07 23:54:58.648027+00:00, run_end_date=2025-09-07 23:54:58.776110+00:00, run_duration=0.128083, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=27, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:54:57.252729+00:00, queued_by_job_id=3, pid=51055
2025-09-07 23:55:01,065 INFO - TaskInstance Finished: dag_id=executing_multiple_tasks, task_id=taskG, run_id=manual__2025-09-07T23:54:34.886386+00:00, map_index=-1, run_start_date=2025-09-07 23:55:00.649395+00:00, run_end_date=2025-09-07 23:55:00.778920+00:00, run_duration=0.129525, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=28, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-07 23:54:57.252729+00:00, queued_by_job_id=3, pid=51086
2025-09-07 23:55:01,102 INFO - Marking run <DagRun executing_multiple_tasks @ 2025-09-07 23:54:34.886386+00:00: manual__2025-09-07T23:54:34.886386+00:00, state:running, queued_at: 2025-09-07 23:54:34.894578+00:00. externally triggered: True> successful
2025-09-07 23:55:01,103 INFO - DagRun Finished: dag_id=executing_multiple_tasks, execution_date=2025-09-07 23:54:34.886386+00:00, run_id=manual__2025-09-07T23:54:34.886386+00:00, run_start_date=2025-09-07 23:54:35.315777+00:00, run_end_date=2025-09-07 23:55:01.103296+00:00, run_duration=25.787519, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-06 23:54:34.886386+00:00, data_interval_end=2025-09-07 23:54:34.886386+00:00, dag_hash=8d8253b1cf6ffacd91a1727a3800e645
2025-09-07 23:55:03,251 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:55:34,481 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:56:04,962 INFO - Setting next_dagrun for executing_multiple_tasks to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:56:10,828 INFO - Setting next_dagrun for execute_python_operators to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:56:10,852 INFO - 1 tasks up for execution:
	<TaskInstance: execute_python_operators.python_task scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-07 23:56:10,853 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-07 23:56:10,853 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.python_task scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-07 23:56:10,854 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.python_task scheduled__2025-09-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:56:10,855 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='python_task', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:56:10,855 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'python_task', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:56:10,859 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'python_task', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:56:12,716 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='python_task', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-07 23:56:12,719 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=python_task, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-07 23:56:12.288672+00:00, run_end_date=2025-09-07 23:56:12.416376+00:00, run_duration=0.127704, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=29, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-07 23:56:10.853876+00:00, queued_by_job_id=3, pid=51633
2025-09-07 23:56:12,744 INFO - Marking run <DagRun execute_python_operators @ 2025-09-06 00:00:00+00:00: scheduled__2025-09-06T00:00:00+00:00, state:running, queued_at: 2025-09-07 23:56:10.824657+00:00. externally triggered: False> successful
2025-09-07 23:56:12,744 INFO - DagRun Finished: dag_id=execute_python_operators, execution_date=2025-09-06 00:00:00+00:00, run_id=scheduled__2025-09-06T00:00:00+00:00, run_start_date=2025-09-07 23:56:10.836390+00:00, run_end_date=2025-09-07 23:56:12.744614+00:00, run_duration=1.908224, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=9ce89bec64913621540841e815f9f2ba
2025-09-07 23:56:12,747 INFO - Setting next_dagrun for execute_python_operators to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-07 23:57:49,126 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-07 23:58:44,060 INFO - 1 tasks up for execution:
	<TaskInstance: execute_python_operators.taskA manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>
2025-09-07 23:58:44,060 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-07 23:58:44,061 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.taskA manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>
2025-09-07 23:58:44,062 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.taskA manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:58:44,063 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='taskA', run_id='manual__2025-09-07T23:58:43.787714+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-07 23:58:44,063 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskA', 'manual__2025-09-07T23:58:43.787714+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:58:44,070 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskA', 'manual__2025-09-07T23:58:43.787714+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:58:45,952 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='taskA', run_id='manual__2025-09-07T23:58:43.787714+00:00', try_number=1, map_index=-1)
2025-09-07 23:58:45,956 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=taskA, run_id=manual__2025-09-07T23:58:43.787714+00:00, map_index=-1, run_start_date=2025-09-07 23:58:45.530752+00:00, run_end_date=2025-09-07 23:58:45.636171+00:00, run_duration=0.105419, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=30, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-09-07 23:58:44.061867+00:00, queued_by_job_id=3, pid=53217
2025-09-07 23:58:45,994 INFO - 2 tasks up for execution:
	<TaskInstance: execute_python_operators.taskB manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>
	<TaskInstance: execute_python_operators.taskC manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>
2025-09-07 23:58:45,994 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-07 23:58:45,994 INFO - DAG execute_python_operators has 1/16 running and queued tasks
2025-09-07 23:58:45,994 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.taskB manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>
	<TaskInstance: execute_python_operators.taskC manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>
2025-09-07 23:58:45,996 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.taskB manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>, <TaskInstance: execute_python_operators.taskC manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:58:45,996 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='taskB', run_id='manual__2025-09-07T23:58:43.787714+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:58:45,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskB', 'manual__2025-09-07T23:58:43.787714+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:58:45,997 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='taskC', run_id='manual__2025-09-07T23:58:43.787714+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-07 23:58:45,997 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskC', 'manual__2025-09-07T23:58:43.787714+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:58:46,001 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskB', 'manual__2025-09-07T23:58:43.787714+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:58:53,057 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskC', 'manual__2025-09-07T23:58:43.787714+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:58:54,872 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='taskB', run_id='manual__2025-09-07T23:58:43.787714+00:00', try_number=1, map_index=-1)
2025-09-07 23:58:54,873 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='taskC', run_id='manual__2025-09-07T23:58:43.787714+00:00', try_number=1, map_index=-1)
2025-09-07 23:58:54,876 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=taskB, run_id=manual__2025-09-07T23:58:43.787714+00:00, map_index=-1, run_start_date=2025-09-07 23:58:47.554807+00:00, run_end_date=2025-09-07 23:58:52.659182+00:00, run_duration=5.104375, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=31, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-07 23:58:45.995444+00:00, queued_by_job_id=3, pid=53228
2025-09-07 23:58:54,876 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=taskC, run_id=manual__2025-09-07T23:58:43.787714+00:00, map_index=-1, run_start_date=2025-09-07 23:58:54.465408+00:00, run_end_date=2025-09-07 23:58:54.569921+00:00, run_duration=0.104513, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=32, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-07 23:58:45.995444+00:00, queued_by_job_id=3, pid=53279
2025-09-07 23:58:54,948 INFO - 1 tasks up for execution:
	<TaskInstance: execute_python_operators.taskD manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>
2025-09-07 23:58:54,949 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-07 23:58:54,949 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.taskD manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>
2025-09-07 23:58:54,950 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.taskD manual__2025-09-07T23:58:43.787714+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-07 23:58:54,951 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='taskD', run_id='manual__2025-09-07T23:58:43.787714+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-07 23:58:54,951 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskD', 'manual__2025-09-07T23:58:43.787714+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:58:54,955 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskD', 'manual__2025-09-07T23:58:43.787714+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-07 23:58:56,755 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='taskD', run_id='manual__2025-09-07T23:58:43.787714+00:00', try_number=1, map_index=-1)
2025-09-07 23:58:56,759 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=taskD, run_id=manual__2025-09-07T23:58:43.787714+00:00, map_index=-1, run_start_date=2025-09-07 23:58:56.338346+00:00, run_end_date=2025-09-07 23:58:56.451543+00:00, run_duration=0.113197, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=33, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-07 23:58:54.949987+00:00, queued_by_job_id=3, pid=53295
2025-09-07 23:58:56,782 INFO - Marking run <DagRun execute_python_operators @ 2025-09-07 23:58:43.787714+00:00: manual__2025-09-07T23:58:43.787714+00:00, state:running, queued_at: 2025-09-07 23:58:43.794091+00:00. externally triggered: True> successful
2025-09-07 23:58:56,783 INFO - DagRun Finished: dag_id=execute_python_operators, execution_date=2025-09-07 23:58:43.787714+00:00, run_id=manual__2025-09-07T23:58:43.787714+00:00, run_start_date=2025-09-07 23:58:44.037985+00:00, run_end_date=2025-09-07 23:58:56.783187+00:00, run_duration=12.745202, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=a89a69cc8e869a53357c70eed9d4b77a
2025-09-08 00:00:01,358 INFO - Setting next_dagrun for execute_python_operators to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
2025-09-08 00:00:01,385 INFO - 1 tasks up for execution:
	<TaskInstance: execute_python_operators.greet_hello scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 00:00:01,386 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-08 00:00:01,386 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.greet_hello scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 00:00:01,387 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.greet_hello scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 00:00:01,388 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='greet_hello', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 00:00:01,388 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-08 00:00:01,392 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-08 00:00:03,029 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']' returned non-zero exit status 1..
2025-09-08 00:00:03,031 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='greet_hello', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 00:00:03,037 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=greet_hello, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 00:00:01.386932+00:00, queued_by_job_id=3, pid=None
2025-09-08 00:00:03,038 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: execute_python_operators.greet_hello scheduled__2025-09-07T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-09-08 00:00:03,045 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: execute_python_operators.greet_hello scheduled__2025-09-07T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-09-08 00:00:03,058 INFO - Marking task as FAILED. dag_id=execute_python_operators, task_id=greet_hello, run_id=scheduled__2025-09-07T00:00:00+00:00, execution_date=20250907T000000, start_date=, end_date=20250908T000003
2025-09-08 00:00:04,352 ERROR - Marking run <DagRun execute_python_operators @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 00:00:01.354671+00:00. externally triggered: False> failed
2025-09-08 00:00:04,353 INFO - DagRun Finished: dag_id=execute_python_operators, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 00:00:01.368002+00:00, run_end_date=2025-09-08 00:00:04.353347+00:00, run_duration=2.985345, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=5aa081e1c0111128739363027a59d9be
2025-09-08 00:00:04,357 INFO - Setting next_dagrun for execute_python_operators to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
2025-09-08 00:00:08,483 INFO - 1 tasks up for execution:
	<TaskInstance: execute_python_operators.greet_hello manual__2025-09-08T00:00:07.467811+00:00 [scheduled]>
2025-09-08 00:00:08,484 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-08 00:00:08,484 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.greet_hello manual__2025-09-08T00:00:07.467811+00:00 [scheduled]>
2025-09-08 00:00:08,485 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.greet_hello manual__2025-09-08T00:00:07.467811+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 00:00:08,486 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='greet_hello', run_id='manual__2025-09-08T00:00:07.467811+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 00:00:08,486 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello', 'manual__2025-09-08T00:00:07.467811+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-08 00:00:08,490 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello', 'manual__2025-09-08T00:00:07.467811+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-08 00:00:10,081 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello', 'manual__2025-09-08T00:00:07.467811+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']' returned non-zero exit status 1..
2025-09-08 00:00:10,081 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='greet_hello', run_id='manual__2025-09-08T00:00:07.467811+00:00', try_number=1, map_index=-1)
2025-09-08 00:00:10,084 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=greet_hello, run_id=manual__2025-09-08T00:00:07.467811+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 00:00:08.485095+00:00, queued_by_job_id=3, pid=None
2025-09-08 00:00:10,085 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: execute_python_operators.greet_hello manual__2025-09-08T00:00:07.467811+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-09-08 00:00:10,090 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: execute_python_operators.greet_hello manual__2025-09-08T00:00:07.467811+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-09-08 00:00:10,094 INFO - Marking task as FAILED. dag_id=execute_python_operators, task_id=greet_hello, run_id=manual__2025-09-08T00:00:07.467811+00:00, execution_date=20250908T000007, start_date=, end_date=20250908T000010
2025-09-08 00:00:10,401 ERROR - Marking run <DagRun execute_python_operators @ 2025-09-08 00:00:07.467811+00:00: manual__2025-09-08T00:00:07.467811+00:00, state:running, queued_at: 2025-09-08 00:00:07.475734+00:00. externally triggered: True> failed
2025-09-08 00:00:10,402 INFO - DagRun Finished: dag_id=execute_python_operators, execution_date=2025-09-08 00:00:07.467811+00:00, run_id=manual__2025-09-08T00:00:07.467811+00:00, run_start_date=2025-09-08 00:00:08.466506+00:00, run_end_date=2025-09-08 00:00:10.402208+00:00, run_duration=1.935702, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=5aa081e1c0111128739363027a59d9be
2025-09-08 00:02:44,513 INFO - 1 tasks up for execution:
	<TaskInstance: execute_python_operators.taskA manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>
2025-09-08 00:02:44,514 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-08 00:02:44,514 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.taskA manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>
2025-09-08 00:02:44,515 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.taskA manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 00:02:44,516 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='taskA', run_id='manual__2025-09-08T00:02:43.828724+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 00:02:44,516 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskA', 'manual__2025-09-08T00:02:43.828724+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-08 00:02:44,520 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskA', 'manual__2025-09-08T00:02:43.828724+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_python_operators.py']
2025-09-08 00:02:46,497 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='taskA', run_id='manual__2025-09-08T00:02:43.828724+00:00', try_number=1, map_index=-1)
2025-09-08 00:02:46,500 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=taskA, run_id=manual__2025-09-08T00:02:43.828724+00:00, map_index=-1, run_start_date=2025-09-08 00:02:46.072867+00:00, run_end_date=2025-09-08 00:02:46.182973+00:00, run_duration=0.110106, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=34, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-09-08 00:02:44.515176+00:00, queued_by_job_id=3, pid=54942
2025-09-08 00:02:46,660 INFO - 2 tasks up for execution:
	<TaskInstance: execute_python_operators.taskB manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>
	<TaskInstance: execute_python_operators.taskC manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>
2025-09-08 00:02:46,661 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-08 00:02:46,661 INFO - DAG execute_python_operators has 1/16 running and queued tasks
2025-09-08 00:02:46,661 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.taskB manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>
	<TaskInstance: execute_python_operators.taskC manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>
2025-09-08 00:02:46,663 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.taskB manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>, <TaskInstance: execute_python_operators.taskC manual__2025-09-08T00:02:43.828724+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 00:02:46,663 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='taskB', run_id='manual__2025-09-08T00:02:43.828724+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 00:02:46,663 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskB', 'manual__2025-09-08T00:02:43.828724+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-08 00:02:46,664 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='taskC', run_id='manual__2025-09-08T00:02:43.828724+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 00:02:46,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskC', 'manual__2025-09-08T00:02:43.828724+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-08 00:02:46,668 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskB', 'manual__2025-09-08T00:02:43.828724+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-08 00:02:48,204 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'execute_python_operators', 'taskB', 'manual__2025-09-08T00:02:43.828724+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']' returned non-zero exit status 1..
2025-09-08 00:02:48,204 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'taskC', 'manual__2025-09-08T00:02:43.828724+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-08 00:02:49,623 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'execute_python_operators', 'taskC', 'manual__2025-09-08T00:02:43.828724+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']' returned non-zero exit status 1..
2025-09-08 00:02:49,624 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='taskB', run_id='manual__2025-09-08T00:02:43.828724+00:00', try_number=1, map_index=-1)
2025-09-08 00:02:49,624 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='taskC', run_id='manual__2025-09-08T00:02:43.828724+00:00', try_number=1, map_index=-1)
2025-09-08 00:02:49,627 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=taskB, run_id=manual__2025-09-08T00:02:43.828724+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 00:02:46.662312+00:00, queued_by_job_id=3, pid=None
2025-09-08 00:02:49,627 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: execute_python_operators.taskB manual__2025-09-08T00:02:43.828724+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-09-08 00:02:49,632 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: execute_python_operators.taskB manual__2025-09-08T00:02:43.828724+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-09-08 00:02:49,636 INFO - Marking task as FAILED. dag_id=execute_python_operators, task_id=taskB, run_id=manual__2025-09-08T00:02:43.828724+00:00, execution_date=20250908T000243, start_date=, end_date=20250908T000249
2025-09-08 00:02:49,643 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=taskC, run_id=manual__2025-09-08T00:02:43.828724+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 00:02:46.662312+00:00, queued_by_job_id=3, pid=None
2025-09-08 00:02:49,644 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: execute_python_operators.taskC manual__2025-09-08T00:02:43.828724+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-09-08 00:02:49,649 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: execute_python_operators.taskC manual__2025-09-08T00:02:43.828724+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-09-08 00:02:49,653 INFO - Marking task as FAILED. dag_id=execute_python_operators, task_id=taskC, run_id=manual__2025-09-08T00:02:43.828724+00:00, execution_date=20250908T000243, start_date=, end_date=20250908T000249
2025-09-08 00:02:49,671 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 00:02:50,735 ERROR - Marking run <DagRun execute_python_operators @ 2025-09-08 00:02:43.828724+00:00: manual__2025-09-08T00:02:43.828724+00:00, state:running, queued_at: 2025-09-08 00:02:43.833931+00:00. externally triggered: True> failed
2025-09-08 00:02:50,735 INFO - DagRun Finished: dag_id=execute_python_operators, execution_date=2025-09-08 00:02:43.828724+00:00, run_id=manual__2025-09-08T00:02:43.828724+00:00, run_start_date=2025-09-08 00:02:44.495908+00:00, run_end_date=2025-09-08 00:02:50.735599+00:00, run_duration=6.239691, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=96a25dd9e1ad942b4a0577665f00465e
2025-09-08 00:03:19,969 INFO - 1 tasks up for execution:
	<TaskInstance: execute_python_operators.greet_hello manual__2025-09-08T00:03:18.378179+00:00 [scheduled]>
2025-09-08 00:03:19,970 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-08 00:03:19,970 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.greet_hello manual__2025-09-08T00:03:18.378179+00:00 [scheduled]>
2025-09-08 00:03:19,972 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.greet_hello manual__2025-09-08T00:03:18.378179+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 00:03:19,973 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='greet_hello', run_id='manual__2025-09-08T00:03:18.378179+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 00:03:19,974 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello', 'manual__2025-09-08T00:03:18.378179+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-08 00:03:19,978 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello', 'manual__2025-09-08T00:03:18.378179+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-08 00:03:21,826 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='greet_hello', run_id='manual__2025-09-08T00:03:18.378179+00:00', try_number=1, map_index=-1)
2025-09-08 00:03:21,829 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=greet_hello, run_id=manual__2025-09-08T00:03:18.378179+00:00, map_index=-1, run_start_date=2025-09-08 00:03:21.380970+00:00, run_end_date=2025-09-08 00:03:21.485754+00:00, run_duration=0.104784, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=35, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 00:03:19.971773+00:00, queued_by_job_id=3, pid=55211
2025-09-08 00:03:21,880 INFO - 1 tasks up for execution:
	<TaskInstance: execute_python_operators.greet_hello_with_city manual__2025-09-08T00:03:18.378179+00:00 [scheduled]>
2025-09-08 00:03:21,880 INFO - DAG execute_python_operators has 0/16 running and queued tasks
2025-09-08 00:03:21,881 INFO - Setting the following tasks to queued state:
	<TaskInstance: execute_python_operators.greet_hello_with_city manual__2025-09-08T00:03:18.378179+00:00 [scheduled]>
2025-09-08 00:03:21,882 INFO - Trying to enqueue tasks: [<TaskInstance: execute_python_operators.greet_hello_with_city manual__2025-09-08T00:03:18.378179+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 00:03:21,882 INFO - Sending TaskInstanceKey(dag_id='execute_python_operators', task_id='greet_hello_with_city', run_id='manual__2025-09-08T00:03:18.378179+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 00:03:21,883 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello_with_city', 'manual__2025-09-08T00:03:18.378179+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-08 00:03:21,886 INFO - Executing command: ['airflow', 'tasks', 'run', 'execute_python_operators', 'greet_hello_with_city', 'manual__2025-09-08T00:03:18.378179+00:00', '--local', '--subdir', 'DAGS_FOLDER/execute_multiple_tasks.py']
2025-09-08 00:03:23,704 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='execute_python_operators', task_id='greet_hello_with_city', run_id='manual__2025-09-08T00:03:18.378179+00:00', try_number=1, map_index=-1)
2025-09-08 00:03:23,707 INFO - TaskInstance Finished: dag_id=execute_python_operators, task_id=greet_hello_with_city, run_id=manual__2025-09-08T00:03:18.378179+00:00, map_index=-1, run_start_date=2025-09-08 00:03:23.258310+00:00, run_end_date=2025-09-08 00:03:23.362293+00:00, run_duration=0.103983, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 00:03:21.881639+00:00, queued_by_job_id=3, pid=55222
2025-09-08 00:03:23,731 INFO - Marking run <DagRun execute_python_operators @ 2025-09-08 00:03:18.378179+00:00: manual__2025-09-08T00:03:18.378179+00:00, state:running, queued_at: 2025-09-08 00:03:18.383383+00:00. externally triggered: True> successful
2025-09-08 00:03:23,731 INFO - DagRun Finished: dag_id=execute_python_operators, execution_date=2025-09-08 00:03:18.378179+00:00, run_id=manual__2025-09-08T00:03:18.378179+00:00, run_start_date=2025-09-08 00:03:19.939491+00:00, run_end_date=2025-09-08 00:03:23.731503+00:00, run_duration=3.792012, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=bc32a02210259ab65436b61401a8e504
2025-09-08 00:05:09,823 INFO - Setting next_dagrun for cross_task_communication to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
2025-09-08 00:05:09,851 INFO - 2 tasks up for execution:
	<TaskInstance: cross_task_communication.increment_by_1 scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cross_task_communication.increment_by_1 manual__2025-09-08T00:05:08.954634+00:00 [scheduled]>
2025-09-08 00:05:09,852 INFO - DAG cross_task_communication has 0/16 running and queued tasks
2025-09-08 00:05:09,852 INFO - DAG cross_task_communication has 1/16 running and queued tasks
2025-09-08 00:05:09,852 INFO - Setting the following tasks to queued state:
	<TaskInstance: cross_task_communication.increment_by_1 scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cross_task_communication.increment_by_1 manual__2025-09-08T00:05:08.954634+00:00 [scheduled]>
2025-09-08 00:05:09,855 INFO - Trying to enqueue tasks: [<TaskInstance: cross_task_communication.increment_by_1 scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cross_task_communication.increment_by_1 manual__2025-09-08T00:05:08.954634+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 00:05:09,855 INFO - Sending TaskInstanceKey(dag_id='cross_task_communication', task_id='increment_by_1', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 00:05:09,856 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cross_task_communication', 'increment_by_1', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 00:05:09,856 INFO - Sending TaskInstanceKey(dag_id='cross_task_communication', task_id='increment_by_1', run_id='manual__2025-09-08T00:05:08.954634+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 00:05:09,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cross_task_communication', 'increment_by_1', 'manual__2025-09-08T00:05:08.954634+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 00:05:09,868 INFO - Executing command: ['airflow', 'tasks', 'run', 'cross_task_communication', 'increment_by_1', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 00:05:11,754 INFO - Executing command: ['airflow', 'tasks', 'run', 'cross_task_communication', 'increment_by_1', 'manual__2025-09-08T00:05:08.954634+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 00:05:13,796 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cross_task_communication', task_id='increment_by_1', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 00:05:13,797 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cross_task_communication', task_id='increment_by_1', run_id='manual__2025-09-08T00:05:08.954634+00:00', try_number=1, map_index=-1)
2025-09-08 00:05:13,802 INFO - TaskInstance Finished: dag_id=cross_task_communication, task_id=increment_by_1, run_id=manual__2025-09-08T00:05:08.954634+00:00, map_index=-1, run_start_date=2025-09-08 00:05:13.366835+00:00, run_end_date=2025-09-08 00:05:13.478249+00:00, run_duration=0.111414, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=38, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 00:05:09.853424+00:00, queued_by_job_id=3, pid=56079
2025-09-08 00:05:13,802 INFO - TaskInstance Finished: dag_id=cross_task_communication, task_id=increment_by_1, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 00:05:11.324745+00:00, run_end_date=2025-09-08 00:05:11.437150+00:00, run_duration=0.112405, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=37, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 00:05:09.853424+00:00, queued_by_job_id=3, pid=56062
2025-09-08 00:05:13,962 INFO - 2 tasks up for execution:
	<TaskInstance: cross_task_communication.multiply_by_100 scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cross_task_communication.multiply_by_100 manual__2025-09-08T00:05:08.954634+00:00 [scheduled]>
2025-09-08 00:05:13,963 INFO - DAG cross_task_communication has 0/16 running and queued tasks
2025-09-08 00:05:13,963 INFO - DAG cross_task_communication has 1/16 running and queued tasks
2025-09-08 00:05:13,963 INFO - Setting the following tasks to queued state:
	<TaskInstance: cross_task_communication.multiply_by_100 scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cross_task_communication.multiply_by_100 manual__2025-09-08T00:05:08.954634+00:00 [scheduled]>
2025-09-08 00:05:13,965 INFO - Trying to enqueue tasks: [<TaskInstance: cross_task_communication.multiply_by_100 scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cross_task_communication.multiply_by_100 manual__2025-09-08T00:05:08.954634+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 00:05:13,965 INFO - Sending TaskInstanceKey(dag_id='cross_task_communication', task_id='multiply_by_100', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 00:05:13,965 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cross_task_communication', 'multiply_by_100', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 00:05:13,966 INFO - Sending TaskInstanceKey(dag_id='cross_task_communication', task_id='multiply_by_100', run_id='manual__2025-09-08T00:05:08.954634+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 00:05:13,966 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cross_task_communication', 'multiply_by_100', 'manual__2025-09-08T00:05:08.954634+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 00:05:13,970 INFO - Executing command: ['airflow', 'tasks', 'run', 'cross_task_communication', 'multiply_by_100', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 00:05:15,779 INFO - Executing command: ['airflow', 'tasks', 'run', 'cross_task_communication', 'multiply_by_100', 'manual__2025-09-08T00:05:08.954634+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 00:05:17,667 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cross_task_communication', task_id='multiply_by_100', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 00:05:17,667 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cross_task_communication', task_id='multiply_by_100', run_id='manual__2025-09-08T00:05:08.954634+00:00', try_number=1, map_index=-1)
2025-09-08 00:05:17,670 INFO - TaskInstance Finished: dag_id=cross_task_communication, task_id=multiply_by_100, run_id=manual__2025-09-08T00:05:08.954634+00:00, map_index=-1, run_start_date=2025-09-08 00:05:17.238839+00:00, run_end_date=2025-09-08 00:05:17.370082+00:00, run_duration=0.131243, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=40, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 00:05:13.964373+00:00, queued_by_job_id=3, pid=56096
2025-09-08 00:05:17,671 INFO - TaskInstance Finished: dag_id=cross_task_communication, task_id=multiply_by_100, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 00:05:15.361675+00:00, run_end_date=2025-09-08 00:05:15.496878+00:00, run_duration=0.135203, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=39, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 00:05:13.964373+00:00, queued_by_job_id=3, pid=56091
2025-09-08 00:05:17,818 INFO - Marking run <DagRun cross_task_communication @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 00:05:09.819130+00:00. externally triggered: False> successful
2025-09-08 00:05:17,819 INFO - DagRun Finished: dag_id=cross_task_communication, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 00:05:09.831530+00:00, run_end_date=2025-09-08 00:05:17.819262+00:00, run_duration=7.987732, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=2b7be5bfa024f39269d8350060e88ac7
2025-09-08 00:05:17,821 INFO - Setting next_dagrun for cross_task_communication to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
2025-09-08 00:05:17,823 INFO - Marking run <DagRun cross_task_communication @ 2025-09-08 00:05:08.954634+00:00: manual__2025-09-08T00:05:08.954634+00:00, state:running, queued_at: 2025-09-08 00:05:08.965928+00:00. externally triggered: True> successful
2025-09-08 00:05:17,823 INFO - DagRun Finished: dag_id=cross_task_communication, execution_date=2025-09-08 00:05:08.954634+00:00, run_id=manual__2025-09-08T00:05:08.954634+00:00, run_start_date=2025-09-08 00:05:09.831681+00:00, run_end_date=2025-09-08 00:05:17.823531+00:00, run_duration=7.99185, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=2b7be5bfa024f39269d8350060e88ac7
2025-09-08 15:13:35,621 INFO - Loaded executor: SequentialExecutor
2025-09-08 15:13:35,689 INFO - Starting the scheduler
2025-09-08 15:13:35,692 INFO - Processing each file at most -1 times
2025-09-08 15:13:35,704 INFO - Launched DagFileProcessorManager with pid: 6988
2025-09-08 15:13:35,705 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:13:35,714 INFO - Configured default timezone UTC
2025-09-08 15:13:35,717 INFO - Marked 1 SchedulerJob instances as failed
2025-09-08 15:13:55,819 INFO - 1 tasks up for execution:
	<TaskInstance: cross_task_communication.increment_by_1 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>
2025-09-08 15:13:55,819 INFO - DAG cross_task_communication has 0/16 running and queued tasks
2025-09-08 15:13:55,819 INFO - Setting the following tasks to queued state:
	<TaskInstance: cross_task_communication.increment_by_1 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>
2025-09-08 15:13:55,821 INFO - Trying to enqueue tasks: [<TaskInstance: cross_task_communication.increment_by_1 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:13:55,822 INFO - Sending TaskInstanceKey(dag_id='cross_task_communication', task_id='increment_by_1', run_id='manual__2025-09-08T15:13:54.269605+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:13:55,822 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cross_task_communication', 'increment_by_1', 'manual__2025-09-08T15:13:54.269605+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 15:13:55,826 INFO - Executing command: ['airflow', 'tasks', 'run', 'cross_task_communication', 'increment_by_1', 'manual__2025-09-08T15:13:54.269605+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 15:13:57,820 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cross_task_communication', task_id='increment_by_1', run_id='manual__2025-09-08T15:13:54.269605+00:00', try_number=1, map_index=-1)
2025-09-08 15:13:57,825 INFO - TaskInstance Finished: dag_id=cross_task_communication, task_id=increment_by_1, run_id=manual__2025-09-08T15:13:54.269605+00:00, map_index=-1, run_start_date=2025-09-08 15:13:57.416852+00:00, run_end_date=2025-09-08 15:13:57.530444+00:00, run_duration=0.113592, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=42, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-09-08 15:13:55.820406+00:00, queued_by_job_id=41, pid=7161
2025-09-08 15:13:57,880 INFO - 1 tasks up for execution:
	<TaskInstance: cross_task_communication.multiply_by_100 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>
2025-09-08 15:13:57,880 INFO - DAG cross_task_communication has 0/16 running and queued tasks
2025-09-08 15:13:57,881 INFO - Setting the following tasks to queued state:
	<TaskInstance: cross_task_communication.multiply_by_100 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>
2025-09-08 15:13:57,882 INFO - Trying to enqueue tasks: [<TaskInstance: cross_task_communication.multiply_by_100 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:13:57,882 INFO - Sending TaskInstanceKey(dag_id='cross_task_communication', task_id='multiply_by_100', run_id='manual__2025-09-08T15:13:54.269605+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2025-09-08 15:13:57,883 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cross_task_communication', 'multiply_by_100', 'manual__2025-09-08T15:13:54.269605+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 15:13:57,887 INFO - Executing command: ['airflow', 'tasks', 'run', 'cross_task_communication', 'multiply_by_100', 'manual__2025-09-08T15:13:54.269605+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 15:13:59,797 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cross_task_communication', task_id='multiply_by_100', run_id='manual__2025-09-08T15:13:54.269605+00:00', try_number=1, map_index=-1)
2025-09-08 15:13:59,800 INFO - TaskInstance Finished: dag_id=cross_task_communication, task_id=multiply_by_100, run_id=manual__2025-09-08T15:13:54.269605+00:00, map_index=-1, run_start_date=2025-09-08 15:13:59.368517+00:00, run_end_date=2025-09-08 15:13:59.492974+00:00, run_duration=0.124457, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=43, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-09-08 15:13:57.881619+00:00, queued_by_job_id=41, pid=7172
2025-09-08 15:13:59,832 INFO - 1 tasks up for execution:
	<TaskInstance: cross_task_communication.subtract_9 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>
2025-09-08 15:13:59,833 INFO - DAG cross_task_communication has 0/16 running and queued tasks
2025-09-08 15:13:59,833 INFO - Setting the following tasks to queued state:
	<TaskInstance: cross_task_communication.subtract_9 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>
2025-09-08 15:13:59,834 INFO - Trying to enqueue tasks: [<TaskInstance: cross_task_communication.subtract_9 manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:13:59,835 INFO - Sending TaskInstanceKey(dag_id='cross_task_communication', task_id='subtract_9', run_id='manual__2025-09-08T15:13:54.269605+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 15:13:59,835 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cross_task_communication', 'subtract_9', 'manual__2025-09-08T15:13:54.269605+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 15:13:59,839 INFO - Executing command: ['airflow', 'tasks', 'run', 'cross_task_communication', 'subtract_9', 'manual__2025-09-08T15:13:54.269605+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 15:14:01,829 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cross_task_communication', task_id='subtract_9', run_id='manual__2025-09-08T15:13:54.269605+00:00', try_number=1, map_index=-1)
2025-09-08 15:14:01,832 INFO - TaskInstance Finished: dag_id=cross_task_communication, task_id=subtract_9, run_id=manual__2025-09-08T15:13:54.269605+00:00, map_index=-1, run_start_date=2025-09-08 15:14:01.383691+00:00, run_end_date=2025-09-08 15:14:01.502290+00:00, run_duration=0.118599, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=44, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 15:13:59.834132+00:00, queued_by_job_id=41, pid=7207
2025-09-08 15:14:01,876 INFO - 1 tasks up for execution:
	<TaskInstance: cross_task_communication.print_value manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>
2025-09-08 15:14:01,876 INFO - DAG cross_task_communication has 0/16 running and queued tasks
2025-09-08 15:14:01,877 INFO - Setting the following tasks to queued state:
	<TaskInstance: cross_task_communication.print_value manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>
2025-09-08 15:14:01,878 INFO - Trying to enqueue tasks: [<TaskInstance: cross_task_communication.print_value manual__2025-09-08T15:13:54.269605+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:14:01,878 INFO - Sending TaskInstanceKey(dag_id='cross_task_communication', task_id='print_value', run_id='manual__2025-09-08T15:13:54.269605+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:14:01,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cross_task_communication', 'print_value', 'manual__2025-09-08T15:13:54.269605+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 15:14:01,883 INFO - Executing command: ['airflow', 'tasks', 'run', 'cross_task_communication', 'print_value', 'manual__2025-09-08T15:13:54.269605+00:00', '--local', '--subdir', 'DAGS_FOLDER/cross_task_communication.py']
2025-09-08 15:14:03,736 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cross_task_communication', task_id='print_value', run_id='manual__2025-09-08T15:13:54.269605+00:00', try_number=1, map_index=-1)
2025-09-08 15:14:03,739 INFO - TaskInstance Finished: dag_id=cross_task_communication, task_id=print_value, run_id=manual__2025-09-08T15:13:54.269605+00:00, map_index=-1, run_start_date=2025-09-08 15:14:03.327222+00:00, run_end_date=2025-09-08 15:14:03.435739+00:00, run_duration=0.108517, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=45, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:14:01.877683+00:00, queued_by_job_id=41, pid=7218
2025-09-08 15:14:03,770 INFO - Marking run <DagRun cross_task_communication @ 2025-09-08 15:13:54.269605+00:00: manual__2025-09-08T15:13:54.269605+00:00, state:running, queued_at: 2025-09-08 15:13:54.285076+00:00. externally triggered: True> successful
2025-09-08 15:14:03,770 INFO - DagRun Finished: dag_id=cross_task_communication, execution_date=2025-09-08 15:13:54.269605+00:00, run_id=manual__2025-09-08T15:13:54.269605+00:00, run_start_date=2025-09-08 15:13:55.788713+00:00, run_end_date=2025-09-08 15:14:03.770890+00:00, run_duration=7.982177, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=4a83f29e6ed6d85c6ece60cce22fc607
2025-09-08 15:18:07,319 INFO - Setting next_dagrun for python_pipeline to None, run_after=None
2025-09-08 15:18:07,371 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 15:18:07,371 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:18:07,372 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 15:18:07,373 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:18:07,373 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:18:07,374 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:18:07,378 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:18:09,666 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 15:18:09,671 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=read_csv_file, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 15:18:09.100043+00:00, run_end_date=2025-09-08 15:18:09.220210+00:00, run_duration=0.120167, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=46, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:18:07.372729+00:00, queued_by_job_id=41, pid=9184
2025-09-08 15:18:09,835 ERROR - Marking run <DagRun python_pipeline @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 15:18:07.308990+00:00. externally triggered: False> failed
2025-09-08 15:18:09,836 INFO - DagRun Finished: dag_id=python_pipeline, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 15:18:07.354259+00:00, run_end_date=2025-09-08 15:18:09.836366+00:00, run_duration=2.482107, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=51f7da6e55b7cc7831ba1a57b24b6930
2025-09-08 15:18:09,838 INFO - Setting next_dagrun for python_pipeline to None, run_after=None
2025-09-08 15:18:35,768 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:19:44,213 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:19:43.285026+00:00 [scheduled]>
2025-09-08 15:19:44,213 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:19:44,213 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:19:43.285026+00:00 [scheduled]>
2025-09-08 15:19:44,214 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:19:43.285026+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:19:44,215 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:19:43.285026+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:19:44,215 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:19:43.285026+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:19:44,219 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:19:43.285026+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:19:46,548 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:19:43.285026+00:00', try_number=1, map_index=-1)
2025-09-08 15:19:46,551 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T15:19:43.285026+00:00, map_index=-1, run_start_date=2025-09-08 15:19:46.000716+00:00, run_end_date=2025-09-08 15:19:46.199278+00:00, run_duration=0.198562, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=47, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:19:44.214315+00:00, queued_by_job_id=41, pid=9897
2025-09-08 15:19:46,820 INFO - Marking run <DagRun python_pipeline @ 2025-09-08 15:19:43.285026+00:00: manual__2025-09-08T15:19:43.285026+00:00, state:running, queued_at: 2025-09-08 15:19:43.290801+00:00. externally triggered: True> successful
2025-09-08 15:19:46,820 INFO - DagRun Finished: dag_id=python_pipeline, execution_date=2025-09-08 15:19:43.285026+00:00, run_id=manual__2025-09-08T15:19:43.285026+00:00, run_start_date=2025-09-08 15:19:44.195802+00:00, run_end_date=2025-09-08 15:19:46.820475+00:00, run_duration=2.624673, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:19:43.285026+00:00, data_interval_end=2025-09-08 15:19:43.285026+00:00, dag_hash=51f7da6e55b7cc7831ba1a57b24b6930
2025-09-08 15:21:07,080 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:21:06.864985+00:00 [scheduled]>
2025-09-08 15:21:07,081 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:21:07,081 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:21:06.864985+00:00 [scheduled]>
2025-09-08 15:21:07,083 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:21:06.864985+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:21:07,084 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:21:06.864985+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 15:21:07,084 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:21:06.864985+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:21:07,089 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:21:06.864985+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:21:09,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:21:06.864985+00:00', try_number=1, map_index=-1)
2025-09-08 15:21:09,547 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T15:21:06.864985+00:00, map_index=-1, run_start_date=2025-09-08 15:21:09.060852+00:00, run_end_date=2025-09-08 15:21:09.194450+00:00, run_duration=0.133598, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=48, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 15:21:07.082149+00:00, queued_by_job_id=41, pid=10531
2025-09-08 15:21:09,600 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:21:06.864985+00:00 [scheduled]>
2025-09-08 15:21:09,601 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:21:09,601 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:21:06.864985+00:00 [scheduled]>
2025-09-08 15:21:09,602 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:21:06.864985+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:21:09,603 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T15:21:06.864985+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:21:09,603 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'remove_null_values', 'manual__2025-09-08T15:21:06.864985+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:21:09,607 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'remove_null_values', 'manual__2025-09-08T15:21:06.864985+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:21:11,742 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T15:21:06.864985+00:00', try_number=1, map_index=-1)
2025-09-08 15:21:11,745 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=remove_null_values, run_id=manual__2025-09-08T15:21:06.864985+00:00, map_index=-1, run_start_date=2025-09-08 15:21:11.231389+00:00, run_end_date=2025-09-08 15:21:11.393266+00:00, run_duration=0.161877, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=49, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:21:09.601959+00:00, queued_by_job_id=41, pid=10543
2025-09-08 15:21:11,782 INFO - Marking run <DagRun python_pipeline @ 2025-09-08 15:21:06.864985+00:00: manual__2025-09-08T15:21:06.864985+00:00, state:running, queued_at: 2025-09-08 15:21:06.871937+00:00. externally triggered: True> successful
2025-09-08 15:21:11,782 INFO - DagRun Finished: dag_id=python_pipeline, execution_date=2025-09-08 15:21:06.864985+00:00, run_id=manual__2025-09-08T15:21:06.864985+00:00, run_start_date=2025-09-08 15:21:07.053630+00:00, run_end_date=2025-09-08 15:21:11.782346+00:00, run_duration=4.728716, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:21:06.864985+00:00, data_interval_end=2025-09-08 15:21:06.864985+00:00, dag_hash=9c007d544054c84d70068adea65271be
2025-09-08 15:22:31,459 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>
2025-09-08 15:22:31,460 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:22:31,460 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>
2025-09-08 15:22:31,461 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:22:31,462 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:22:30.034563+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:22:31,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:22:30.034563+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:22:31,467 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:22:30.034563+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:22:33,626 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:22:30.034563+00:00', try_number=1, map_index=-1)
2025-09-08 15:22:33,629 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T15:22:30.034563+00:00, map_index=-1, run_start_date=2025-09-08 15:22:33.044705+00:00, run_end_date=2025-09-08 15:22:33.209542+00:00, run_duration=0.164837, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=50, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-09-08 15:22:31.461146+00:00, queued_by_job_id=41, pid=11155
2025-09-08 15:22:33,676 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>
2025-09-08 15:22:33,677 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:22:33,677 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>
2025-09-08 15:22:33,678 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:22:33,679 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T15:22:30.034563+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2025-09-08 15:22:33,679 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'remove_null_values', 'manual__2025-09-08T15:22:30.034563+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:22:33,684 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'remove_null_values', 'manual__2025-09-08T15:22:30.034563+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:22:36,110 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T15:22:30.034563+00:00', try_number=1, map_index=-1)
2025-09-08 15:22:36,114 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=remove_null_values, run_id=manual__2025-09-08T15:22:30.034563+00:00, map_index=-1, run_start_date=2025-09-08 15:22:35.601339+00:00, run_end_date=2025-09-08 15:22:35.751465+00:00, run_duration=0.150126, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=51, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-09-08 15:22:33.677965+00:00, queued_by_job_id=41, pid=11180
2025-09-08 15:22:36,173 INFO - 2 tasks up for execution:
	<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>
	<TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>
2025-09-08 15:22:36,174 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:22:36,174 INFO - DAG python_pipeline has 1/16 running and queued tasks
2025-09-08 15:22:36,174 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>
	<TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>
2025-09-08 15:22:36,176 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>, <TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:22:30.034563+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:22:36,176 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_smoker', run_id='manual__2025-09-08T15:22:30.034563+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:22:36,176 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_smoker', 'manual__2025-09-08T15:22:30.034563+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:22:36,177 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_region', run_id='manual__2025-09-08T15:22:30.034563+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:22:36,177 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_region', 'manual__2025-09-08T15:22:30.034563+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:22:36,181 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_smoker', 'manual__2025-09-08T15:22:30.034563+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:22:38,424 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_region', 'manual__2025-09-08T15:22:30.034563+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:22:40,755 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_smoker', run_id='manual__2025-09-08T15:22:30.034563+00:00', try_number=1, map_index=-1)
2025-09-08 15:22:40,756 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_region', run_id='manual__2025-09-08T15:22:30.034563+00:00', try_number=1, map_index=-1)
2025-09-08 15:22:40,759 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=groupby_region, run_id=manual__2025-09-08T15:22:30.034563+00:00, map_index=-1, run_start_date=2025-09-08 15:22:40.216131+00:00, run_end_date=2025-09-08 15:22:40.352644+00:00, run_duration=0.136513, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=53, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:22:36.175273+00:00, queued_by_job_id=41, pid=11229
2025-09-08 15:22:40,759 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=groupby_smoker, run_id=manual__2025-09-08T15:22:30.034563+00:00, map_index=-1, run_start_date=2025-09-08 15:22:37.879514+00:00, run_end_date=2025-09-08 15:22:38.031223+00:00, run_duration=0.151709, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=52, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:22:36.175273+00:00, queued_by_job_id=41, pid=11192
2025-09-08 15:22:40,799 ERROR - Marking run <DagRun python_pipeline @ 2025-09-08 15:22:30.034563+00:00: manual__2025-09-08T15:22:30.034563+00:00, state:running, queued_at: 2025-09-08 15:22:30.039187+00:00. externally triggered: True> failed
2025-09-08 15:22:40,799 INFO - DagRun Finished: dag_id=python_pipeline, execution_date=2025-09-08 15:22:30.034563+00:00, run_id=manual__2025-09-08T15:22:30.034563+00:00, run_start_date=2025-09-08 15:22:31.441845+00:00, run_end_date=2025-09-08 15:22:40.799473+00:00, run_duration=9.357628, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:22:30.034563+00:00, data_interval_end=2025-09-08 15:22:30.034563+00:00, dag_hash=45c5d6619fd40b470c236d7f0f5bb925
2025-09-08 15:23:21,591 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>
2025-09-08 15:23:21,591 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:23:21,592 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>
2025-09-08 15:23:21,593 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:23:21,593 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:23:20.062640+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:23:21,594 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:23:20.062640+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:21,598 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:23:20.062640+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:23,753 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:23:20.062640+00:00', try_number=1, map_index=-1)
2025-09-08 15:23:23,757 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T15:23:20.062640+00:00, map_index=-1, run_start_date=2025-09-08 15:23:23.210917+00:00, run_end_date=2025-09-08 15:23:23.357792+00:00, run_duration=0.146875, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=54, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-09-08 15:23:21.592671+00:00, queued_by_job_id=41, pid=11554
2025-09-08 15:23:23,812 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>
2025-09-08 15:23:23,812 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:23:23,812 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>
2025-09-08 15:23:23,814 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:23:23,814 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T15:23:20.062640+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2025-09-08 15:23:23,814 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'remove_null_values', 'manual__2025-09-08T15:23:20.062640+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:23,818 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'remove_null_values', 'manual__2025-09-08T15:23:20.062640+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:26,086 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T15:23:20.062640+00:00', try_number=1, map_index=-1)
2025-09-08 15:23:26,090 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=remove_null_values, run_id=manual__2025-09-08T15:23:20.062640+00:00, map_index=-1, run_start_date=2025-09-08 15:23:25.567315+00:00, run_end_date=2025-09-08 15:23:25.716658+00:00, run_duration=0.149343, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=55, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-09-08 15:23:23.813345+00:00, queued_by_job_id=41, pid=11573
2025-09-08 15:23:26,244 INFO - 2 tasks up for execution:
	<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>
	<TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>
2025-09-08 15:23:26,245 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:23:26,245 INFO - DAG python_pipeline has 1/16 running and queued tasks
2025-09-08 15:23:26,245 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>
	<TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>
2025-09-08 15:23:26,247 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>, <TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:23:20.062640+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:23:26,247 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_smoker', run_id='manual__2025-09-08T15:23:20.062640+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:23:26,247 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_smoker', 'manual__2025-09-08T15:23:20.062640+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:26,248 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_region', run_id='manual__2025-09-08T15:23:20.062640+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:23:26,248 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_region', 'manual__2025-09-08T15:23:20.062640+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:26,253 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_smoker', 'manual__2025-09-08T15:23:20.062640+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:28,648 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_region', 'manual__2025-09-08T15:23:20.062640+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:31,215 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_smoker', run_id='manual__2025-09-08T15:23:20.062640+00:00', try_number=1, map_index=-1)
2025-09-08 15:23:31,215 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_region', run_id='manual__2025-09-08T15:23:20.062640+00:00', try_number=1, map_index=-1)
2025-09-08 15:23:31,218 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=groupby_region, run_id=manual__2025-09-08T15:23:20.062640+00:00, map_index=-1, run_start_date=2025-09-08 15:23:30.669442+00:00, run_end_date=2025-09-08 15:23:30.824396+00:00, run_duration=0.154954, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=57, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:23:26.246391+00:00, queued_by_job_id=41, pid=11627
2025-09-08 15:23:31,219 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=groupby_smoker, run_id=manual__2025-09-08T15:23:20.062640+00:00, map_index=-1, run_start_date=2025-09-08 15:23:27.997098+00:00, run_end_date=2025-09-08 15:23:28.128545+00:00, run_duration=0.131447, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=56, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:23:26.246391+00:00, queued_by_job_id=41, pid=11590
2025-09-08 15:23:31,270 ERROR - Marking run <DagRun python_pipeline @ 2025-09-08 15:23:20.062640+00:00: manual__2025-09-08T15:23:20.062640+00:00, state:running, queued_at: 2025-09-08 15:23:20.068441+00:00. externally triggered: True> failed
2025-09-08 15:23:31,271 INFO - DagRun Finished: dag_id=python_pipeline, execution_date=2025-09-08 15:23:20.062640+00:00, run_id=manual__2025-09-08T15:23:20.062640+00:00, run_start_date=2025-09-08 15:23:21.572739+00:00, run_end_date=2025-09-08 15:23:31.271287+00:00, run_duration=9.698548, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:23:20.062640+00:00, data_interval_end=2025-09-08 15:23:20.062640+00:00, dag_hash=45c5d6619fd40b470c236d7f0f5bb925
2025-09-08 15:23:35,797 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:23:45,881 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>
2025-09-08 15:23:45,882 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:23:45,882 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>
2025-09-08 15:23:45,883 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.read_csv_file manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:23:45,884 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:23:44.876235+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:23:45,884 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:23:44.876235+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:45,888 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'read_csv_file', 'manual__2025-09-08T15:23:44.876235+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:48,081 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T15:23:44.876235+00:00', try_number=1, map_index=-1)
2025-09-08 15:23:48,084 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T15:23:44.876235+00:00, map_index=-1, run_start_date=2025-09-08 15:23:47.588810+00:00, run_end_date=2025-09-08 15:23:47.726717+00:00, run_duration=0.137907, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=58, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-09-08 15:23:45.883169+00:00, queued_by_job_id=41, pid=11749
2025-09-08 15:23:48,250 INFO - 1 tasks up for execution:
	<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>
2025-09-08 15:23:48,251 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:23:48,251 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>
2025-09-08 15:23:48,252 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.remove_null_values manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:23:48,253 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T15:23:44.876235+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2025-09-08 15:23:48,253 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'remove_null_values', 'manual__2025-09-08T15:23:44.876235+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:48,259 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'remove_null_values', 'manual__2025-09-08T15:23:44.876235+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:50,484 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T15:23:44.876235+00:00', try_number=1, map_index=-1)
2025-09-08 15:23:50,487 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=remove_null_values, run_id=manual__2025-09-08T15:23:44.876235+00:00, map_index=-1, run_start_date=2025-09-08 15:23:49.986950+00:00, run_end_date=2025-09-08 15:23:50.134656+00:00, run_duration=0.147706, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=59, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-09-08 15:23:48.252201+00:00, queued_by_job_id=41, pid=11762
2025-09-08 15:23:50,642 INFO - 2 tasks up for execution:
	<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>
	<TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>
2025-09-08 15:23:50,642 INFO - DAG python_pipeline has 0/16 running and queued tasks
2025-09-08 15:23:50,642 INFO - DAG python_pipeline has 1/16 running and queued tasks
2025-09-08 15:23:50,643 INFO - Setting the following tasks to queued state:
	<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>
	<TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>
2025-09-08 15:23:50,644 INFO - Trying to enqueue tasks: [<TaskInstance: python_pipeline.groupby_smoker manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>, <TaskInstance: python_pipeline.groupby_region manual__2025-09-08T15:23:44.876235+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:23:50,644 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_smoker', run_id='manual__2025-09-08T15:23:44.876235+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:23:50,645 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_smoker', 'manual__2025-09-08T15:23:44.876235+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:50,645 INFO - Sending TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_region', run_id='manual__2025-09-08T15:23:44.876235+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:23:50,645 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_region', 'manual__2025-09-08T15:23:44.876235+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:50,650 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_smoker', 'manual__2025-09-08T15:23:44.876235+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:52,908 INFO - Executing command: ['airflow', 'tasks', 'run', 'python_pipeline', 'groupby_region', 'manual__2025-09-08T15:23:44.876235+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_python_pipeline.py']
2025-09-08 15:23:55,056 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_smoker', run_id='manual__2025-09-08T15:23:44.876235+00:00', try_number=1, map_index=-1)
2025-09-08 15:23:55,056 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='python_pipeline', task_id='groupby_region', run_id='manual__2025-09-08T15:23:44.876235+00:00', try_number=1, map_index=-1)
2025-09-08 15:23:55,060 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=groupby_region, run_id=manual__2025-09-08T15:23:44.876235+00:00, map_index=-1, run_start_date=2025-09-08 15:23:54.584919+00:00, run_end_date=2025-09-08 15:23:54.718581+00:00, run_duration=0.133662, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=61, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:23:50.643646+00:00, queued_by_job_id=41, pid=11813
2025-09-08 15:23:55,060 INFO - TaskInstance Finished: dag_id=python_pipeline, task_id=groupby_smoker, run_id=manual__2025-09-08T15:23:44.876235+00:00, map_index=-1, run_start_date=2025-09-08 15:23:52.445437+00:00, run_end_date=2025-09-08 15:23:52.578327+00:00, run_duration=0.13289, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=60, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 15:23:50.643646+00:00, queued_by_job_id=41, pid=11801
2025-09-08 15:23:55,216 INFO - Marking run <DagRun python_pipeline @ 2025-09-08 15:23:44.876235+00:00: manual__2025-09-08T15:23:44.876235+00:00, state:running, queued_at: 2025-09-08 15:23:44.881935+00:00. externally triggered: True> successful
2025-09-08 15:23:55,217 INFO - DagRun Finished: dag_id=python_pipeline, execution_date=2025-09-08 15:23:44.876235+00:00, run_id=manual__2025-09-08T15:23:44.876235+00:00, run_start_date=2025-09-08 15:23:45.863574+00:00, run_end_date=2025-09-08 15:23:55.217034+00:00, run_duration=9.35346, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:23:44.876235+00:00, data_interval_end=2025-09-08 15:23:44.876235+00:00, dag_hash=45c5d6619fd40b470c236d7f0f5bb925
2025-09-08 15:25:19,655 INFO - Setting next_dagrun for executing_sql_pipeline to None, run_after=None
2025-09-08 15:25:19,681 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.create_table scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 15:25:19,681 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:25:19,681 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.create_table scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 15:25:19,683 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.create_table scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:25:19,683 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:25:19,683 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:25:19,687 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:25:21,895 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 15:25:21,898 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=create_table, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 15:25:21.265855+00:00, run_end_date=2025-09-08 15:25:21.588368+00:00, run_duration=0.322513, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=62, pool=default_pool, queue=default, priority_weight=1, operator=SqliteOperator, queued_dttm=2025-09-08 15:25:19.682305+00:00, queued_by_job_id=41, pid=12479
2025-09-08 15:25:21,948 ERROR - Marking run <DagRun executing_sql_pipeline @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 15:25:19.652951+00:00. externally triggered: False> failed
2025-09-08 15:25:21,948 INFO - DagRun Finished: dag_id=executing_sql_pipeline, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 15:25:19.663691+00:00, run_end_date=2025-09-08 15:25:21.948688+00:00, run_duration=2.284997, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=b05138d59871aa55e1d34fa793650715
2025-09-08 15:25:21,950 INFO - Setting next_dagrun for executing_sql_pipeline to None, run_after=None
2025-09-08 15:28:35,836 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:31:46,266 INFO - Exiting gracefully upon receiving signal 15
2025-09-08 15:31:47,269 INFO - Sending 15 to group 6988. PIDs of all processes in the group: [6988]
2025-09-08 15:31:47,269 INFO - Sending the signal 15 to group 6988
2025-09-08 15:31:47,485 INFO - Process psutil.Process(pid=6988, status='terminated', exitcode=0, started='15:13:35') (6988) terminated with exit code 0
2025-09-08 15:31:47,487 INFO - Sending 15 to group 6988. PIDs of all processes in the group: []
2025-09-08 15:31:47,487 INFO - Sending the signal 15 to group 6988
2025-09-08 15:31:47,487 INFO - Sending the signal 15 to process 6988 as process group is missing.
2025-09-08 15:31:47,488 INFO - Exited execute loop
2025-09-08 15:32:07,422 INFO - Loaded executor: SequentialExecutor
2025-09-08 15:32:07,473 INFO - Starting the scheduler
2025-09-08 15:32:07,477 INFO - Processing each file at most -1 times
2025-09-08 15:32:07,486 INFO - Launched DagFileProcessorManager with pid: 16275
2025-09-08 15:32:07,489 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:32:07,495 INFO - Configured default timezone UTC
2025-09-08 15:32:28,845 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:32:27.724906+00:00 [scheduled]>
2025-09-08 15:32:28,845 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:32:28,846 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:32:27.724906+00:00 [scheduled]>
2025-09-08 15:32:28,848 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:32:27.724906+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:32:28,848 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:32:27.724906+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:32:28,848 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:32:27.724906+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:32:28,852 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:32:27.724906+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:32:30,904 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:32:27.724906+00:00', try_number=1, map_index=-1)
2025-09-08 15:32:30,912 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=create_table, run_id=manual__2025-09-08T15:32:27.724906+00:00, map_index=-1, run_start_date=2025-09-08 15:32:30.458987+00:00, run_end_date=2025-09-08 15:32:30.610291+00:00, run_duration=0.151304, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=64, pool=default_pool, queue=default, priority_weight=1, operator=SqliteOperator, queued_dttm=2025-09-08 15:32:28.846902+00:00, queued_by_job_id=63, pid=16474
2025-09-08 15:32:30,954 INFO - Marking run <DagRun executing_sql_pipeline @ 2025-09-08 15:32:27.724906+00:00: manual__2025-09-08T15:32:27.724906+00:00, state:running, queued_at: 2025-09-08 15:32:27.732756+00:00. externally triggered: True> successful
2025-09-08 15:32:30,955 INFO - DagRun Finished: dag_id=executing_sql_pipeline, execution_date=2025-09-08 15:32:27.724906+00:00, run_id=manual__2025-09-08T15:32:27.724906+00:00, run_start_date=2025-09-08 15:32:28.818556+00:00, run_end_date=2025-09-08 15:32:30.955713+00:00, run_duration=2.137157, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:32:27.724906+00:00, data_interval_end=2025-09-08 15:32:27.724906+00:00, dag_hash=b05138d59871aa55e1d34fa793650715
2025-09-08 15:34:09,007 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>
2025-09-08 15:34:09,007 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:34:09,008 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>
2025-09-08 15:34:09,010 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:34:09,010 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:34:07.941265+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:34:09,011 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:34:07.941265+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:34:09,014 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:34:07.941265+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:34:10,834 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:34:07.941265+00:00', try_number=1, map_index=-1)
2025-09-08 15:34:10,837 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=create_table, run_id=manual__2025-09-08T15:34:07.941265+00:00, map_index=-1, run_start_date=2025-09-08 15:34:10.427318+00:00, run_end_date=2025-09-08 15:34:10.555184+00:00, run_duration=0.127866, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=65, pool=default_pool, queue=default, priority_weight=4, operator=SqliteOperator, queued_dttm=2025-09-08 15:34:09.008948+00:00, queued_by_job_id=63, pid=17236
2025-09-08 15:34:10,889 INFO - 2 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>
	<TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>
2025-09-08 15:34:10,889 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:34:10,890 INFO - DAG executing_sql_pipeline has 1/16 running and queued tasks
2025-09-08 15:34:10,890 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>
	<TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>
2025-09-08 15:34:10,891 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>, <TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:34:10,892 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_1', run_id='manual__2025-09-08T15:34:07.941265+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 15:34:10,892 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_1', 'manual__2025-09-08T15:34:07.941265+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:34:10,892 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_2', run_id='manual__2025-09-08T15:34:07.941265+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 15:34:10,893 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_2', 'manual__2025-09-08T15:34:07.941265+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:34:10,897 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_1', 'manual__2025-09-08T15:34:07.941265+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:34:12,851 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_2', 'manual__2025-09-08T15:34:07.941265+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:34:14,723 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_1', run_id='manual__2025-09-08T15:34:07.941265+00:00', try_number=1, map_index=-1)
2025-09-08 15:34:14,723 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_2', run_id='manual__2025-09-08T15:34:07.941265+00:00', try_number=1, map_index=-1)
2025-09-08 15:34:14,729 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=insert_values_1, run_id=manual__2025-09-08T15:34:07.941265+00:00, map_index=-1, run_start_date=2025-09-08 15:34:12.454886+00:00, run_end_date=2025-09-08 15:34:12.588984+00:00, run_duration=0.134098, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=66, pool=default_pool, queue=default, priority_weight=2, operator=SqliteOperator, queued_dttm=2025-09-08 15:34:10.891100+00:00, queued_by_job_id=63, pid=17265
2025-09-08 15:34:14,730 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=insert_values_2, run_id=manual__2025-09-08T15:34:07.941265+00:00, map_index=-1, run_start_date=2025-09-08 15:34:14.243709+00:00, run_end_date=2025-09-08 15:34:14.405838+00:00, run_duration=0.162129, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=67, pool=default_pool, queue=default, priority_weight=2, operator=SqliteOperator, queued_dttm=2025-09-08 15:34:10.891100+00:00, queued_by_job_id=63, pid=17275
2025-09-08 15:34:15,200 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.display_result manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>
2025-09-08 15:34:15,200 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:34:15,200 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.display_result manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>
2025-09-08 15:34:15,201 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.display_result manual__2025-09-08T15:34:07.941265+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:34:15,202 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='display_result', run_id='manual__2025-09-08T15:34:07.941265+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:34:15,202 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'display_result', 'manual__2025-09-08T15:34:07.941265+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:34:15,206 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'display_result', 'manual__2025-09-08T15:34:07.941265+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:34:17,033 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='display_result', run_id='manual__2025-09-08T15:34:07.941265+00:00', try_number=1, map_index=-1)
2025-09-08 15:34:17,037 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=display_result, run_id=manual__2025-09-08T15:34:07.941265+00:00, map_index=-1, run_start_date=2025-09-08 15:34:16.590438+00:00, run_end_date=2025-09-08 15:34:16.759156+00:00, run_duration=0.168718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=68, pool=default_pool, queue=default, priority_weight=1, operator=SqliteOperator, queued_dttm=2025-09-08 15:34:15.201225+00:00, queued_by_job_id=63, pid=17295
2025-09-08 15:34:17,189 INFO - Marking run <DagRun executing_sql_pipeline @ 2025-09-08 15:34:07.941265+00:00: manual__2025-09-08T15:34:07.941265+00:00, state:running, queued_at: 2025-09-08 15:34:07.952401+00:00. externally triggered: True> successful
2025-09-08 15:34:17,190 INFO - DagRun Finished: dag_id=executing_sql_pipeline, execution_date=2025-09-08 15:34:07.941265+00:00, run_id=manual__2025-09-08T15:34:07.941265+00:00, run_start_date=2025-09-08 15:34:08.983734+00:00, run_end_date=2025-09-08 15:34:17.190202+00:00, run_duration=8.206468, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:34:07.941265+00:00, data_interval_end=2025-09-08 15:34:07.941265+00:00, dag_hash=946478d96624fa7f96130f4f4b674e5e
2025-09-08 15:35:11,585 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
2025-09-08 15:35:11,585 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:35:11,586 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
2025-09-08 15:35:11,587 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:35:11,587 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 15:35:11,588 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:11,593 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:13,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1)
2025-09-08 15:35:13,597 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=create_table, run_id=manual__2025-09-08T15:35:10.997528+00:00, map_index=-1, run_start_date=2025-09-08 15:35:13.170180+00:00, run_end_date=2025-09-08 15:35:13.297926+00:00, run_duration=0.127746, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=69, pool=default_pool, queue=default, priority_weight=6, operator=SqliteOperator, queued_dttm=2025-09-08 15:35:11.586543+00:00, queued_by_job_id=63, pid=17730
2025-09-08 15:35:13,649 INFO - 2 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
	<TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
2025-09-08 15:35:13,650 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:35:13,650 INFO - DAG executing_sql_pipeline has 1/16 running and queued tasks
2025-09-08 15:35:13,650 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
	<TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
2025-09-08 15:35:13,652 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>, <TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:35:13,652 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_1', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:35:13,652 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_1', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:13,653 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_2', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:35:13,653 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_2', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:13,657 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_1', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:15,546 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_2', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:17,388 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_1', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1)
2025-09-08 15:35:17,388 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_2', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1)
2025-09-08 15:35:17,391 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=insert_values_1, run_id=manual__2025-09-08T15:35:10.997528+00:00, map_index=-1, run_start_date=2025-09-08 15:35:15.148632+00:00, run_end_date=2025-09-08 15:35:15.287932+00:00, run_duration=0.1393, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=70, pool=default_pool, queue=default, priority_weight=4, operator=SqliteOperator, queued_dttm=2025-09-08 15:35:13.651259+00:00, queued_by_job_id=63, pid=17747
2025-09-08 15:35:17,392 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=insert_values_2, run_id=manual__2025-09-08T15:35:10.997528+00:00, map_index=-1, run_start_date=2025-09-08 15:35:16.963324+00:00, run_end_date=2025-09-08 15:35:17.094907+00:00, run_duration=0.131583, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=71, pool=default_pool, queue=default, priority_weight=4, operator=SqliteOperator, queued_dttm=2025-09-08 15:35:13.651259+00:00, queued_by_job_id=63, pid=17758
2025-09-08 15:35:17,950 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
2025-09-08 15:35:17,951 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:35:17,951 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
2025-09-08 15:35:17,952 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:35:17,953 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='delete_values', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2025-09-08 15:35:17,953 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'delete_values', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:17,961 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'delete_values', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:19,991 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='delete_values', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1)
2025-09-08 15:35:19,995 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=delete_values, run_id=manual__2025-09-08T15:35:10.997528+00:00, map_index=-1, run_start_date=2025-09-08 15:35:19.500921+00:00, run_end_date=2025-09-08 15:35:19.646294+00:00, run_duration=0.145373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=72, pool=default_pool, queue=default, priority_weight=3, operator=SqliteOperator, queued_dttm=2025-09-08 15:35:17.951984+00:00, queued_by_job_id=63, pid=17775
2025-09-08 15:35:20,164 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
2025-09-08 15:35:20,164 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:35:20,165 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>
2025-09-08 15:35:20,167 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:35:10.997528+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:35:20,167 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='update_values', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 15:35:20,168 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'update_values', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:20,173 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'update_values', 'manual__2025-09-08T15:35:10.997528+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:35:22,086 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='update_values', run_id='manual__2025-09-08T15:35:10.997528+00:00', try_number=1, map_index=-1)
2025-09-08 15:35:22,089 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=update_values, run_id=manual__2025-09-08T15:35:10.997528+00:00, map_index=-1, run_start_date=2025-09-08 15:35:21.641041+00:00, run_end_date=2025-09-08 15:35:21.780842+00:00, run_duration=0.139801, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=73, pool=default_pool, queue=default, priority_weight=2, operator=SqliteOperator, queued_dttm=2025-09-08 15:35:20.166469+00:00, queued_by_job_id=63, pid=17794
2025-09-08 15:35:22,236 ERROR - Marking run <DagRun executing_sql_pipeline @ 2025-09-08 15:35:10.997528+00:00: manual__2025-09-08T15:35:10.997528+00:00, state:running, queued_at: 2025-09-08 15:35:11.002193+00:00. externally triggered: True> failed
2025-09-08 15:35:22,236 INFO - DagRun Finished: dag_id=executing_sql_pipeline, execution_date=2025-09-08 15:35:10.997528+00:00, run_id=manual__2025-09-08T15:35:10.997528+00:00, run_start_date=2025-09-08 15:35:11.557348+00:00, run_end_date=2025-09-08 15:35:22.236870+00:00, run_duration=10.679522, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:35:10.997528+00:00, data_interval_end=2025-09-08 15:35:10.997528+00:00, dag_hash=e06107d889ccc9290730baadc593d0e1
2025-09-08 15:37:07,547 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:40:21,954 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
2025-09-08 15:40:21,954 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:40:21,954 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
2025-09-08 15:40:21,955 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:40:21,956 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 15:40:21,956 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:21,960 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:23,747 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1)
2025-09-08 15:40:23,751 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=create_table, run_id=manual__2025-09-08T15:40:20.624553+00:00, map_index=-1, run_start_date=2025-09-08 15:40:23.345517+00:00, run_end_date=2025-09-08 15:40:23.471706+00:00, run_duration=0.126189, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=74, pool=default_pool, queue=default, priority_weight=6, operator=SqliteOperator, queued_dttm=2025-09-08 15:40:21.955297+00:00, queued_by_job_id=63, pid=20299
2025-09-08 15:40:24,194 INFO - 2 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
	<TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
2025-09-08 15:40:24,195 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:40:24,195 INFO - DAG executing_sql_pipeline has 1/16 running and queued tasks
2025-09-08 15:40:24,196 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
	<TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
2025-09-08 15:40:24,197 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>, <TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:40:24,197 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_1', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:40:24,198 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_1', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:24,198 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_2', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:40:24,198 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_2', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:24,203 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_1', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:26,136 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_2', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:28,108 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_1', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1)
2025-09-08 15:40:28,108 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_2', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1)
2025-09-08 15:40:28,112 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=insert_values_1, run_id=manual__2025-09-08T15:40:20.624553+00:00, map_index=-1, run_start_date=2025-09-08 15:40:25.652406+00:00, run_end_date=2025-09-08 15:40:25.827502+00:00, run_duration=0.175096, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=75, pool=default_pool, queue=default, priority_weight=4, operator=SqliteOperator, queued_dttm=2025-09-08 15:40:24.196559+00:00, queued_by_job_id=63, pid=20316
2025-09-08 15:40:28,112 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=insert_values_2, run_id=manual__2025-09-08T15:40:20.624553+00:00, map_index=-1, run_start_date=2025-09-08 15:40:27.674893+00:00, run_end_date=2025-09-08 15:40:27.811859+00:00, run_duration=0.136966, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=76, pool=default_pool, queue=default, priority_weight=4, operator=SqliteOperator, queued_dttm=2025-09-08 15:40:24.196559+00:00, queued_by_job_id=63, pid=20351
2025-09-08 15:40:28,284 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
2025-09-08 15:40:28,284 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:40:28,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
2025-09-08 15:40:28,286 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:40:28,286 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='delete_values', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2025-09-08 15:40:28,286 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'delete_values', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:28,290 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'delete_values', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:30,209 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='delete_values', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1)
2025-09-08 15:40:30,212 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=delete_values, run_id=manual__2025-09-08T15:40:20.624553+00:00, map_index=-1, run_start_date=2025-09-08 15:40:29.783442+00:00, run_end_date=2025-09-08 15:40:29.917957+00:00, run_duration=0.134515, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=77, pool=default_pool, queue=default, priority_weight=3, operator=SqliteOperator, queued_dttm=2025-09-08 15:40:28.285301+00:00, queued_by_job_id=63, pid=20367
2025-09-08 15:40:30,370 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
2025-09-08 15:40:30,370 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:40:30,371 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>
2025-09-08 15:40:30,373 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:40:20.624553+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:40:30,374 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='update_values', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 15:40:30,375 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'update_values', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:30,384 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'update_values', 'manual__2025-09-08T15:40:20.624553+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:40:32,338 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='update_values', run_id='manual__2025-09-08T15:40:20.624553+00:00', try_number=1, map_index=-1)
2025-09-08 15:40:32,342 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=update_values, run_id=manual__2025-09-08T15:40:20.624553+00:00, map_index=-1, run_start_date=2025-09-08 15:40:31.921576+00:00, run_end_date=2025-09-08 15:40:32.057619+00:00, run_duration=0.136043, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=78, pool=default_pool, queue=default, priority_weight=2, operator=SqliteOperator, queued_dttm=2025-09-08 15:40:30.372167+00:00, queued_by_job_id=63, pid=20385
2025-09-08 15:40:32,488 ERROR - Marking run <DagRun executing_sql_pipeline @ 2025-09-08 15:40:20.624553+00:00: manual__2025-09-08T15:40:20.624553+00:00, state:running, queued_at: 2025-09-08 15:40:20.630403+00:00. externally triggered: True> failed
2025-09-08 15:40:32,489 INFO - DagRun Finished: dag_id=executing_sql_pipeline, execution_date=2025-09-08 15:40:20.624553+00:00, run_id=manual__2025-09-08T15:40:20.624553+00:00, run_start_date=2025-09-08 15:40:21.935098+00:00, run_end_date=2025-09-08 15:40:32.489302+00:00, run_duration=10.554204, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:40:20.624553+00:00, data_interval_end=2025-09-08 15:40:20.624553+00:00, dag_hash=e06107d889ccc9290730baadc593d0e1
2025-09-08 15:42:07,574 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:43:38,711 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:38,711 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:43:38,712 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:38,713 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.create_table manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:43:38,713 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 15:43:38,713 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:38,718 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'create_table', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:40,676 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='create_table', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1)
2025-09-08 15:43:40,681 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=create_table, run_id=manual__2025-09-08T15:43:37.740286+00:00, map_index=-1, run_start_date=2025-09-08 15:43:40.193645+00:00, run_end_date=2025-09-08 15:43:40.333091+00:00, run_duration=0.139446, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=79, pool=default_pool, queue=default, priority_weight=6, operator=SqliteOperator, queued_dttm=2025-09-08 15:43:38.712492+00:00, queued_by_job_id=63, pid=22293
2025-09-08 15:43:40,753 INFO - 2 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
	<TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:40,753 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:43:40,753 INFO - DAG executing_sql_pipeline has 1/16 running and queued tasks
2025-09-08 15:43:40,754 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
	<TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:40,755 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.insert_values_1 manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>, <TaskInstance: executing_sql_pipeline.insert_values_2 manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:43:40,755 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_1', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:43:40,756 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_1', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:40,756 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_2', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 15:43:40,756 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_2', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:40,760 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_1', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:42,723 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'insert_values_2', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:44,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_1', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1)
2025-09-08 15:43:44,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='insert_values_2', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1)
2025-09-08 15:43:44,597 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=insert_values_1, run_id=manual__2025-09-08T15:43:37.740286+00:00, map_index=-1, run_start_date=2025-09-08 15:43:42.269339+00:00, run_end_date=2025-09-08 15:43:42.416003+00:00, run_duration=0.146664, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=80, pool=default_pool, queue=default, priority_weight=4, operator=SqliteOperator, queued_dttm=2025-09-08 15:43:40.754793+00:00, queued_by_job_id=63, pid=22327
2025-09-08 15:43:44,598 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=insert_values_2, run_id=manual__2025-09-08T15:43:37.740286+00:00, map_index=-1, run_start_date=2025-09-08 15:43:44.180586+00:00, run_end_date=2025-09-08 15:43:44.313103+00:00, run_duration=0.132517, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=81, pool=default_pool, queue=default, priority_weight=4, operator=SqliteOperator, queued_dttm=2025-09-08 15:43:40.754793+00:00, queued_by_job_id=63, pid=22344
2025-09-08 15:43:44,752 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:44,752 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:43:44,752 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:44,754 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.delete_values manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:43:44,754 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='delete_values', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2025-09-08 15:43:44,754 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'delete_values', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:44,758 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'delete_values', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:46,627 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='delete_values', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1)
2025-09-08 15:43:46,631 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=delete_values, run_id=manual__2025-09-08T15:43:37.740286+00:00, map_index=-1, run_start_date=2025-09-08 15:43:46.163994+00:00, run_end_date=2025-09-08 15:43:46.299954+00:00, run_duration=0.13596, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=82, pool=default_pool, queue=default, priority_weight=3, operator=SqliteOperator, queued_dttm=2025-09-08 15:43:44.753384+00:00, queued_by_job_id=63, pid=22371
2025-09-08 15:43:46,690 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:46,691 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:43:46,691 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:46,692 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.update_values manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:43:46,693 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='update_values', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 15:43:46,693 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'update_values', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:46,697 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'update_values', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:48,767 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='update_values', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1)
2025-09-08 15:43:48,771 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=update_values, run_id=manual__2025-09-08T15:43:37.740286+00:00, map_index=-1, run_start_date=2025-09-08 15:43:48.320064+00:00, run_end_date=2025-09-08 15:43:48.474574+00:00, run_duration=0.15451, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=83, pool=default_pool, queue=default, priority_weight=2, operator=SqliteOperator, queued_dttm=2025-09-08 15:43:46.691915+00:00, queued_by_job_id=63, pid=22392
2025-09-08 15:43:48,816 INFO - 1 tasks up for execution:
	<TaskInstance: executing_sql_pipeline.display_result manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:48,816 INFO - DAG executing_sql_pipeline has 0/16 running and queued tasks
2025-09-08 15:43:48,817 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_sql_pipeline.display_result manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>
2025-09-08 15:43:48,818 INFO - Trying to enqueue tasks: [<TaskInstance: executing_sql_pipeline.display_result manual__2025-09-08T15:43:37.740286+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 15:43:48,818 INFO - Sending TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='display_result', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 15:43:48,819 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'display_result', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:48,823 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_sql_pipeline', 'display_result', 'manual__2025-09-08T15:43:37.740286+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_sql_pipeline.py']
2025-09-08 15:43:50,656 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_sql_pipeline', task_id='display_result', run_id='manual__2025-09-08T15:43:37.740286+00:00', try_number=1, map_index=-1)
2025-09-08 15:43:50,659 INFO - TaskInstance Finished: dag_id=executing_sql_pipeline, task_id=display_result, run_id=manual__2025-09-08T15:43:37.740286+00:00, map_index=-1, run_start_date=2025-09-08 15:43:50.251675+00:00, run_end_date=2025-09-08 15:43:50.386993+00:00, run_duration=0.135318, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=84, pool=default_pool, queue=default, priority_weight=1, operator=SqliteOperator, queued_dttm=2025-09-08 15:43:48.817610+00:00, queued_by_job_id=63, pid=22403
2025-09-08 15:43:50,683 INFO - Marking run <DagRun executing_sql_pipeline @ 2025-09-08 15:43:37.740286+00:00: manual__2025-09-08T15:43:37.740286+00:00, state:running, queued_at: 2025-09-08 15:43:37.745991+00:00. externally triggered: True> successful
2025-09-08 15:43:50,684 INFO - DagRun Finished: dag_id=executing_sql_pipeline, execution_date=2025-09-08 15:43:37.740286+00:00, run_id=manual__2025-09-08T15:43:37.740286+00:00, run_start_date=2025-09-08 15:43:38.691842+00:00, run_end_date=2025-09-08 15:43:50.684209+00:00, run_duration=11.992367, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 15:43:37.740286+00:00, data_interval_end=2025-09-08 15:43:37.740286+00:00, dag_hash=e06107d889ccc9290730baadc593d0e1
2025-09-08 15:47:07,713 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:52:07,740 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 15:57:07,768 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 16:02:07,795 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 16:07:07,838 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 16:12:07,880 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 16:38:05,844 INFO - Loaded executor: SequentialExecutor
2025-09-08 16:38:05,917 INFO - Starting the scheduler
2025-09-08 16:38:05,918 INFO - Processing each file at most -1 times
2025-09-08 16:38:05,931 INFO - Launched DagFileProcessorManager with pid: 4276
2025-09-08 16:38:05,933 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 16:38:05,940 INFO - Configured default timezone UTC
2025-09-08 16:38:05,946 INFO - Marked 1 SchedulerJob instances as failed
2025-09-08 16:40:03,797 INFO - Setting next_dagrun for branching_pipeline to None, run_after=None
2025-09-08 16:40:03,859 INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:40:03,859 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:40:03,860 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:40:03,861 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:40:03,862 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 16:40:03,862 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:03,867 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:06,381 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:40:06,387 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=read_csv_file, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:40:05.740952+00:00, run_end_date=2025-09-08 16:40:06.009073+00:00, run_duration=0.268121, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=86, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:40:03.860698+00:00, queued_by_job_id=85, pid=6291
2025-09-08 16:40:06,457 INFO - 2 tasks up for execution:
	<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:40:06,458 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:40:06,458 INFO - DAG branching_pipeline has 1/16 running and queued tasks
2025-09-08 16:40:06,458 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:40:06,460 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>, <TaskInstance: branching_pipeline.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:40:06,461 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 16:40:06,461 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:06,461 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 16:40:06,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:06,466 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:08,695 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:11,880 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1)
2025-09-08 16:40:11,881 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:40:11,887 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T16:40:03.512588+00:00, map_index=-1, run_start_date=2025-09-08 16:40:08.182706+00:00, run_end_date=2025-09-08 16:40:08.327021+00:00, run_duration=0.144315, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=87, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:40:06.459513+00:00, queued_by_job_id=85, pid=6310
2025-09-08 16:40:11,887 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=remove_null_values, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:40:11.288387+00:00, run_end_date=2025-09-08 16:40:11.455908+00:00, run_duration=0.167521, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=88, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:40:06.459513+00:00, queued_by_job_id=85, pid=6346
2025-09-08 16:40:12,074 INFO - 2 tasks up for execution:
	<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:40:12,075 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:40:12,075 INFO - DAG branching_pipeline has 1/16 running and queued tasks
2025-09-08 16:40:12,075 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:40:12,077 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>, <TaskInstance: branching_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:40:12,077 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 16:40:12,077 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:12,078 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 16:40:12,078 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:12,082 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:14,383 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:16,635 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1)
2025-09-08 16:40:16,636 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:40:16,639 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=remove_null_values, run_id=manual__2025-09-08T16:40:03.512588+00:00, map_index=-1, run_start_date=2025-09-08 16:40:13.800284+00:00, run_end_date=2025-09-08 16:40:13.949464+00:00, run_duration=0.14918, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=89, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:40:12.076325+00:00, queued_by_job_id=85, pid=6359
2025-09-08 16:40:16,640 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=determine_branch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:40:16.060600+00:00, run_end_date=2025-09-08 16:40:16.205028+00:00, run_duration=0.144428, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=90, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:40:12.076325+00:00, queued_by_job_id=85, pid=6371
2025-09-08 16:40:17,140 INFO - 2 tasks up for execution:
	<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.groupby_region_smoker scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:40:17,140 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:40:17,141 INFO - DAG branching_pipeline has 1/16 running and queued tasks
2025-09-08 16:40:17,141 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
	<TaskInstance: branching_pipeline.groupby_region_smoker scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:40:17,142 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>, <TaskInstance: branching_pipeline.groupby_region_smoker scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:40:17,143 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 16:40:17,143 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:17,144 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='groupby_region_smoker', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 16:40:17,144 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'groupby_region_smoker', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:17,148 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:19,367 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'groupby_region_smoker', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:21,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1)
2025-09-08 16:40:21,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='groupby_region_smoker', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:40:21,795 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=determine_branch, run_id=manual__2025-09-08T16:40:03.512588+00:00, map_index=-1, run_start_date=2025-09-08 16:40:18.835946+00:00, run_end_date=2025-09-08 16:40:18.966896+00:00, run_duration=0.13095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=91, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:40:17.142156+00:00, queued_by_job_id=85, pid=6399
2025-09-08 16:40:21,795 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=groupby_region_smoker, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:40:21.238482+00:00, run_end_date=2025-09-08 16:40:21.385093+00:00, run_duration=0.146611, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=92, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:40:17.142156+00:00, queued_by_job_id=85, pid=6430
2025-09-08 16:40:21,953 INFO - Marking run <DagRun branching_pipeline @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 16:40:03.785858+00:00. externally triggered: False> successful
2025-09-08 16:40:21,954 INFO - DagRun Finished: dag_id=branching_pipeline, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 16:40:03.811859+00:00, run_end_date=2025-09-08 16:40:21.954306+00:00, run_duration=18.142447, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=017ebd910dbefd69905fbd942c6d293a
2025-09-08 16:40:21,956 INFO - Setting next_dagrun for branching_pipeline to None, run_after=None
2025-09-08 16:40:21,965 INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.groupby_region_smoker manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
2025-09-08 16:40:21,965 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:40:21,966 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.groupby_region_smoker manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>
2025-09-08 16:40:21,967 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.groupby_region_smoker manual__2025-09-08T16:40:03.512588+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:40:21,967 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='groupby_region_smoker', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 16:40:21,968 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'groupby_region_smoker', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:21,972 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'groupby_region_smoker', 'manual__2025-09-08T16:40:03.512588+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:40:24,309 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='groupby_region_smoker', run_id='manual__2025-09-08T16:40:03.512588+00:00', try_number=1, map_index=-1)
2025-09-08 16:40:24,312 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=groupby_region_smoker, run_id=manual__2025-09-08T16:40:03.512588+00:00, map_index=-1, run_start_date=2025-09-08 16:40:23.800257+00:00, run_end_date=2025-09-08 16:40:23.939864+00:00, run_duration=0.139607, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=93, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:40:21.966534+00:00, queued_by_job_id=85, pid=6448
2025-09-08 16:40:24,461 INFO - Marking run <DagRun branching_pipeline @ 2025-09-08 16:40:03.512588+00:00: manual__2025-09-08T16:40:03.512588+00:00, state:running, queued_at: 2025-09-08 16:40:03.526583+00:00. externally triggered: True> successful
2025-09-08 16:40:24,462 INFO - DagRun Finished: dag_id=branching_pipeline, execution_date=2025-09-08 16:40:03.512588+00:00, run_id=manual__2025-09-08T16:40:03.512588+00:00, run_start_date=2025-09-08 16:40:06.435646+00:00, run_end_date=2025-09-08 16:40:24.462004+00:00, run_duration=18.026358, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 16:40:03.512588+00:00, data_interval_end=2025-09-08 16:40:03.512588+00:00, dag_hash=017ebd910dbefd69905fbd942c6d293a
2025-09-08 16:43:06,005 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 16:45:48,492 INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
2025-09-08 16:45:48,492 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:45:48,493 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
2025-09-08 16:45:48,494 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.read_csv_file manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:45:48,494 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 16:45:48,495 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:45:48,499 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'read_csv_file', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:45:50,924 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='read_csv_file', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1)
2025-09-08 16:45:50,928 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=read_csv_file, run_id=manual__2025-09-08T16:45:47.011336+00:00, map_index=-1, run_start_date=2025-09-08 16:45:50.389855+00:00, run_end_date=2025-09-08 16:45:50.527538+00:00, run_duration=0.137683, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=94, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:45:48.493796+00:00, queued_by_job_id=85, pid=8964
2025-09-08 16:45:50,997 INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
2025-09-08 16:45:50,997 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:45:50,997 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
2025-09-08 16:45:50,999 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.remove_null_values manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:45:51,000 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 16:45:51,001 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:45:51,006 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'remove_null_values', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:45:53,267 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='remove_null_values', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1)
2025-09-08 16:45:53,270 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=remove_null_values, run_id=manual__2025-09-08T16:45:47.011336+00:00, map_index=-1, run_start_date=2025-09-08 16:45:52.713208+00:00, run_end_date=2025-09-08 16:45:52.884960+00:00, run_duration=0.171752, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=95, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:45:50.998496+00:00, queued_by_job_id=85, pid=8976
2025-09-08 16:45:53,324 INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
2025-09-08 16:45:53,324 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:45:53,324 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
2025-09-08 16:45:53,326 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.determine_branch manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:45:53,326 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 16:45:53,326 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:45:53,330 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'determine_branch', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:45:55,670 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1)
2025-09-08 16:45:55,675 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=determine_branch, run_id=manual__2025-09-08T16:45:47.011336+00:00, map_index=-1, run_start_date=2025-09-08 16:45:55.028154+00:00, run_end_date=2025-09-08 16:45:55.163651+00:00, run_duration=0.135497, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=96, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:45:53.325326+00:00, queued_by_job_id=85, pid=8989
2025-09-08 16:45:56,230 INFO - 1 tasks up for execution:
	<TaskInstance: branching_pipeline.filter_by_region manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
2025-09-08 16:45:56,230 INFO - DAG branching_pipeline has 0/16 running and queued tasks
2025-09-08 16:45:56,231 INFO - Setting the following tasks to queued state:
	<TaskInstance: branching_pipeline.filter_by_region manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>
2025-09-08 16:45:56,232 INFO - Trying to enqueue tasks: [<TaskInstance: branching_pipeline.filter_by_region manual__2025-09-08T16:45:47.011336+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:45:56,232 INFO - Sending TaskInstanceKey(dag_id='branching_pipeline', task_id='filter_by_region', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 16:45:56,233 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branching_pipeline', 'filter_by_region', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:45:56,237 INFO - Executing command: ['airflow', 'tasks', 'run', 'branching_pipeline', 'filter_by_region', 'manual__2025-09-08T16:45:47.011336+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:45:58,464 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branching_pipeline', task_id='filter_by_region', run_id='manual__2025-09-08T16:45:47.011336+00:00', try_number=1, map_index=-1)
2025-09-08 16:45:58,467 INFO - TaskInstance Finished: dag_id=branching_pipeline, task_id=filter_by_region, run_id=manual__2025-09-08T16:45:47.011336+00:00, map_index=-1, run_start_date=2025-09-08 16:45:57.924482+00:00, run_end_date=2025-09-08 16:45:58.084108+00:00, run_duration=0.159626, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=97, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:45:56.231742+00:00, queued_by_job_id=85, pid=9028
2025-09-08 16:45:58,622 INFO - Marking run <DagRun branching_pipeline @ 2025-09-08 16:45:47.011336+00:00: manual__2025-09-08T16:45:47.011336+00:00, state:running, queued_at: 2025-09-08 16:45:47.017081+00:00. externally triggered: True> successful
2025-09-08 16:45:58,623 INFO - DagRun Finished: dag_id=branching_pipeline, execution_date=2025-09-08 16:45:47.011336+00:00, run_id=manual__2025-09-08T16:45:47.011336+00:00, run_start_date=2025-09-08 16:45:48.473460+00:00, run_end_date=2025-09-08 16:45:58.623218+00:00, run_duration=10.149758, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 16:45:47.011336+00:00, data_interval_end=2025-09-08 16:45:47.011336+00:00, dag_hash=017ebd910dbefd69905fbd942c6d293a
2025-09-08 16:48:06,037 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 16:50:42,088 INFO - Setting next_dagrun for executing_branching to None, run_after=None
2025-09-08 16:50:42,122 INFO - 1 tasks up for execution:
	<TaskInstance: executing_branching.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:50:42,123 INFO - DAG executing_branching has 0/16 running and queued tasks
2025-09-08 16:50:42,124 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_branching.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:50:42,126 INFO - Trying to enqueue tasks: [<TaskInstance: executing_branching.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:50:42,127 INFO - Sending TaskInstanceKey(dag_id='executing_branching', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 8 and queue default
2025-09-08 16:50:42,128 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_branching', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:50:42,132 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_branching', 'read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:50:44,534 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_branching', task_id='read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:50:44,537 INFO - TaskInstance Finished: dag_id=executing_branching, task_id=read_csv_file, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:50:43.917713+00:00, run_end_date=2025-09-08 16:50:44.071093+00:00, run_duration=0.15338, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=98, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2025-09-08 16:50:42.125076+00:00, queued_by_job_id=85, pid=11150
2025-09-08 16:50:45,024 INFO - 1 tasks up for execution:
	<TaskInstance: executing_branching.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:50:45,024 INFO - DAG executing_branching has 0/16 running and queued tasks
2025-09-08 16:50:45,024 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_branching.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:50:45,026 INFO - Trying to enqueue tasks: [<TaskInstance: executing_branching.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:50:45,026 INFO - Sending TaskInstanceKey(dag_id='executing_branching', task_id='remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2025-09-08 16:50:45,026 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_branching', 'remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:50:45,030 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_branching', 'remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:50:47,325 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_branching', task_id='remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:50:47,329 INFO - TaskInstance Finished: dag_id=executing_branching, task_id=remove_null_values, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:50:46.753134+00:00, run_end_date=2025-09-08 16:50:46.901799+00:00, run_duration=0.148665, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=99, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-09-08 16:50:45.025353+00:00, queued_by_job_id=85, pid=11170
2025-09-08 16:50:47,484 INFO - 1 tasks up for execution:
	<TaskInstance: executing_branching.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:50:47,485 INFO - DAG executing_branching has 0/16 running and queued tasks
2025-09-08 16:50:47,485 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_branching.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:50:47,486 INFO - Trying to enqueue tasks: [<TaskInstance: executing_branching.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:50:47,487 INFO - Sending TaskInstanceKey(dag_id='executing_branching', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 16:50:47,487 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_branching', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:50:47,491 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_branching', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:50:49,715 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_branching', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:50:49,718 INFO - TaskInstance Finished: dag_id=executing_branching, task_id=determine_branch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:50:49.196176+00:00, run_end_date=2025-09-08 16:50:49.336110+00:00, run_duration=0.139934, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=100, pool=default_pool, queue=default, priority_weight=6, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:50:47.486213+00:00, queued_by_job_id=85, pid=11189
2025-09-08 16:50:49,775 INFO - 1 tasks up for execution:
	<TaskInstance: executing_branching.filter_by_southeast scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:50:49,776 INFO - DAG executing_branching has 0/16 running and queued tasks
2025-09-08 16:50:49,776 INFO - Setting the following tasks to queued state:
	<TaskInstance: executing_branching.filter_by_southeast scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 16:50:49,777 INFO - Trying to enqueue tasks: [<TaskInstance: executing_branching.filter_by_southeast scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:50:49,778 INFO - Sending TaskInstanceKey(dag_id='executing_branching', task_id='filter_by_southeast', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 16:50:49,778 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'executing_branching', 'filter_by_southeast', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:50:49,782 INFO - Executing command: ['airflow', 'tasks', 'run', 'executing_branching', 'filter_by_southeast', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:50:52,177 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='executing_branching', task_id='filter_by_southeast', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:50:52,182 INFO - TaskInstance Finished: dag_id=executing_branching, task_id=filter_by_southeast, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:50:51.605201+00:00, run_end_date=2025-09-08 16:50:51.746597+00:00, run_duration=0.141396, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=101, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:50:49.776924+00:00, queued_by_job_id=85, pid=11226
2025-09-08 16:50:52,331 INFO - Marking run <DagRun executing_branching @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 16:50:42.078175+00:00. externally triggered: False> successful
2025-09-08 16:50:52,332 INFO - DagRun Finished: dag_id=executing_branching, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 16:50:42.098183+00:00, run_end_date=2025-09-08 16:50:52.331969+00:00, run_duration=10.233786, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=2f2979667b5d51f05c44b06be49754a6
2025-09-08 16:50:52,333 INFO - Setting next_dagrun for executing_branching to None, run_after=None
2025-09-08 16:53:06,064 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 16:56:54,440 INFO - Setting next_dagrun for taskgroup_and_labels_pipeline to None, run_after=None
2025-09-08 16:56:54,477 INFO - 2 tasks up for execution:
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
2025-09-08 16:56:54,478 INFO - DAG taskgroup_and_labels_pipeline has 0/16 running and queued tasks
2025-09-08 16:56:54,478 INFO - DAG taskgroup_and_labels_pipeline has 1/16 running and queued tasks
2025-09-08 16:56:54,479 INFO - Setting the following tasks to queued state:
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
2025-09-08 16:56:54,481 INFO - Trying to enqueue tasks: [<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.read_csv_file manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:56:54,481 INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 16:56:54,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:56:54,482 INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.read_csv_file', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 16:56:54,482 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.read_csv_file', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:56:54,487 INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.read_csv_file', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:56:57,033 INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.read_csv_file', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:56:59,374 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.read_csv_file', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:56:59,374 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.read_csv_file', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1)
2025-09-08 16:56:59,380 INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Reading_and_Preprocessing.read_csv_file, run_id=manual__2025-09-08T16:56:53.736348+00:00, map_index=-1, run_start_date=2025-09-08 16:56:58.807067+00:00, run_end_date=2025-09-08 16:56:58.946975+00:00, run_duration=0.139908, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=103, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:56:54.479841+00:00, queued_by_job_id=85, pid=14075
2025-09-08 16:56:59,380 INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Reading_and_Preprocessing.read_csv_file, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:56:56.339013+00:00, run_end_date=2025-09-08 16:56:56.493270+00:00, run_duration=0.154257, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=102, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-09-08 16:56:54.479841+00:00, queued_by_job_id=85, pid=14039
2025-09-08 16:56:59,558 INFO - 2 tasks up for execution:
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
2025-09-08 16:56:59,558 INFO - DAG taskgroup_and_labels_pipeline has 0/16 running and queued tasks
2025-09-08 16:56:59,559 INFO - DAG taskgroup_and_labels_pipeline has 1/16 running and queued tasks
2025-09-08 16:56:59,559 INFO - Setting the following tasks to queued state:
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
2025-09-08 16:56:59,560 INFO - Trying to enqueue tasks: [<TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: taskgroup_and_labels_pipeline.Reading_and_Preprocessing.remove_null_values manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:56:59,561 INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 16:56:59,561 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:56:59,561 INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.remove_null_values', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 16:56:59,562 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.remove_null_values', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:56:59,566 INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.remove_null_values', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:01,823 INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Reading_and_Preprocessing.remove_null_values', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:04,131 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.remove_null_values', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:57:04,131 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Reading_and_Preprocessing.remove_null_values', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1)
2025-09-08 16:57:04,135 INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Reading_and_Preprocessing.remove_null_values, run_id=manual__2025-09-08T16:56:53.736348+00:00, map_index=-1, run_start_date=2025-09-08 16:57:03.535570+00:00, run_end_date=2025-09-08 16:57:03.702562+00:00, run_duration=0.166992, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=105, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:56:59.559848+00:00, queued_by_job_id=85, pid=14107
2025-09-08 16:57:04,135 INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Reading_and_Preprocessing.remove_null_values, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:57:01.255183+00:00, run_end_date=2025-09-08 16:57:01.418308+00:00, run_duration=0.163125, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=104, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 16:56:59.559848+00:00, queued_by_job_id=85, pid=14089
2025-09-08 16:57:04,295 INFO - 2 tasks up for execution:
	<TaskInstance: taskgroup_and_labels_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.determine_branch manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
2025-09-08 16:57:04,295 INFO - DAG taskgroup_and_labels_pipeline has 0/16 running and queued tasks
2025-09-08 16:57:04,295 INFO - DAG taskgroup_and_labels_pipeline has 1/16 running and queued tasks
2025-09-08 16:57:04,296 INFO - Setting the following tasks to queued state:
	<TaskInstance: taskgroup_and_labels_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.determine_branch manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
2025-09-08 16:57:04,297 INFO - Trying to enqueue tasks: [<TaskInstance: taskgroup_and_labels_pipeline.determine_branch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: taskgroup_and_labels_pipeline.determine_branch manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:57:04,297 INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 16:57:04,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:04,298 INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 16:57:04,298 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'determine_branch', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:04,303 INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'determine_branch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:06,488 INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'determine_branch', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:08,929 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='determine_branch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:57:08,930 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='determine_branch', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1)
2025-09-08 16:57:08,933 INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=determine_branch, run_id=manual__2025-09-08T16:56:53.736348+00:00, map_index=-1, run_start_date=2025-09-08 16:57:08.353054+00:00, run_end_date=2025-09-08 16:57:08.517736+00:00, run_duration=0.164682, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=107, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:57:04.296526+00:00, queued_by_job_id=85, pid=14162
2025-09-08 16:57:08,934 INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=determine_branch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:57:05.942739+00:00, run_end_date=2025-09-08 16:57:06.103068+00:00, run_duration=0.160329, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=106, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 16:57:04.296526+00:00, queued_by_job_id=85, pid=14120
2025-09-08 16:57:09,504 INFO - 2 tasks up for execution:
	<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
2025-09-08 16:57:09,504 INFO - DAG taskgroup_and_labels_pipeline has 0/16 running and queued tasks
2025-09-08 16:57:09,504 INFO - DAG taskgroup_and_labels_pipeline has 1/16 running and queued tasks
2025-09-08 16:57:09,505 INFO - Setting the following tasks to queued state:
	<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>
2025-09-08 16:57:09,506 INFO - Trying to enqueue tasks: [<TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: taskgroup_and_labels_pipeline.Filtering.filter_by_region manual__2025-09-08T16:56:53.736348+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 16:57:09,507 INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Filtering.filter_by_region', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 16:57:09,507 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Filtering.filter_by_region', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:09,507 INFO - Sending TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Filtering.filter_by_region', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 16:57:09,508 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Filtering.filter_by_region', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:09,512 INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Filtering.filter_by_region', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:11,711 INFO - Executing command: ['airflow', 'tasks', 'run', 'taskgroup_and_labels_pipeline', 'Filtering.filter_by_region', 'manual__2025-09-08T16:56:53.736348+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_branching_pipeline.py']
2025-09-08 16:57:14,004 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Filtering.filter_by_region', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 16:57:14,004 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='taskgroup_and_labels_pipeline', task_id='Filtering.filter_by_region', run_id='manual__2025-09-08T16:56:53.736348+00:00', try_number=1, map_index=-1)
2025-09-08 16:57:14,009 INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Filtering.filter_by_region, run_id=manual__2025-09-08T16:56:53.736348+00:00, map_index=-1, run_start_date=2025-09-08 16:57:13.424892+00:00, run_end_date=2025-09-08 16:57:13.583399+00:00, run_duration=0.158507, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=109, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:57:09.505792+00:00, queued_by_job_id=85, pid=14189
2025-09-08 16:57:14,010 INFO - TaskInstance Finished: dag_id=taskgroup_and_labels_pipeline, task_id=Filtering.filter_by_region, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 16:57:11.202210+00:00, run_end_date=2025-09-08 16:57:11.340103+00:00, run_duration=0.137893, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=108, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-09-08 16:57:09.505792+00:00, queued_by_job_id=85, pid=14177
2025-09-08 16:57:14,568 INFO - Marking run <DagRun taskgroup_and_labels_pipeline @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 16:56:54.437018+00:00. externally triggered: False> successful
2025-09-08 16:57:14,568 INFO - DagRun Finished: dag_id=taskgroup_and_labels_pipeline, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 16:56:54.450135+00:00, run_end_date=2025-09-08 16:57:14.568504+00:00, run_duration=20.118369, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=a2f56e96da3fac730cdc84e09782986d
2025-09-08 16:57:14,570 INFO - Setting next_dagrun for taskgroup_and_labels_pipeline to None, run_after=None
2025-09-08 16:57:14,572 INFO - Marking run <DagRun taskgroup_and_labels_pipeline @ 2025-09-08 16:56:53.736348+00:00: manual__2025-09-08T16:56:53.736348+00:00, state:running, queued_at: 2025-09-08 16:56:53.748070+00:00. externally triggered: True> successful
2025-09-08 16:57:14,572 INFO - DagRun Finished: dag_id=taskgroup_and_labels_pipeline, execution_date=2025-09-08 16:56:53.736348+00:00, run_id=manual__2025-09-08T16:56:53.736348+00:00, run_start_date=2025-09-08 16:56:54.450184+00:00, run_end_date=2025-09-08 16:57:14.572665+00:00, run_duration=20.122481, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-09-08 16:56:53.736348+00:00, data_interval_end=2025-09-08 16:56:53.736348+00:00, dag_hash=a2f56e96da3fac730cdc84e09782986d
2025-09-08 16:58:06,108 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 17:01:34,182 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-04 00:00:00+00:00, run_after=2025-09-05 00:00:00+00:00
2025-09-08 17:01:34,212 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:34,212 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:01:34,213 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:34,214 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:01:34,214 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:01:34,214 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:34,219 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:36,066 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:36,071 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:35.610987+00:00, run_end_date=2025-09-08 17:01:35.743979+00:00, run_duration=0.132992, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:34.213513+00:00, queued_by_job_id=85, pid=16221
2025-09-08 17:01:36,126 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-05 00:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
2025-09-08 17:01:36,158 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:36,158 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:01:36,158 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:01:36,159 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:36,160 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-04T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:01:36,161 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:01:36,161 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:36,161 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:01:36,162 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:36,166 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:38,133 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:40,043 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:40,043 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:40,047 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:39.568725+00:00, run_end_date=2025-09-08 17:01:39.684018+00:00, run_duration=0.115293, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:01:36.159837+00:00, queued_by_job_id=85, pid=16250
2025-09-08 17:01:40,047 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:37.695163+00:00, run_end_date=2025-09-08 17:01:37.821796+00:00, run_duration=0.126633, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:36.159837+00:00, queued_by_job_id=85, pid=16239
2025-09-08 17:01:40,211 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-07 00:00:00+00:00
2025-09-08 17:01:40,248 INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:40,248 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:01:40,248 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:01:40,249 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:01:40,249 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-03T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:40,251 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-05T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-04T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-03T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:01:40,252 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:01:40,252 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:40,252 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:01:40,253 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:40,253 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:01:40,253 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:40,259 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:42,262 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:44,148 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:46,072 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:46,072 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:46,073 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-03T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:46,079 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-03T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:45.583924+00:00, run_end_date=2025-09-08 17:01:45.717279+00:00, run_duration=0.133355, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=115, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:01:40.250227+00:00, queued_by_job_id=85, pid=16307
2025-09-08 17:01:46,079 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:41.692953+00:00, run_end_date=2025-09-08 17:01:41.833832+00:00, run_duration=0.140879, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:40.250227+00:00, queued_by_job_id=85, pid=16269
2025-09-08 17:01:46,080 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:43.701970+00:00, run_end_date=2025-09-08 17:01:43.822114+00:00, run_duration=0.120144, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:01:40.250227+00:00, queued_by_job_id=85, pid=16297
2025-09-08 17:01:46,127 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-08 17:01:46,162 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-03 00:00:00+00:00: scheduled__2025-09-03T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:34.178510+00:00. externally triggered: False> successful
2025-09-08 17:01:46,162 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-03 00:00:00+00:00, run_id=scheduled__2025-09-03T00:00:00+00:00, run_start_date=2025-09-08 17:01:34.192959+00:00, run_end_date=2025-09-08 17:01:46.162836+00:00, run_duration=11.969877, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-03 00:00:00+00:00, data_interval_end=2025-09-04 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
2025-09-08 17:01:46,165 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-04 00:00:00+00:00, run_after=2025-09-05 00:00:00+00:00
2025-09-08 17:01:46,176 INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:46,176 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:01:46,177 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:01:46,177 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:01:46,177 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:46,179 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-05T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:01:46,179 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:01:46,180 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:46,180 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:01:46,180 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:46,181 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:01:46,181 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:46,186 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:48,563 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:50,546 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:52,623 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:52,623 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:52,624 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:01:52,627 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:50.087933+00:00, run_end_date=2025-09-08 17:01:50.211184+00:00, run_duration=0.123251, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=117, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:01:46.178422+00:00, queued_by_job_id=85, pid=16337
2025-09-08 17:01:52,628 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:51.980027+00:00, run_end_date=2025-09-08 17:01:52.176816+00:00, run_duration=0.196789, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=118, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:01:46.178422+00:00, queued_by_job_id=85, pid=16348
2025-09-08 17:01:52,628 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:47.945394+00:00, run_end_date=2025-09-08 17:01:48.081145+00:00, run_duration=0.135751, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=116, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:46.178422+00:00, queued_by_job_id=85, pid=16325
2025-09-08 17:01:52,785 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
2025-09-08 17:01:52,851 INFO - 4 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:52,851 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:01:52,852 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:01:52,852 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:01:52,853 INFO - DAG cron_catchup_backfill has 3/16 running and queued tasks
2025-09-08 17:01:52,853 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
2025-09-08 17:01:52,858 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-05T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:01:52,858 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:01:52,859 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:52,860 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:01:52,860 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:52,861 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:01:52,861 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:52,862 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:01:52,863 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:52,868 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:54,799 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:56,987 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:01:59,067 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:00,997 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:00,997 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:00,997 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:00,998 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:01,004 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:56.371427+00:00, run_end_date=2025-09-08 17:01:56.491630+00:00, run_duration=0.120203, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=120, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:01:52.855076+00:00, queued_by_job_id=85, pid=16395
2025-09-08 17:02:01,004 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:00.525492+00:00, run_end_date=2025-09-08 17:02:00.639581+00:00, run_duration=0.114089, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=122, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:01:52.855076+00:00, queued_by_job_id=85, pid=16423
2025-09-08 17:02:01,005 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:58.537791+00:00, run_end_date=2025-09-08 17:01:58.695781+00:00, run_duration=0.15799, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=121, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:01:52.855076+00:00, queued_by_job_id=85, pid=16412
2025-09-08 17:02:01,005 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:01:54.343282+00:00, run_end_date=2025-09-08 17:01:54.475309+00:00, run_duration=0.132027, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=119, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:01:52.855076+00:00, queued_by_job_id=85, pid=16383
2025-09-08 17:02:01,583 INFO - 4 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
2025-09-08 17:02:01,584 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:02:01,584 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:02:01,584 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:02:01,585 INFO - DAG cron_catchup_backfill has 3/16 running and queued tasks
2025-09-08 17:02:01,585 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-04T00:00:00+00:00 [scheduled]>
2025-09-08 17:02:01,587 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-05T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-04T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:02:01,587 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:02:01,587 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:01,588 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:02:01,588 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:01,588 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:02:01,589 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:01,589 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:02:01,589 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:01,594 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:03,732 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:05,752 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:07,685 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:09,722 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:09,723 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:09,723 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:09,723 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-04T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:09,727 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:05.235088+00:00, run_end_date=2025-09-08 17:02:05.399226+00:00, run_duration=0.164138, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=124, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:02:01.586088+00:00, queued_by_job_id=85, pid=16472
2025-09-08 17:02:09,728 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-04T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:09.166810+00:00, run_end_date=2025-09-08 17:02:09.305741+00:00, run_duration=0.138931, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:02:01.586088+00:00, queued_by_job_id=85, pid=16494
2025-09-08 17:02:09,728 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:07.182417+00:00, run_end_date=2025-09-08 17:02:07.296810+00:00, run_duration=0.114393, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=125, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:02:01.586088+00:00, queued_by_job_id=85, pid=16483
2025-09-08 17:02:09,729 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:03.192337+00:00, run_end_date=2025-09-08 17:02:03.334761+00:00, run_duration=0.142424, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=123, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:02:01.586088+00:00, queued_by_job_id=85, pid=16455
2025-09-08 17:02:10,331 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-04 00:00:00+00:00: scheduled__2025-09-04T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:36.122509+00:00. externally triggered: False> successful
2025-09-08 17:02:10,332 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-04 00:00:00+00:00, run_id=scheduled__2025-09-04T00:00:00+00:00, run_start_date=2025-09-08 17:01:36.135943+00:00, run_end_date=2025-09-08 17:02:10.332352+00:00, run_duration=34.196409, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-04 00:00:00+00:00, data_interval_end=2025-09-05 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
2025-09-08 17:02:10,335 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-05 00:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
2025-09-08 17:02:10,344 INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
2025-09-08 17:02:10,345 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:02:10,345 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:02:10,345 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:02:10,346 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-05T00:00:00+00:00 [scheduled]>
2025-09-08 17:02:10,347 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-05T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:02:10,348 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:02:10,348 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:10,348 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:02:10,349 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:10,349 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:02:10,349 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:10,354 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:12,302 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:14,369 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:16,406 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:16,406 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:16,407 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-05T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:16,410 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:13.905124+00:00, run_end_date=2025-09-08 17:02:14.020026+00:00, run_duration=0.114902, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:02:10.346939+00:00, queued_by_job_id=85, pid=16550
2025-09-08 17:02:16,411 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-05T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:15.917917+00:00, run_end_date=2025-09-08 17:02:16.059660+00:00, run_duration=0.141743, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:02:10.346939+00:00, queued_by_job_id=85, pid=16567
2025-09-08 17:02:16,411 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:11.836223+00:00, run_end_date=2025-09-08 17:02:11.972607+00:00, run_duration=0.136384, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:02:10.346939+00:00, queued_by_job_id=85, pid=16521
2025-09-08 17:02:16,561 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-07 00:00:00+00:00
2025-09-08 17:02:16,578 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-05 00:00:00+00:00: scheduled__2025-09-05T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:40.201500+00:00. externally triggered: False> successful
2025-09-08 17:02:16,579 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-05 00:00:00+00:00, run_id=scheduled__2025-09-05T00:00:00+00:00, run_start_date=2025-09-08 17:01:40.221338+00:00, run_end_date=2025-09-08 17:02:16.579242+00:00, run_duration=36.357904, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-05 00:00:00+00:00, data_interval_end=2025-09-06 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
2025-09-08 17:02:16,582 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-07 00:00:00+00:00
2025-09-08 17:02:16,590 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-08 17:02:16,591 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:02:16,591 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:02:16,591 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
2025-09-08 17:02:16,593 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-06T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:02:16,593 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:02:16,594 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:16,594 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:02:16,594 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:16,598 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:18,682 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:20,733 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:20,734 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:20,737 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:20.223833+00:00, run_end_date=2025-09-08 17:02:20.386408+00:00, run_duration=0.162575, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:02:16.592388+00:00, queued_by_job_id=85, pid=16591
2025-09-08 17:02:20,738 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:18.168061+00:00, run_end_date=2025-09-08 17:02:18.286704+00:00, run_duration=0.118643, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:02:16.592388+00:00, queued_by_job_id=85, pid=16580
2025-09-08 17:02:20,892 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-08 17:02:20,907 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-06 00:00:00+00:00: scheduled__2025-09-06T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:46.123409+00:00. externally triggered: False> successful
2025-09-08 17:02:20,908 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-06 00:00:00+00:00, run_id=scheduled__2025-09-06T00:00:00+00:00, run_start_date=2025-09-08 17:01:46.138584+00:00, run_end_date=2025-09-08 17:02:20.908004+00:00, run_duration=34.76942, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-07 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
2025-09-08 17:02:20,910 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-07 00:00:00+00:00, run_after=2025-09-08 00:00:00+00:00
2025-09-08 17:02:20,919 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:02:20,920 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:02:20,920 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:02:20,921 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:02:20,922 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:02:20,922 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:20,926 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:02:22,890 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:02:22,893 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:02:22.407195+00:00, run_end_date=2025-09-08 17:02:22.544644+00:00, run_duration=0.137449, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=132, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:02:20.920961+00:00, queued_by_job_id=85, pid=16610
2025-09-08 17:02:23,181 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
2025-09-08 17:02:23,192 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:01:52.780375+00:00. externally triggered: False> successful
2025-09-08 17:02:23,192 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 17:01:52.800996+00:00, run_end_date=2025-09-08 17:02:23.192863+00:00, run_duration=30.391867, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-08 00:00:00+00:00, dag_hash=dda6d94958868d4787d188406d9c8c34
2025-09-08 17:02:23,195 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-08 00:00:00+00:00, run_after=2025-09-09 00:00:00+00:00
2025-09-08 17:03:06,136 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 17:03:43,537 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-09 12:00:00+00:00, run_after=2025-08-16 00:00:00+00:00
2025-09-08 17:03:43,566 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:03:43,567 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:03:43,567 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:03:43,568 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:03:43,569 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:03:43,569 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:43,574 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:45,620 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:03:45,623 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:45.156129+00:00, run_end_date=2025-09-08 17:03:45.284506+00:00, run_duration=0.128377, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:03:43.568067+00:00, queued_by_job_id=85, pid=17253
2025-09-08 17:03:45,667 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 00:00:00+00:00, run_after=2025-08-16 12:00:00+00:00
2025-09-08 17:03:45,699 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:03:45,699 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:03:45,700 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:03:45,700 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:03:45,701 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-09T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:03:45,702 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:03:45,702 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:45,703 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:03:45,703 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:45,707 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:47,629 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:49,638 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:03:49,638 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:03:49,642 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:49.181621+00:00, run_end_date=2025-09-08 17:03:49.305457+00:00, run_duration=0.123836, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:03:45.701185+00:00, queued_by_job_id=85, pid=17282
2025-09-08 17:03:49,642 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-09T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:47.149834+00:00, run_end_date=2025-09-08 17:03:47.278793+00:00, run_duration=0.128959, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:03:45.701185+00:00, queued_by_job_id=85, pid=17265
2025-09-08 17:03:49,783 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 12:00:00+00:00, run_after=2025-08-23 00:00:00+00:00
2025-09-08 17:03:49,818 INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:03:49,818 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:03:49,818 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:03:49,819 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:03:49,819 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:03:49,821 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-09T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:03:49,821 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:03:49,821 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:49,822 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:03:49,822 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:49,822 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:03:49,823 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:49,827 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:51,748 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:53,771 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:55,897 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:03:55,897 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:03:55,897 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:03:55,901 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:55.391312+00:00, run_end_date=2025-09-08 17:03:55.528495+00:00, run_duration=0.137183, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=115, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:03:49.820059+00:00, queued_by_job_id=85, pid=17340
2025-09-08 17:03:55,902 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:51.287717+00:00, run_end_date=2025-09-08 17:03:51.414413+00:00, run_duration=0.126696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:03:49.820059+00:00, queued_by_job_id=85, pid=17294
2025-09-08 17:03:55,902 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-09T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:53.200005+00:00, run_end_date=2025-09-08 17:03:53.321442+00:00, run_duration=0.121437, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:03:49.820059+00:00, queued_by_job_id=85, pid=17306
2025-09-08 17:03:56,059 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 00:00:00+00:00, run_after=2025-08-23 12:00:00+00:00
2025-09-08 17:03:56,100 INFO - 4 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:03:56,100 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:03:56,100 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:03:56,101 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:03:56,101 INFO - DAG cron_catchup_backfill has 3/16 running and queued tasks
2025-09-08 17:03:56,101 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:03:56,103 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-16T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-09T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:03:56,103 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:03:56,104 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:56,104 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:03:56,104 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:56,105 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:03:56,105 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:56,105 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:03:56,106 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:56,110 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:03:58,031 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:00,088 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-09T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:02,002 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:03,925 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:03,925 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:03,926 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-09T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:03,926 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:03,930 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-16T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:57.580384+00:00, run_end_date=2025-09-08 17:03:57.713366+00:00, run_duration=0.132982, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=116, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:03:56.102559+00:00, queued_by_job_id=85, pid=17352
2025-09-08 17:04:03,930 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:03.441979+00:00, run_end_date=2025-09-08 17:04:03.551263+00:00, run_duration=0.109284, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=119, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:03:56.102559+00:00, queued_by_job_id=85, pid=17392
2025-09-08 17:04:03,931 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:03:59.613203+00:00, run_end_date=2025-09-08 17:03:59.745651+00:00, run_duration=0.132448, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=117, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:03:56.102559+00:00, queued_by_job_id=85, pid=17370
2025-09-08 17:04:03,931 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-09T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:01.524716+00:00, run_end_date=2025-09-08 17:04:01.664139+00:00, run_duration=0.139423, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=118, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:03:56.102559+00:00, queued_by_job_id=85, pid=17381
2025-09-08 17:04:04,083 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 12:00:00+00:00, run_after=2025-08-30 00:00:00+00:00
2025-09-08 17:04:04,113 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-09 12:00:00+00:00: scheduled__2025-08-09T12:00:00+00:00, state:running, queued_at: 2025-09-08 17:03:45.663853+00:00. externally triggered: False> successful
2025-09-08 17:04:04,114 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-09 12:00:00+00:00, run_id=scheduled__2025-08-09T12:00:00+00:00, run_start_date=2025-09-08 17:03:45.676899+00:00, run_end_date=2025-09-08 17:04:04.114070+00:00, run_duration=18.437171, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-09 12:00:00+00:00, data_interval_end=2025-08-16 00:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:04,116 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 00:00:00+00:00, run_after=2025-08-16 12:00:00+00:00
2025-09-08 17:04:04,128 INFO - 4 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:04,128 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:04,129 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:04,129 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:04:04,129 INFO - DAG cron_catchup_backfill has 3/16 running and queued tasks
2025-09-08 17:04:04,130 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-09T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:04,131 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-16T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-09T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:04,132 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:04:04,132 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:04,132 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:04:04,133 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:04,133 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:04:04,133 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:04,134 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:04:04,134 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:04,139 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:06,285 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:08,172 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:10,144 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:12,122 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:12,122 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:12,122 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-16T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:12,123 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-09T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:12,127 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-16T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:07.724293+00:00, run_end_date=2025-09-08 17:04:07.851092+00:00, run_duration=0.126799, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=121, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:04.130871+00:00, queued_by_job_id=85, pid=17438
2025-09-08 17:04:12,127 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-08-09T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:11.649566+00:00, run_end_date=2025-09-08 17:04:11.780565+00:00, run_duration=0.130999, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=123, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:04:04.130871+00:00, queued_by_job_id=85, pid=17466
2025-09-08 17:04:12,128 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:05.793486+00:00, run_end_date=2025-09-08 17:04:05.948979+00:00, run_duration=0.155493, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=120, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:04.130871+00:00, queued_by_job_id=85, pid=17426
2025-09-08 17:04:12,128 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-16T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:09.647447+00:00, run_end_date=2025-09-08 17:04:09.782820+00:00, run_duration=0.135373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=122, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:04.130871+00:00, queued_by_job_id=85, pid=17449
2025-09-08 17:04:12,294 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 00:00:00+00:00, run_after=2025-08-30 12:00:00+00:00
2025-09-08 17:04:12,325 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-16 00:00:00+00:00: scheduled__2025-08-16T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:03:49.779832+00:00. externally triggered: False> successful
2025-09-08 17:04:12,325 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-16 00:00:00+00:00, run_id=scheduled__2025-08-16T00:00:00+00:00, run_start_date=2025-09-08 17:03:49.792629+00:00, run_end_date=2025-09-08 17:04:12.325943+00:00, run_duration=22.533314, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-16 00:00:00+00:00, data_interval_end=2025-08-16 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:12,328 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 12:00:00+00:00, run_after=2025-08-23 00:00:00+00:00
2025-09-08 17:04:12,330 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-09 00:00:00+00:00: scheduled__2025-08-09T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:03:43.533483+00:00. externally triggered: False> successful
2025-09-08 17:04:12,331 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-09 00:00:00+00:00, run_id=scheduled__2025-08-09T00:00:00+00:00, run_start_date=2025-09-08 17:03:43.546655+00:00, run_end_date=2025-09-08 17:04:12.331177+00:00, run_duration=28.784522, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-09 00:00:00+00:00, data_interval_end=2025-08-09 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:12,335 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-09 12:00:00+00:00, run_after=2025-08-16 00:00:00+00:00
2025-09-08 17:04:12,347 INFO - 3 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:12,348 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:12,348 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:12,348 INFO - DAG cron_catchup_backfill has 2/16 running and queued tasks
2025-09-08 17:04:12,349 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:12,351 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-23T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-16T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:12,352 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:04:12,352 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:12,352 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:04:12,353 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:12,353 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:04:12,354 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:12,358 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:14,270 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:16,416 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-16T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:18,309 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:18,310 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:18,310 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-16T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:18,314 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-16T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:17.856549+00:00, run_end_date=2025-09-08 17:04:17.993423+00:00, run_duration=0.136874, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:12.350158+00:00, queued_by_job_id=85, pid=17524
2025-09-08 17:04:18,314 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:15.954140+00:00, run_end_date=2025-09-08 17:04:16.083263+00:00, run_duration=0.129123, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=125, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:12.350158+00:00, queued_by_job_id=85, pid=17514
2025-09-08 17:04:18,315 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:13.816434+00:00, run_end_date=2025-09-08 17:04:13.952053+00:00, run_duration=0.135619, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=124, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:12.350158+00:00, queued_by_job_id=85, pid=17479
2025-09-08 17:04:18,874 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-16 00:00:00+00:00, run_after=2025-08-16 12:00:00+00:00
2025-09-08 17:04:18,901 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-16 12:00:00+00:00: scheduled__2025-08-16T12:00:00+00:00, state:running, queued_at: 2025-09-08 17:03:56.055671+00:00. externally triggered: False> successful
2025-09-08 17:04:18,901 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-16 12:00:00+00:00, run_id=scheduled__2025-08-16T12:00:00+00:00, run_start_date=2025-09-08 17:03:56.069197+00:00, run_end_date=2025-09-08 17:04:18.901674+00:00, run_duration=22.832477, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-16 12:00:00+00:00, data_interval_end=2025-08-23 00:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:18,904 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 00:00:00+00:00, run_after=2025-08-23 12:00:00+00:00
2025-09-08 17:04:18,913 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:18,913 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:18,914 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:18,914 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:18,916 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-23T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:18,917 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:04:18,917 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:18,918 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:04:18,918 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:18,922 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:20,887 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:22,891 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:22,891 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:22,895 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:22.413867+00:00, run_end_date=2025-09-08 17:04:22.547866+00:00, run_duration=0.133999, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:18.915561+00:00, queued_by_job_id=85, pid=17555
2025-09-08 17:04:22,895 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:20.444828+00:00, run_end_date=2025-09-08 17:04:20.563447+00:00, run_duration=0.118619, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:18.915561+00:00, queued_by_job_id=85, pid=17538
2025-09-08 17:04:23,038 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 12:00:00+00:00, run_after=2025-08-30 00:00:00+00:00
2025-09-08 17:04:23,063 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:23,063 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:23,064 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:23,064 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:23,065 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-23T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:23,066 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:04:23,066 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:23,067 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:04:23,067 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:23,071 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:24,999 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:27,060 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:27,061 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:27,064 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:26.579369+00:00, run_end_date=2025-09-08 17:04:26.692299+00:00, run_duration=0.11293, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:04:23.065162+00:00, queued_by_job_id=85, pid=17602
2025-09-08 17:04:27,065 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:24.461605+00:00, run_end_date=2025-09-08 17:04:24.606499+00:00, run_duration=0.144894, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:23.065162+00:00, queued_by_job_id=85, pid=17567
2025-09-08 17:04:27,214 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 00:00:00+00:00, run_after=2025-08-30 12:00:00+00:00
2025-09-08 17:04:27,238 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:27,239 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:27,239 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:27,239 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:27,241 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-23T12:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:27,241 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:04:27,241 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:27,242 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:04:27,242 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:27,246 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:29,261 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:31,196 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:31,196 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-23T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:31,200 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-08-23T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:30.749920+00:00, run_end_date=2025-09-08 17:04:30.884797+00:00, run_duration=0.134877, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=132, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:04:27.240377+00:00, queued_by_job_id=85, pid=17629
2025-09-08 17:04:31,200 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:28.786698+00:00, run_end_date=2025-09-08 17:04:28.900140+00:00, run_duration=0.113442, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:04:27.240377+00:00, queued_by_job_id=85, pid=17618
2025-09-08 17:04:31,447 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 12:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
2025-09-08 17:04:31,475 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-23 00:00:00+00:00: scheduled__2025-08-23T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:04.079636+00:00. externally triggered: False> successful
2025-09-08 17:04:31,476 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-23 00:00:00+00:00, run_id=scheduled__2025-08-23T00:00:00+00:00, run_start_date=2025-09-08 17:04:04.093209+00:00, run_end_date=2025-09-08 17:04:31.476148+00:00, run_duration=27.382939, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-23 00:00:00+00:00, data_interval_end=2025-08-23 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:31,478 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-23 12:00:00+00:00, run_after=2025-08-30 00:00:00+00:00
2025-09-08 17:04:31,488 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:31,488 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:31,489 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:31,489 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:31,490 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-23T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:31,491 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:04:31,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:31,492 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:04:31,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:31,496 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:33,497 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-23T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:35,420 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:35,420 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-23T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:35,424 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:32.974095+00:00, run_end_date=2025-09-08 17:04:33.127018+00:00, run_duration=0.152923, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=133, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:31.490086+00:00, queued_by_job_id=85, pid=17648
2025-09-08 17:04:35,425 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-08-23T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:34.960377+00:00, run_end_date=2025-09-08 17:04:35.092193+00:00, run_duration=0.131816, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=134, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:04:31.490086+00:00, queued_by_job_id=85, pid=17660
2025-09-08 17:04:36,079 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 00:00:00+00:00, run_after=2025-08-30 12:00:00+00:00
2025-09-08 17:04:36,094 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-23 12:00:00+00:00: scheduled__2025-08-23T12:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:12.289239+00:00. externally triggered: False> successful
2025-09-08 17:04:36,095 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-23 12:00:00+00:00, run_id=scheduled__2025-08-23T12:00:00+00:00, run_start_date=2025-09-08 17:04:12.305334+00:00, run_end_date=2025-09-08 17:04:36.095342+00:00, run_duration=23.790008, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-23 12:00:00+00:00, data_interval_end=2025-08-30 00:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:36,098 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 00:00:00+00:00, run_after=2025-08-30 12:00:00+00:00
2025-09-08 17:04:36,107 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:36,107 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:36,108 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:36,109 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:36,109 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:04:36,110 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:36,114 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:38,082 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:38,085 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:37.608323+00:00, run_end_date=2025-09-08 17:04:37.730998+00:00, run_duration=0.122675, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=135, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:36.108557+00:00, queued_by_job_id=85, pid=17703
2025-09-08 17:04:38,226 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 12:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
2025-09-08 17:04:38,248 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:38,249 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:38,249 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T00:00:00+00:00 [scheduled]>
2025-09-08 17:04:38,250 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:38,251 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:04:38,251 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:38,255 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:40,191 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-30T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:40,195 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-30T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:39.665026+00:00, run_end_date=2025-09-08 17:04:39.822956+00:00, run_duration=0.15793, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=136, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:38.249993+00:00, queued_by_job_id=85, pid=17715
2025-09-08 17:04:40,340 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-06 12:00:00+00:00
2025-09-08 17:04:40,363 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-30 00:00:00+00:00: scheduled__2025-08-30T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:31.443393+00:00. externally triggered: False> successful
2025-09-08 17:04:40,363 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-30 00:00:00+00:00, run_id=scheduled__2025-08-30T00:00:00+00:00, run_start_date=2025-09-08 17:04:31.459322+00:00, run_end_date=2025-09-08 17:04:40.363932+00:00, run_duration=8.90461, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-30 00:00:00+00:00, data_interval_end=2025-08-30 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:40,366 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-08-30 12:00:00+00:00, run_after=2025-09-06 00:00:00+00:00
2025-09-08 17:04:40,375 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:40,376 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:40,376 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:40,377 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:40,378 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:04:40,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:40,382 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:42,265 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:42,268 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:41.821881+00:00, run_end_date=2025-09-08 17:04:41.954799+00:00, run_duration=0.132918, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=137, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:40.377105+00:00, queued_by_job_id=85, pid=17727
2025-09-08 17:04:42,422 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
2025-09-08 17:04:42,456 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:42,456 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:42,457 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:42,457 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:42,458 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:42,459 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:04:42,459 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:42,460 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:04:42,460 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:42,464 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:44,412 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:46,448 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:46,448 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:46,452 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:45.935059+00:00, run_end_date=2025-09-08 17:04:46.108298+00:00, run_duration=0.173239, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=139, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:42.458056+00:00, queued_by_job_id=85, pid=17765
2025-09-08 17:04:46,452 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:43.966715+00:00, run_end_date=2025-09-08 17:04:44.099927+00:00, run_duration=0.133212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=138, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:04:42.458056+00:00, queued_by_job_id=85, pid=17746
2025-09-08 17:04:46,511 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:46,511 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:46,511 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:46,512 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:46,513 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:46,513 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:04:46,514 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:46,514 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:04:46,514 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:46,519 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:48,444 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:50,452 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:50,452 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:50,456 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:49.952822+00:00, run_end_date=2025-09-08 17:04:50.088153+00:00, run_duration=0.135331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=141, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:46.512648+00:00, queued_by_job_id=85, pid=17804
2025-09-08 17:04:50,456 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:48.007204+00:00, run_end_date=2025-09-08 17:04:48.126992+00:00, run_duration=0.119788, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=140, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:04:46.512648+00:00, queued_by_job_id=85, pid=17787
2025-09-08 17:04:51,029 INFO - 2 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:51,029 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:51,030 INFO - DAG cron_catchup_backfill has 1/16 running and queued tasks
2025-09-08 17:04:51,030 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:51,031 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-06T00:00:00+00:00 [scheduled]>, <TaskInstance: cron_catchup_backfill.taskC scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:51,032 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:04:51,032 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:51,033 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:04:51,033 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:51,037 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:52,982 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:54,994 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-06T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:54,995 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:54,998 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:54.531316+00:00, run_end_date=2025-09-08 17:04:54.664411+00:00, run_duration=0.133095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=143, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:04:51.031068+00:00, queued_by_job_id=85, pid=17835
2025-09-08 17:04:54,999 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-06T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:52.502995+00:00, run_end_date=2025-09-08 17:04:52.640315+00:00, run_duration=0.13732, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=142, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:04:51.031068+00:00, queued_by_job_id=85, pid=17818
2025-09-08 17:04:55,147 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-06 00:00:00+00:00: scheduled__2025-09-06T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:42.418213+00:00. externally triggered: False> successful
2025-09-08 17:04:55,147 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-06 00:00:00+00:00, run_id=scheduled__2025-09-06T00:00:00+00:00, run_start_date=2025-09-08 17:04:42.433417+00:00, run_end_date=2025-09-08 17:04:55.147417+00:00, run_duration=12.714, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-06 00:00:00+00:00, data_interval_end=2025-09-06 12:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:55,150 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
2025-09-08 17:04:55,161 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:55,161 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:04:55,162 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-30T12:00:00+00:00 [scheduled]>
2025-09-08 17:04:55,163 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-08-30T12:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:04:55,164 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:04:55,165 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:55,174 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-08-30T12:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:04:57,247 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-08-30T12:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:04:57,251 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-08-30T12:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:04:56.800687+00:00, run_end_date=2025-09-08 17:04:56.948261+00:00, run_duration=0.147574, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=144, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:04:55.162940+00:00, queued_by_job_id=85, pid=17865
2025-09-08 17:04:57,412 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-08-30 12:00:00+00:00: scheduled__2025-08-30T12:00:00+00:00, state:running, queued_at: 2025-09-08 17:04:40.335843+00:00. externally triggered: False> successful
2025-09-08 17:04:57,413 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-08-30 12:00:00+00:00, run_id=scheduled__2025-08-30T12:00:00+00:00, run_start_date=2025-09-08 17:04:40.350586+00:00, run_end_date=2025-09-08 17:04:57.413292+00:00, run_duration=17.062706, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-30 12:00:00+00:00, data_interval_end=2025-09-06 00:00:00+00:00, dag_hash=39fd1fae9ff986f558854304997b595b
2025-09-08 17:04:57,417 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 00:00:00+00:00, run_after=2025-09-06 12:00:00+00:00
2025-09-08 17:04:58,447 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
2025-09-08 17:06:13,222 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
2025-09-08 17:06:13,249 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:13,250 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:06:13,250 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:13,251 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskA scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:06:13,251 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2025-09-08 17:06:13,252 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:13,256 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskA', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:15,134 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskA', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:06:15,138 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskA, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:14.666154+00:00, run_end_date=2025-09-08 17:06:14.791579+00:00, run_duration=0.125425, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=6, operator=BashOperator, queued_dttm=2025-09-08 17:06:13.250805+00:00, queued_by_job_id=85, pid=18449
2025-09-08 17:06:15,199 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:15,200 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:06:15,200 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:15,201 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskChoose scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:06:15,202 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2025-09-08 17:06:15,202 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:15,206 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskChoose', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:17,188 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskChoose', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:06:17,191 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskChoose, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:16.747389+00:00, run_end_date=2025-09-08 17:06:16.861738+00:00, run_duration=0.114349, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-09-08 17:06:15.201124+00:00, queued_by_job_id=85, pid=18467
2025-09-08 17:06:17,240 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:17,240 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:06:17,241 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:17,242 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskBranch scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:06:17,242 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2025-09-08 17:06:17,243 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:17,247 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskBranch', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:19,289 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskBranch', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:06:19,294 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskBranch, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:18.818280+00:00, run_end_date=2025-09-08 17:06:18.950174+00:00, run_duration=0.131894, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=4, operator=BranchPythonOperator, queued_dttm=2025-09-08 17:06:17.241662+00:00, queued_by_job_id=85, pid=18495
2025-09-08 17:06:19,351 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:19,352 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:06:19,352 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:19,354 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskC scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:06:19,354 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2025-09-08 17:06:19,355 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:19,359 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskC', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:21,282 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskC', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:06:21,287 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskC, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:20.826389+00:00, run_end_date=2025-09-08 17:06:20.934189+00:00, run_duration=0.1078, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-09-08 17:06:19.353349+00:00, queued_by_job_id=85, pid=18506
2025-09-08 17:06:21,353 INFO - 1 tasks up for execution:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:21,354 INFO - DAG cron_catchup_backfill has 0/16 running and queued tasks
2025-09-08 17:06:21,354 INFO - Setting the following tasks to queued state:
	<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>
2025-09-08 17:06:21,355 INFO - Trying to enqueue tasks: [<TaskInstance: cron_catchup_backfill.taskD scheduled__2025-09-07T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2025-09-08 17:06:21,356 INFO - Sending TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2025-09-08 17:06:21,356 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:21,361 INFO - Executing command: ['airflow', 'tasks', 'run', 'cron_catchup_backfill', 'taskD', 'scheduled__2025-09-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/executing_cron_catchup_backfill.py']
2025-09-08 17:06:23,347 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cron_catchup_backfill', task_id='taskD', run_id='scheduled__2025-09-07T00:00:00+00:00', try_number=1, map_index=-1)
2025-09-08 17:06:23,351 INFO - TaskInstance Finished: dag_id=cron_catchup_backfill, task_id=taskD, run_id=scheduled__2025-09-07T00:00:00+00:00, map_index=-1, run_start_date=2025-09-08 17:06:22.892765+00:00, run_end_date=2025-09-08 17:06:23.027969+00:00, run_duration=0.135204, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-09-08 17:06:21.355102+00:00, queued_by_job_id=85, pid=18523
2025-09-08 17:06:23,390 INFO - Marking run <DagRun cron_catchup_backfill @ 2025-09-07 00:00:00+00:00: scheduled__2025-09-07T00:00:00+00:00, state:running, queued_at: 2025-09-08 17:06:13.218489+00:00. externally triggered: False> successful
2025-09-08 17:06:23,390 INFO - DagRun Finished: dag_id=cron_catchup_backfill, execution_date=2025-09-07 00:00:00+00:00, run_id=scheduled__2025-09-07T00:00:00+00:00, run_start_date=2025-09-08 17:06:13.230980+00:00, run_end_date=2025-09-08 17:06:23.390859+00:00, run_duration=10.159879, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-09-07 00:00:00+00:00, data_interval_end=2025-09-07 12:00:00+00:00, dag_hash=712f1f12a72f4bb9b6d8fa080e6c8e8d
2025-09-08 17:06:23,394 INFO - Setting next_dagrun for cron_catchup_backfill to 2025-09-06 12:00:00+00:00, run_after=2025-09-13 00:00:00+00:00
2025-09-08 17:08:06,205 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 17:13:06,251 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-09-08 17:14:30,444 INFO - Exiting gracefully upon receiving signal 15
2025-09-08 17:14:31,449 INFO - Sending 15 to group 4276. PIDs of all processes in the group: [4276]
2025-09-08 17:14:31,449 INFO - Sending the signal 15 to group 4276
2025-09-08 17:14:31,664 INFO - Process psutil.Process(pid=4276, status='terminated', exitcode=0, started='16:38:05') (4276) terminated with exit code 0
2025-09-08 17:14:31,672 INFO - Sending 15 to group 4276. PIDs of all processes in the group: []
2025-09-08 17:14:31,676 INFO - Sending the signal 15 to group 4276
2025-09-08 17:14:31,676 INFO - Sending the signal 15 to process 4276 as process group is missing.
2025-09-08 17:14:31,677 INFO - Exited execute loop
